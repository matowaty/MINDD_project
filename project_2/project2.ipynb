{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "#  Project\n",
    "\n",
    "**Project Goal:** \n",
    "\n",
    "**Dataset Period:**\n",
    "\n",
    "**Methodology:** \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## 1. Business Understanding\n",
    "\n",
    "### 1.1 Business Objectives\n",
    "TODO\n",
    "\n",
    "### 1.2 Project Goals and Successs Criteria\n",
    "TODO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import PowerTransformer, RobustScaler, StandardScaler, PowerTransformer\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import Lasso, LogisticRegression, LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer, mean_squared_error, mean_absolute_percentage_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import (\n",
    "    BaggingRegressor,\n",
    "    GradientBoostingRegressor,\n",
    "    RandomForestRegressor,\n",
    ")\n",
    "\n",
    "import math\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Data Understanding\n",
    "\n",
    "### 2.1 Data Collection\n",
    "\n",
    "The first step is to load the datasets into the working environment. This involves importing the necessary libraries and reading the data file into a suitable data structure, namely, a DataFrame using Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "weather = pd.read_csv(\"weather.csv\", parse_dates=[\"time\"])\n",
    "energy = pd.read_csv(\"energy_dataset.csv\", parse_dates=[\"time\"])\n",
    "\n",
    "# Set 'time' as index\n",
    "weather = weather.set_index(\"time\")\n",
    "energy = energy.set_index(\"time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### 2.2 Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "##### Basic dataset information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "The *energy* dataset contains 35064 entries and 24 features, representing hourly records of electricity generation from various sources, total system load, and the day-ahead market price. Each row corresponds to one hour of energy system operation, and the goal is to forecast the electricity price one hour and one day ahead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "The *weather* dataset also contains 35064 entries and 5 features representing hourly meteorological measurements such as temperature, pressure, humidity, and wind speed. Each row corresponds to one hour of weather conditions, and these variables are used as exogenous inputs to improve electricity price forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### 2.3 Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "#### 2.3.1 Target variable analysis\n",
    "\n",
    "The target variable `price_day_ahead` represents the eletricity market price for the upcoming hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col='price_day_ahead'\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.hist(energy[target_col], bins=50, edgecolor='black')\n",
    "plt.title(\"Histogram of Day-Ahead Electricity Price\")\n",
    "plt.xlabel(\"Price (€/MWh)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "The histogram shows a distribution that is very close to a normal distribution, although it is slightly right-skewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(energy[target_col])\n",
    "plt.title(\"Time Series of Electricity Price (Day-Ahead)\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Price (€/MWh)\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "The time series plot shows strong short-term fluctuations and clear seasonal patterns, with occasional price spikes. Prices vary over time, indicating non-stationarity and the presence of both volatility and periodic behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "#### 2.3.2 Feature distribution analysis\n",
    "\n",
    "Now we will perform feature distribution analysis to examine how the data values are spread across the datasets. We will use plots and histograms to visualise the distributions features. Box plots for will be skipped in this step, as they will be specifically used for outlier detection in paragraph `2.4.2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_distribution(nonDiscreteFeatures, df):\n",
    "    nrows = math.ceil(len(nonDiscreteFeatures) / 2)\n",
    "    ncols = 2\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(16, nrows * 5))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, col in enumerate(nonDiscreteFeatures):\n",
    "        df[col].hist(bins=30, ax=axes[i])\n",
    "        axes[i].set_title(f'{col} Distribution')\n",
    "        axes[i].set_xlabel(col)\n",
    "        axes[i].set_ylabel('Frequency')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "All of the features are numerical and continuous."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "##### Energy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_features = [col for col in energy.columns \n",
    "                   if col not in ['time', 'price_day_ahead']]\n",
    "feat_distribution(energy_features, energy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "None of the features has a normal distribution. `generation_hydro_pumped_storage_consumption`, `generation_hydro_water_reservoir`, and `generation_solar` are strongly right-skewed, while `generation_wind_onshore` is moderately right-skewed. In contrast, `generation_waste` is left-skewed.\n",
    "Variables with skewed distributions will be handled in paragraph 3.4.3, because skewness can negatively affect the models used later in paragraph 4.2, particularly KNN, SVR, and Linear Regression, which rely on distance metrics or assumptions of linearity.\n",
    "\n",
    "`generation_marine`, `generation_geothermal`, `generation_fossil_oil_shale`, `generation_fossil_peat`, and `generation_fossil_coal-derived_gas` contain only zeros, which is consistent with the dataset description provided in paragraph 2.2.\n",
    "\n",
    "The data represented by the remaining variables generally show irregular, multimodal, or heavily skewed shapes, reflecting the diverse and highly variable nature of electricity generation across different sources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "##### Weather dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_features = [col for col in weather.columns if col != 'time']\n",
    "feat_distribution(weather_features, weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "`temperature` and `pressure` distribution is close to normal, whereas `humidity` is slightly left-skewed and `wind_speed` is right-skewed.\n",
    "\n",
    "Skeweness will be handled in paragraph DOK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "skewed_cols = ['generation_hydro_pumped_storage_consumption','generation_hydro_water_reservoir','generation_solar','generation_wind_onshore','generation_waste','wind_speed']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "### 2.4 Data Quality Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "#### 2.4.1 Identify missing values\n",
    "\n",
    "In the first place, we will check for missing values to ensure data completeness and avoid potential issues during analysis and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# % missing values by column\n",
    "\n",
    "def missing_values_info(df):\n",
    "    nulls = df.isnull().sum()\n",
    "    percent = round(nulls / df.shape[0] * 100, 3)\n",
    "    \n",
    "    nullvalues = pd.concat([nulls, percent], axis=1)\n",
    "    nullvalues.columns = [\"Count\", \"%\"]\n",
    "    \n",
    "    return nullvalues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_info(energy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "The proportion of missing values varies across the energy-generation features. Most variables contain only a very small fraction of missing entries (around 0.05% each), including `generation_biomass`, `generation_fossil_gas`, `generation_solar`, `generation_wind_onshore`, and many others.\n",
    "A few features have slightly higher but still low missing rates, such as `generation_nuclear` at 0.048% and `total_load_actual` at 0.103%.\n",
    "\n",
    "Two variables — `generation_hydro_pumped_storage_aggregated` and `forecast_wind_offshore_eday_ahead` — have 100% missing values, meaning they contain no usable data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skipping the NaNs\n",
    "energy_features = [\n",
    "    f for f in energy_features\n",
    "    if energy[f].notna().sum() > 0\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_info(weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "There are no missing values in `weather` dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "#### 2.4.2 Identify outliers\n",
    "\n",
    "Based on dataframes information in paragraph `2.2` there might be potential outliers such as values at the extreme ends of the distributions (e.g., very high generation levels or unusually low/high prices). These points can disproportionately influence analysis and model results. That's why now we will identify outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "DOK \n",
    "Rolling Window Analysis: calculate rolling mean and standard deviation. Values\n",
    "that deviate significantly from the rolling mean (e.g., beyond ±3 standard\n",
    "deviations) may be considered outliers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "##### 2.4.2.1 Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,5))\n",
    "plt.boxplot(\n",
    "    energy[target_col],\n",
    "    vert=True,\n",
    "    patch_artist=True,\n",
    "    boxprops=dict(facecolor='lightblue', color='blue'),\n",
    "    medianprops=dict(color='red'),\n",
    "    whiskerprops=dict(color='blue'),\n",
    "    capprops=dict(color='blue'),\n",
    "    flierprops=dict(marker='o', markersize=4, markerfacecolor='blue')\n",
    ")\n",
    "plt.title(\"Boxplot of Day-Ahead Electricity Price\")\n",
    "plt.ylabel(\"Price (€/MWh)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "The boxplot shows clear price spikes, confirming the presence of outliers in the target variable. These extreme values reflect real market volatility but may negatively affect several forecasting models. Therefore, while they are kept in the dataset, they will be handled later in paragraph `3.4.3` DOK through appropriate preprocessing to minimise their impact on model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "##### 2.4.2.2 Energy features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplots(numeric_features, df):\n",
    "    num_plots = len(numeric_features)\n",
    "    cols = 2\n",
    "    rows = math.ceil(num_plots / cols)\n",
    "\n",
    "    plt.figure(figsize=(cols * 5, rows * 4))\n",
    "\n",
    "    for i, feature in enumerate(numeric_features):\n",
    "        plt.subplot(rows, cols, i + 1)\n",
    "        sns.boxplot(y=df[feature])\n",
    "        plt.title(f\"Boxplot: {feature}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def outliers_detection(numericFeatures, df):\n",
    "    Q1 = df[numericFeatures].quantile(0.25)\n",
    "    Q3 = df[numericFeatures].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    outliers = ((df[numericFeatures] < (Q1 - 1.5 * IQR)) | (df[numericFeatures] > (Q3 + 1.5 * IQR)))\n",
    "    print(\"Number of outliers per numeric feature:\")\n",
    "    print(outliers.sum())\n",
    "\n",
    "    outliers_cols = outliers.any()\n",
    "    outliers_cols = outliers_cols[outliers_cols].index.tolist()\n",
    "    print(\"\\nColumns containing outliers:\")\n",
    "    print(outliers_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplots(energy_features, energy)\n",
    "outliers_detection(energy_features, energy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "We performed outliers detection on all numerical features using the Interquartile Range (IQR) method and visualized it using boxplots.\n",
    "\n",
    "Features such as `generation_fossil_gas`, `generation_hydro_pumped_storage_consumption` and `generation_other` contain a high number of outlier values.\n",
    "`generation_wind_onshore`, `generation_waste`,`generation_hydro_water_reservoir` and `generation_fossil_oil` also contained a noticeable number out outliers.\n",
    "`generation_biomass` contains a few outliers.\n",
    "The rest of the features of `energy` dataset showed no outliers according to the IQR method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "##### 2.4.2.3 Weather features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplots(weather_features, weather)\n",
    "outliers_detection(weather_features, weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "`pressure` and `wind_speed` contain a noticeable number of outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_cols = ['pressure', \n",
    "                 'wind_speed', \n",
    "                 'generation_fossil_gas', \n",
    "                 'generation_hydro_pumped_storage_consumption', \n",
    "                 'generation_other', \n",
    "                 'generation_wind_onshore', \n",
    "                 'generation_waste',\n",
    "                 'generation_hydro_water_reservoir',\n",
    "                 'generation_biomass',\n",
    "                 'generation_fossil_oil' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "#### 2.4.3 Check data duplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy.index.duplicated().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.index.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "There are no duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Data Preparation\n",
    "\n",
    "### 3.1 Data Cleaning\n",
    "\n",
    "#### 3.1.1 Missing values\n",
    "\n",
    "The first thing to be perfomed is to handle missing values indicated in paragraph `2.4.1`.\n",
    "\n",
    "The missing values cannot be romoved that's why the NaNs will be filled in and columns only with NaNs will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Remaining NaNs in energy:\", energy.isna().sum().sum())\n",
    "\n",
    "# Drop columns that contain only NaN values\n",
    "energy = energy.dropna(axis=1, how='all')\n",
    "\n",
    "# Interpolate missing values (time-series aware)\n",
    "energy.index = pd.to_datetime(energy.index, errors='coerce', utc=True)\n",
    "energy = energy.interpolate(method='time')\n",
    "\n",
    "# Forward-fill remaining NaNs (edge cases)\n",
    "energy = energy.ffill().bfill()\n",
    "\n",
    "print(\"Remaining NaNs in energy:\", energy.isna().sum().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58",
   "metadata": {},
   "source": [
    "#### 3.1.2 Handling outliers\n",
    "\n",
    "To remove outliers identified in paragraph `2.4.2` we will perform winsorization and use **Robust Scaler** during `Data Transformation` in paragraph `3.3`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "### 3.2 Bivariate analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60",
   "metadata": {},
   "source": [
    "Here we will skip features that consist only of values 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis = energy.join(weather, how=\"inner\")\n",
    "\n",
    "# remove columns that are entirely zero\n",
    "non_zero_cols = df_analysis.columns[(df_analysis != 0).any()]\n",
    "\n",
    "# keep only numeric features\n",
    "num_df = df_analysis[non_zero_cols].select_dtypes(include=\"number\")\n",
    "\n",
    "# compute correlation with price\n",
    "corr = num_df.corr()[target_col].drop(labels=[target_col]).sort_values()\n",
    "\n",
    "plt.figure(figsize=(8,12))\n",
    "corr.plot(kind=\"barh\")\n",
    "plt.title(\"Correlation with Day-Ahead Price\")\n",
    "plt.xlabel(\"Correlation\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "The diagram shows that some variables are correlated positively, some nagetively and some are only slightly or not correlated with the target variable at all."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63",
   "metadata": {},
   "source": [
    "#### Correlation between the eletricity price and the day of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(energy.index))\n",
    "# print(energy.index[:5])\n",
    "\n",
    "weekday_price = energy['price_day_ahead'].groupby(energy.index.to_series().dt.dayofweek).mean()\n",
    "print(weekday_price)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "weekday_price.plot(kind='bar')\n",
    "plt.title(\"Average Day-Ahead Electricity Price by Day of the Week\")\n",
    "plt.ylabel(\"Price (€/MWh)\")\n",
    "plt.xlabel(\"Day of Week (0=Mon, 6=Sun)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65",
   "metadata": {},
   "source": [
    "There's no strong dependency between the day of the week and the eletricity price, however the price tends to be lower on the weekends."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66",
   "metadata": {},
   "source": [
    "##### Correlation between the temperature and the eletricity price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_analysis[\"temperature\"]\n",
    "y = df_analysis[target_col]\n",
    "\n",
    "# smooth curve\n",
    "low = lowess(y, x, frac=0.15)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(x, y, s=5, alpha=0.1)\n",
    "plt.plot(low[:,0], low[:,1], linewidth=3)\n",
    "\n",
    "plt.title(\"LOWESS Smoothed Relationship: Temperature vs Price\")\n",
    "plt.xlabel(\"Temperature (K)\")\n",
    "plt.ylabel(\"Day-Ahead Price (€/MWh)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "There's no significant correlation between the eletricity price and the temperature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69",
   "metadata": {},
   "source": [
    "### 3.3 Data Transformation\n",
    "\n",
    "Since all the features are numerical they don't have to be encoded in any way.\n",
    "\n",
    "#### 3.3.1 Dropping unnecessary variables\n",
    "\n",
    "There are variables with all 0 values. They will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = energy.join(weather, how=\"inner\")\n",
    "\n",
    "dfML = df.copy()\n",
    "\n",
    "zero_cols = dfML.columns[(dfML == 0).all()]\n",
    "print(\"Dropped columns with all zeros:\", list(zero_cols))\n",
    "\n",
    "dfML = dfML.drop(columns=zero_cols)\n",
    "\n",
    "dfML.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71",
   "metadata": {},
   "source": [
    "\n",
    "#### 3.3.1 Handling variables with skewed distribution\n",
    "\n",
    "Since not all of the skewed distrubutions concern variables with positive values we will use **Yeo-Johnson** scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast to float before transformation to avoid dtype issues\n",
    "dfML = dfML.copy()\n",
    "\n",
    "for col in skewed_cols:\n",
    "    dfML[col] = dfML[col].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = PowerTransformer(method='yeo-johnson')\n",
    "\n",
    "print(df[skewed_cols].dtypes)\n",
    "\n",
    "dfML.loc[:, skewed_cols] = pt.fit_transform(dfML.loc[:, skewed_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74",
   "metadata": {},
   "source": [
    "#### 3.3.2 Handling outliers\n",
    "\n",
    "As indicated in paragraph `3.1`, we will use **Robust Scaler** to handle outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = RobustScaler()\n",
    "\n",
    "print(outliers_cols)\n",
    "print(type(outliers_cols))\n",
    "\n",
    "# Fit the scaler on the numeric features and transform\n",
    "dfML.loc[:,outliers_cols] = scaler.fit_transform(dfML[outliers_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76",
   "metadata": {},
   "source": [
    "### 3.4 Data Splitting\n",
    "\n",
    "To evaluate the models used in paragraph `4` we have to split dataset into a train and a test set. We will use an 75/25 split ratio (the whole dataset represents 4 years of data and the test set will consist of last 12 months) to ensure sufficient amount of data for training while retaining enough samples for meaningful evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last 12 months for test\n",
    "split_date = dfML.index.max() - pd.DateOffset(years=1)\n",
    "\n",
    "train_dfML = dfML[dfML.index <= split_date]\n",
    "test_dfML  = dfML[dfML.index > split_date]\n",
    "\n",
    "print(\"Split date:\", split_date)\n",
    "print(\"Train:\", train_dfML.shape)\n",
    "print(\"Test:\", test_dfML.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78",
   "metadata": {},
   "source": [
    "### 3.5 Feature selection\n",
    "\n",
    "#### Embedded method - Lasso regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_regularization(df, target_col=\"price_day_ahead\"):\n",
    "\n",
    "    X = df.drop(columns=[target_col]).copy()\n",
    "    y = df[target_col].copy()\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    lasso = Lasso(alpha=0.01, random_state=42, max_iter=5000)\n",
    "\n",
    "    sel_ = SelectFromModel(lasso)\n",
    "    sel_.fit(X_scaled, y)\n",
    "\n",
    "    selected_feat = X.columns[sel_.get_support()]\n",
    "    removed_feat = X.columns[~sel_.get_support()]\n",
    "\n",
    "    print(f\"Selected features ({len(selected_feat)}):\")\n",
    "    print(selected_feat.tolist())\n",
    "\n",
    "    print(f\"\\nRemoved features ({len(removed_feat)}):\")\n",
    "    print(removed_feat.tolist())\n",
    "\n",
    "    return selected_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lasso_SelectedColumns = lasso_regularization(train_dfML)\n",
    "\n",
    "Lasso_SelectedColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dfML = train_dfML[list(Lasso_SelectedColumns) + [target_col]]\n",
    "test_dfML  = test_dfML[list(Lasso_SelectedColumns) + [target_col]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84",
   "metadata": {},
   "source": [
    "With these methods, we prepared a dataframes for future testing and tuning to compare different models and select the one with the best performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Modelling\n",
    "\n",
    "### 4.1 Statistical Models\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86",
   "metadata": {},
   "source": [
    "### 4.2 Machine Learning Models\n",
    "\n",
    "comment\n",
    "\n",
    "#### 4.2.1 Build supervised sliding-window datasets\n",
    "\n",
    "We will be using two functions two build sliding-window datasets. `make_sliding_window` is used for single-step predicitons and `slideWindow` for multi-step predictions. Later on these functions will be used to build the sliding-window datasets after choosing the best window size in paragraph `4.2.2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sliding_window(series, window_size, horizon=1): # for single-step\n",
    "    X, y = [], []\n",
    "    for i in range(len(series) - window_size - horizon + 1):\n",
    "        X.append(series[i:i + window_size])\n",
    "        y.append(series[i + window_size + horizon - 1])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "def slideWindow(time_series, window_in, horizon): # for multi-step\n",
    "    if (len(time_series) - window_in - horizon + 1) <= 0:\n",
    "       raise ValueError(\"Time series too short for window size or horizon.\")\n",
    "    \n",
    "    d = time_series.values\n",
    "    X, y = [], []\n",
    "\n",
    "    for start in range(len(time_series)-window_in):\n",
    "        end = start + window_in\n",
    "        out = end + horizon\n",
    "        X.append(d[start:end].reshape(-1))\n",
    "        y.append(d[end:out].ravel()) # ravel() is equivalent to reshape(-1): returnscontiguous flattened array\n",
    "        cols_x = [f'x{i}' for i in range(1, window_in+1)]\n",
    "        cols_y = [f'y{i}' for i in range(1, horizon+1)]\n",
    "        df_X = pd.DataFrame(X, columns=cols_x)\n",
    "        df_y = pd.DataFrame(y, columns=cols_y)\n",
    "\n",
    "    return pd.concat([df_X, df_y], axis=1).dropna()\n",
    "\n",
    "def slideWindow2(time_series, window_in, horizon):\n",
    "    if (len(time_series) - window_in - horizon + 1) <= 0:\n",
    "        raise ValueError(\"Time series too short for window size or horizon.\")\n",
    "\n",
    "    d = time_series.values\n",
    "    n_samples = len(d) - window_in - horizon + 1\n",
    "\n",
    "    X = np.empty((n_samples, window_in))\n",
    "    y = np.empty((n_samples, horizon))\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        X[i] = d[i : i + window_in]\n",
    "        y[i] = d[i + window_in : i + window_in + horizon]\n",
    "\n",
    "    cols_x = [f\"x{i}\" for i in range(1, window_in + 1)]\n",
    "    cols_y = [f\"y{i}\" for i in range(1, horizon + 1)]\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        np.hstack([X, y]),\n",
    "        columns=cols_x + cols_y\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "# HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88",
   "metadata": {},
   "source": [
    "#### 4.2.2 Several window sizes comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89",
   "metadata": {},
   "source": [
    "Now we will compare three window sizes (one day, two days and one week) to find the most efficient one. For that we will use Random Forest because it's the least sensitive to data changes and variance is reduced by averaging.\n",
    "To compare the results we will use MAE - Mean Aboslute Error - because it has low sensitivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_sizes = [24, 48, 168]   # 1 day, 2 days, 1 week\n",
    "horizons = [1, 24] # the number of time steps into the future to forecast at any point in time\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "results = []\n",
    "\n",
    "for w in window_sizes:\n",
    "\n",
    "    X, y = make_sliding_window(train_dfML[target_col].values, window_size=w, horizon=1)\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(tscv.split(X)):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        model = RandomForestRegressor(\n",
    "            n_estimators=50,\n",
    "            max_depth=10,\n",
    "            random_state=42,\n",
    "            n_jobs=-1 # enable paralelism\n",
    "        )\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_val)\n",
    "        mae = mean_absolute_error(y_val, y_pred)\n",
    "\n",
    "        results.append({\n",
    "            \"window\": w,\n",
    "            \"fold\": fold,\n",
    "            \"MAE\": mae\n",
    "        })\n",
    "        print(f\"Window {w}, Fold {fold}\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df.groupby(\"window\")[\"MAE\"].mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91",
   "metadata": {},
   "source": [
    "Mean Aboslute Error (MAE) is the lowest for 24-hour long window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_WINDOW = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = make_sliding_window(\n",
    "    train_dfML[target_col].values,\n",
    "    window_size=BEST_WINDOW,\n",
    "    horizon=1\n",
    ")\n",
    "\n",
    "print(\"One Day Sliding Window Created for 1 step\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sw_one_day_multi_step = slideWindow2(\n",
    "        train_dfML[target_col],\n",
    "        window_in=BEST_WINDOW,\n",
    "        horizon=24\n",
    "    )\n",
    "\n",
    "print(\"One Day Sliding Window Created for 24 step\") # TO BE CREATED LATER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95",
   "metadata": {},
   "source": [
    "#### 4.2.3 Model selection and tuning\n",
    "\n",
    "Model selection will be performed for 1-step predicitons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_stage1 = {\n",
    "    \"LinearRegression\": Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\", LinearRegression())\n",
    "    ]),\n",
    "\n",
    "    \"DecisionTree\": DecisionTreeRegressor(random_state=42),\n",
    "\n",
    "    \"KNN\": Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\", KNeighborsRegressor())\n",
    "    ]),\n",
    "\n",
    "    \"SVR\": Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\", SVR())\n",
    "    ]),\n",
    "\n",
    "    \"Bagging\": BaggingRegressor(random_state=42),\n",
    "\n",
    "    \"GradientBoosting\": GradientBoostingRegressor(random_state=42),\n",
    "\n",
    "    \"RandomForest\": RandomForestRegressor(\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "\n",
    "    \"XGBoost\": XGBRegressor(\n",
    "        objective=\"reg:squarederror\",\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "\n",
    "    \"LightGBM\": LGBMRegressor(\n",
    "        random_state=42\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_mape(y_true, y_pred, eps=1e-8):\n",
    "    y_true = np.maximum(np.abs(y_true), eps)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {\n",
    "    \"mae\": \"neg_mean_absolute_error\",\n",
    "    \"rmse\": make_scorer(\n",
    "        lambda y, yhat: np.sqrt(mean_squared_error(y, yhat)),\n",
    "        greater_is_better=False\n",
    "    ),\n",
    "    \"mape\": make_scorer(\n",
    "        safe_mape,\n",
    "        greater_is_better=False\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99",
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "stage1_results = []\n",
    "\n",
    "for name, model in models_stage1.items():\n",
    "    fold_mae = []\n",
    "    fold_rmse = []\n",
    "    fold_mape = []\n",
    "\n",
    "    print(f\"\\nTraining model: {name}\")\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(tscv.split(X_train), 1):\n",
    "        print(f\"  Fold {fold}/5\")\n",
    "\n",
    "        X_tr, X_val = X_train[train_idx], X_train[val_idx]\n",
    "        y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "        model.fit(X_tr, y_tr)\n",
    "        y_pred = model.predict(X_val)\n",
    "\n",
    "        fold_mae.append(mean_absolute_error(y_val, y_pred))\n",
    "        fold_rmse.append(np.sqrt(mean_squared_error(y_val, y_pred)))\n",
    "        fold_mape.append(\n",
    "            np.mean(np.abs((y_val - y_pred) / np.maximum(np.abs(y_val), 1e-8)))\n",
    "        )\n",
    "\n",
    "    stage1_results.append({\n",
    "        \"Model\": name,\n",
    "        \"MAE\": np.mean(fold_mae),\n",
    "        \"RMSE\": np.mean(fold_rmse),\n",
    "        \"MAPE\": np.mean(fold_mape),\n",
    "    })\n",
    "\n",
    "    print(f\"  → MAE:  {np.mean(fold_mae):.3f}\")\n",
    "    print(f\"  → RMSE: {np.mean(fold_rmse):.3f}\")\n",
    "    print(f\"  → MAPE: {np.mean(fold_mape):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stage1 = (\n",
    "    pd.DataFrame(stage1_results)\n",
    "      .sort_values(by=[\"MAE\", \"RMSE\", \"MAPE\"])\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(\"\\nFinal results:\")\n",
    "print(results_stage1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101",
   "metadata": {},
   "source": [
    "Before tuning:\n",
    "\n",
    "| Model            | MAE    | RMSE   | MAPE   |\n",
    "| ---------------- | ------ | ------ | ------ |\n",
    "| LinearRegression | 2.0272 | 3.1191 | 0.0561 |\n",
    "| RandomForest     | 2.2178 | 3.4819 | 0.0657 |\n",
    "| LightGBM         | 2.2992 | 3.5899 | 0.0693 |\n",
    "| GradientBoosting | 2.3319 | 3.6322 | 0.0688 |\n",
    "| Bagging          | 2.3822 | 3.6588 | 0.0676 |\n",
    "| XGBoost          | 2.4362 | 3.7724 | 0.0773 |\n",
    "| SVR              | 3.1489 | 5.6502 | 0.1291 |\n",
    "| DecisionTree     | 3.4551 | 5.2995 | 0.1020 |\n",
    "| KNN              | 3.9266 | 5.5235 | 0.1241 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102",
   "metadata": {},
   "source": [
    "#### 4.2.4 Hyperparameter tuning\n",
    "\n",
    "Hyperparameter tuning will be performed for 1-step predictions.\n",
    "\n",
    "svr musi byc sekwencyjnie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grids = {\n",
    "    \"DecisionTree\": {\n",
    "        \"max_depth\": [3, 5, 10, None],\n",
    "        \"min_samples_leaf\": [1, 5, 10]\n",
    "    },\n",
    "\n",
    "    \"KNN\": {\n",
    "        \"model__n_neighbors\": [3, 5, 10, 20]\n",
    "    },\n",
    "\n",
    "    \"SVR\": {\n",
    "        \"model__C\": [1, 10],\n",
    "        \"model__gamma\": [\"scale\"]\n",
    "    },\n",
    "\n",
    "    \"Bagging\": {\n",
    "        \"n_estimators\": [50, 100]\n",
    "    },\n",
    "\n",
    "    \"GradientBoosting\": {\n",
    "        \"n_estimators\": [100, 200],\n",
    "        \"learning_rate\": [0.05, 0.1],\n",
    "        \"max_depth\": [3, 5]\n",
    "    },\n",
    "\n",
    "    \"RandomForest\": {\n",
    "        \"n_estimators\": [100, 200],\n",
    "        \"max_depth\": [5, 10, None]\n",
    "    },\n",
    "\n",
    "    \"XGBoost\": {\n",
    "        \"n_estimators\": [200, 400],\n",
    "        \"learning_rate\": [0.05, 0.1],\n",
    "        \"max_depth\": [3, 5]\n",
    "    },\n",
    "\n",
    "    \"LightGBM\": {\n",
    "        \"n_estimators\": [200, 400],\n",
    "        \"learning_rate\": [0.05, 0.1],\n",
    "        \"num_leaves\": [31, 63]\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_results = []\n",
    "best_estimators = {}\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "for name, model in models_stage1.items():\n",
    "    print(f\"\\nTuning model: {name}\")\n",
    "\n",
    "    if name == \"LinearRegression\":\n",
    "        print(\"No tuning perfomed\")\n",
    "        continue\n",
    "\n",
    "    if name in [\"SVR\", \"LightGBM\"]:\n",
    "        grid = GridSearchCV(\n",
    "            estimator=model,\n",
    "            param_grid=param_grids.get(name, {}),\n",
    "            cv=tscv,\n",
    "            scoring=scoring,     \n",
    "            refit=\"mae\",         \n",
    "            n_jobs=1\n",
    "        )\n",
    "    elif name in [\"RandomForest\", \"XGBoost\"]:\n",
    "        grid = GridSearchCV(\n",
    "            estimator=model,\n",
    "            param_grid=param_grids.get(name, {}),\n",
    "            cv=tscv,\n",
    "            scoring=scoring,    \n",
    "            refit=\"mae\"\n",
    "        )\n",
    "    else:\n",
    "        grid = GridSearchCV(\n",
    "            estimator=model,\n",
    "            param_grid=param_grids.get(name, {}),\n",
    "            cv=tscv,\n",
    "            scoring=scoring,     \n",
    "            refit=\"mae\",\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    best_idx = grid.best_index_\n",
    "\n",
    "    best_mae = -grid.cv_results_[\"mean_test_mae\"][best_idx]\n",
    "    best_rmse = -grid.cv_results_[\"mean_test_rmse\"][best_idx]\n",
    "    best_mape = -grid.cv_results_[\"mean_test_mape\"][best_idx]\n",
    "\n",
    "    tuning_results.append({\n",
    "        \"Model\": name,\n",
    "        \"Best_MAE\": best_mae,\n",
    "        \"Best_RMSE\": best_rmse,\n",
    "        \"Best_MAPE\": best_mape,\n",
    "        \"Best_Params\": grid.best_params_\n",
    "    })\n",
    "\n",
    "    best_estimators[name] = grid.best_estimator_\n",
    "\n",
    "    print(f\"  → MAE:  {best_mae:.3f}\")\n",
    "    print(f\"  → RMSE: {best_rmse:.3f}\")\n",
    "    print(f\"  → MAPE: {best_mape:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_tuning = (\n",
    "    pd.DataFrame(tuning_results)\n",
    "      .sort_values(\"Best_MAE\")\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(\"\\nFinal results:\")\n",
    "print(results_tuning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106",
   "metadata": {},
   "source": [
    "After tuning:\n",
    "\n",
    "| Model            | MAE       | RMSE      | MAPE       | Best Parameters                                       |\n",
    "| ---------------- | --------- | --------- | ---------- | ----------------------------------------------------- |\n",
    "| **RandomForest** | **2.211** | **3.470** | **0.0658** | `max_depth=None, n_estimators=200`                    |\n",
    "| Bagging          | 2.221     | 3.479     | 0.0654     | `n_estimators=100`                                    |\n",
    "| LightGBM         | 2.263     | 3.544     | 0.0684     | `learning_rate=0.05, n_estimators=200, num_leaves=31` |\n",
    "| GradientBoosting | 2.274     | 3.621     | 0.0703     | `learning_rate=0.05, max_depth=5, n_estimators=200`   |\n",
    "| XGBoost          | 2.279     | 3.595     | 0.0707     | `learning_rate=0.05, max_depth=5, n_estimators=200`   |\n",
    "| SVR              | 2.527     | 4.664     | 0.0832     | `C=10, gamma=scale`                                   |\n",
    "| DecisionTree     | 2.717     | 4.049     | 0.0793     | `max_depth=10, min_samples_leaf=10`                   |\n",
    "| KNN              | 3.875     | 5.434     | 0.1281     | `n_neighbors=10`                                      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107",
   "metadata": {},
   "source": [
    "Among the evaluated machine-learning models, Random Forest achieved the best overall performance, obtaining the lowest MAE, RMSE, and MAPE. Ensemble methods generally outperformed single learners, while distance-based (KNN) and kernel-based (SVR) models performed worse. \n",
    "\n",
    "***Comparison with the baseline: Seasonal Naïve***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_last_value_cv(X_train, y_train, n_splits=5):\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "    maes, rmses, mapes = [], [], []\n",
    "\n",
    "    for _, val_idx in tscv.split(X_train):\n",
    "        X_val = X_train[val_idx]\n",
    "        y_val = y_train[val_idx]\n",
    "\n",
    "        # Naive forecast = last value in the window\n",
    "        y_pred = X_val[:, -1]\n",
    "\n",
    "        maes.append(mean_absolute_error(y_val, y_pred))\n",
    "        rmses.append(np.sqrt(mean_squared_error(y_val, y_pred)))\n",
    "        mapes.append(\n",
    "            np.mean(np.abs((y_val - y_pred) / np.maximum(np.abs(y_val), 1e-8)))\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        \"Model\": \"Naive (Last value)\",\n",
    "        \"MAE\": np.mean(maes),\n",
    "        \"RMSE\": np.mean(rmses),\n",
    "        \"MAPE\": np.mean(mapes),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_results = naive_last_value_cv(X_train, y_train)\n",
    "baseline_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEASONAL_LAG = 24   # change if your data is different\n",
    "\n",
    "def seasonal_naive_cv(X, y, seasonal_lag=24, n_splits=5):\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "    maes, rmses, mapes = [], [], []\n",
    "\n",
    "    for train_idx, val_idx in tscv.split(X):\n",
    "        X_val = X[val_idx]\n",
    "        y_val = y[val_idx]\n",
    "\n",
    "        # Seasonal naive forecast\n",
    "        # Take value from t - seasonal_lag inside the window\n",
    "        y_pred = X_val[:, -seasonal_lag]\n",
    "\n",
    "        maes.append(mean_absolute_error(y_val, y_pred))\n",
    "        rmses.append(np.sqrt(mean_squared_error(y_val, y_pred)))\n",
    "        mapes.append(\n",
    "            np.mean(\n",
    "                np.abs((y_val - y_pred) / np.maximum(np.abs(y_val), 1e-8))\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        \"Model\": \"SeasonalNaive\",\n",
    "        \"MAE\": np.mean(maes),\n",
    "        \"RMSE\": np.mean(rmses),\n",
    "        \"MAPE\": np.mean(mapes),\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_result = seasonal_naive_cv(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    seasonal_lag=24,\n",
    "    n_splits=5\n",
    ")\n",
    "\n",
    "baseline_df = pd.DataFrame([baseline_result])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final results\n",
    "\n",
    "results_before = (\n",
    "    pd.DataFrame(stage1_results)\n",
    "    .sort_values(by=[\"MAE\", \"RMSE\", \"MAPE\"])\n",
    "    .rename(columns={\n",
    "        \"MAE\": \"MAE_before\",\n",
    "        \"RMSE\": \"RMSE_before\",\n",
    "        \"MAPE\": \"MAPE_before\"\n",
    "    })\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "results_after = (\n",
    "    pd.DataFrame(tuning_results)\n",
    "    .rename(columns={\n",
    "        \"Best_MAE\": \"MAE_after\",\n",
    "        \"Best_RMSE\": \"RMSE_after\",\n",
    "        \"Best_MAPE\": \"MAPE_after\"\n",
    "    })\n",
    "    .drop(columns=\"Best_Params\")\n",
    ")\n",
    "\n",
    "comparison_table = (\n",
    "    results_before\n",
    "    .merge(results_after, on=\"Model\", how=\"left\")\n",
    "    .sort_values(\"MAE_after\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "final_table = pd.concat(\n",
    "    [baseline_df, comparison_table],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "final_table = final_table.sort_values(\n",
    "    by=[\"MAE_after\", \"RMSE_after\", \"MAPE_after\"],\n",
    "    na_position=\"last\"\n",
    ").reset_index(drop=True)\n",
    "\n",
    "print(\"\\nFinal results (including baseline):\")\n",
    "print(final_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113",
   "metadata": {},
   "source": [
    "#### 4.2.5 Perform predictions\n",
    "\n",
    "##### 4.2.5.1 Single-step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "115",
   "metadata": {},
   "source": [
    "##### 4.2.5.2 Multi-step (24-step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "117",
   "metadata": {},
   "source": [
    "#### 4.2.5.3 Plots comparing predictions vs. real test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119",
   "metadata": {},
   "source": [
    "### 4.3 Deep Learning Models\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120",
   "metadata": {},
   "source": [
    "LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 1. Data Preparation\n",
    "# ==========================================\n",
    "# Define Hyperparameters\n",
    "WINDOW_SIZE = 48  # Lookback period (e.g., 48 hours)\n",
    "BATCH_SIZE = 32   # Hyperparameter to tune\n",
    "EPOCHS = 50       # Max epochs (EarlyStopping will cut this short)\n",
    "\n",
    "# Scaling: Deep Learning models require scaled data (0 to 1)\n",
    "# Important: Fit the scaler ONLY on training data to avoid data leakage\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "train_scaled = scaler.fit_transform(train_dfML)\n",
    "test_scaled = scaler.transform(test_dfML)\n",
    "\n",
    "# Create Sliding Windows using your function\n",
    "X_train_full, y_train_full = make_sliding_window(train_scaled, WINDOW_SIZE, horizon=1)\n",
    "X_test, y_test = make_sliding_window(test_scaled, WINDOW_SIZE, horizon=1)\n",
    "\n",
    "# CRITICAL STEP:\n",
    "# The function returns 'y' with ALL features. We strictly need only the Price (column 0) as target.\n",
    "y_train_full = y_train_full[:, 0]\n",
    "y_test = y_test[:, 0]\n",
    "\n",
    "# Split Training into Train and Validation for EarlyStopping\n",
    "val_split = int(len(X_train_full) * 0.8)\n",
    "X_train, y_train = X_train_full[:val_split], y_train_full[:val_split]\n",
    "X_val, y_val = X_train_full[val_split:], y_train_full[val_split:]\n",
    "\n",
    "print(f\"Train shape: {X_train.shape}, Val shape: {X_val.shape}, Test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 2. LSTM Model Definition\n",
    "# ==========================================\n",
    "def build_lstm_model(input_shape):\n",
    "    model = Sequential()\n",
    "\n",
    "    # NEW: Explicit Input Layer\n",
    "    model.add(Input(shape=input_shape))\n",
    "\n",
    "    # LSTM Layer 1 (Removed input_shape argument here)\n",
    "    model.add(LSTM(units=50, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # LSTM Layer 2\n",
    "    model.add(LSTM(units=25, return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Output Layer\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    optimizer = Adam(learning_rate=0.0001)\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    return model\n",
    "\n",
    "# Input shape is (Window Size, Number of Features)\n",
    "model = build_lstm_model(input_shape=(X_train.shape[1], X_train.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 3. Training\n",
    "# ==========================================\n",
    "# Define EarlyStopping\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot Training vs Validation Loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('LSTM Training vs Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 4. Evaluation & Metrics\n",
    "# ==========================================\n",
    "# Predict\n",
    "y_pred_scaled = model.predict(X_test)\n",
    "\n",
    "# Inverse Transform (To get back to Real Prices)\n",
    "# We need a dummy array because scaler expects same number of features as original input\n",
    "def inverse_transform_target(pred_array, scaler, n_features):\n",
    "    dummy = np.zeros((len(pred_array), n_features))\n",
    "    dummy[:, 0] = pred_array.flatten() # Put predictions in first column\n",
    "    return scaler.inverse_transform(dummy)[:, 0]\n",
    "\n",
    "y_pred_real = inverse_transform_target(y_pred_scaled, scaler, train_dfML.shape[1])\n",
    "y_test_real = inverse_transform_target(y_test.reshape(-1, 1), scaler, train_dfML.shape[1])\n",
    "\n",
    "# Calculate Metrics\n",
    "mae = mean_absolute_error(y_test_real, y_pred_real)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_real, y_pred_real))\n",
    "non_zero_mask = y_test_real != 0\n",
    "mape = np.mean(np.abs((y_test_real[non_zero_mask] - y_pred_real[non_zero_mask]) / y_test_real[non_zero_mask])) * 100\n",
    "\n",
    "print(f\"\\nModel Performance:\")\n",
    "print(f\"MAE:  {mae:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAPE: {mape:.4f}%\")\n",
    "\n",
    "# Plot Real vs Predicted (Snippet)\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(y_test_real[:200], label='Actual Price', color='blue')\n",
    "plt.plot(y_pred_real[:200], label='Predicted Price', color='red', linestyle='--')\n",
    "plt.title('LSTM Forecast: Actual vs Predicted (First 200 Hours)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126",
   "metadata": {},
   "source": [
    "RESULTS ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127",
   "metadata": {},
   "source": [
    "GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import GRU\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 1. GRU Model Definition\n",
    "# ==========================================\n",
    "def build_gru_model(input_shape):\n",
    "    model = Sequential()\n",
    "\n",
    "    # NEW: Explicit Input Layer\n",
    "    model.add(Input(shape=input_shape))\n",
    "\n",
    "    # GRU Layer 1 (Removed input_shape argument here)\n",
    "    model.add(GRU(units=50, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # GRU Layer 2\n",
    "    model.add(GRU(units=25, return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # Output Layer\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    optimizer = Adam(learning_rate=0.0001)\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    return model\n",
    "\n",
    "# Reuse the same X_train, y_train from the LSTM step\n",
    "model_gru = build_gru_model(input_shape=(X_train.shape[1], X_train.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 2. Training (Same EarlyStopping)\n",
    "# ==========================================\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=20,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "history_gru = model_gru.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=EPOCHS,           # Same as LSTM\n",
    "    batch_size=BATCH_SIZE,       # Same as LSTM\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stop], # Reusing the same EarlyStopping callback\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot Training vs Validation Loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history_gru.history['loss'], label='Training Loss')\n",
    "plt.plot(history_gru.history['val_loss'], label='Validation Loss')\n",
    "plt.title('GRU Training vs Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 3. Evaluation\n",
    "# ==========================================\n",
    "# Predict\n",
    "y_pred_scaled_gru = model_gru.predict(X_test)\n",
    "\n",
    "# Inverse Transform\n",
    "y_pred_real_gru = inverse_transform_target(y_pred_scaled_gru, scaler, train_dfML.shape[1])\n",
    "\n",
    "# Calculate Metrics\n",
    "mae_gru = mean_absolute_error(y_test_real, y_pred_real_gru)\n",
    "rmse_gru = np.sqrt(mean_squared_error(y_test_real, y_pred_real_gru))\n",
    "non_zero_mask = y_test_real != 0\n",
    "mape_gru = np.mean(np.abs((y_test_real[non_zero_mask] - y_pred_real_gru[non_zero_mask]) / y_test_real[non_zero_mask])) * 100\n",
    "\n",
    "print(f\"\\nGRU Model Performance:\")\n",
    "print(f\"MAE:  {mae_gru:.4f}\")\n",
    "print(f\"RMSE: {rmse_gru:.4f}\")\n",
    "print(f\"MAPE: {mape_gru:.4f}%\")\n",
    "\n",
    "# Plot Comparison: LSTM vs GRU vs Real\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(y_test_real[:200], label='Actual Price', color='black', alpha=0.7)\n",
    "plt.plot(y_pred_real[:200], label='LSTM Prediction', color='red', linestyle='--', alpha=0.7)\n",
    "plt.plot(y_pred_real_gru[:200], label='GRU Prediction', color='green', linestyle='-.', alpha=0.7)\n",
    "plt.title('Comparison: LSTM vs GRU vs Actual (First 200 Hours)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132",
   "metadata": {},
   "source": [
    "24-Step Ahead Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 1. Data Preparation for 24-Step Ahead\n",
    "# ==========================================\n",
    "def create_24h_window(data, window_size):\n",
    "    X, y = [], []\n",
    "    # Loop needs to stop earlier to ensure we have 24 future values\n",
    "    for i in range(len(data) - window_size - 24 + 1):\n",
    "        X.append(data[i:i + window_size])       # Input: Past 'window_size' hours\n",
    "        y.append(data[i + window_size: i + window_size + 24, 0]) # Target: Next 24 hours (Price only)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "WINDOW_SIZE = 48\n",
    "\n",
    "# Use the same scaled data from previous steps (train_scaled, test_scaled)\n",
    "X_train_24, y_train_24 = create_24h_window(train_scaled, WINDOW_SIZE)\n",
    "X_test_24, y_test_24 = create_24h_window(test_scaled, WINDOW_SIZE)\n",
    "\n",
    "# Split Validation\n",
    "val_split_24 = int(len(X_train_24) * 0.8)\n",
    "X_train_sub_24, y_train_sub_24 = X_train_24[:val_split_24], y_train_24[:val_split_24]\n",
    "X_val_24, y_val_24 = X_train_24[val_split_24:], y_train_24[val_split_24:]\n",
    "\n",
    "print(f\"Input Shape: {X_train_sub_24.shape}\")  # (Samples, 48, Features)\n",
    "print(f\"Target Shape: {y_train_sub_24.shape}\") # (Samples, 24) -> Vector of 24 prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO pobawić się parametrami\n",
    "\n",
    "# ==========================================\n",
    "# 2. LSTM Model for 24-Step Output\n",
    "# ==========================================\n",
    "model_24 = Sequential()\n",
    "model_24.add(Input(shape=(X_train_sub_24.shape[1], X_train_sub_24.shape[2])))\n",
    "\n",
    "# We can use a slightly larger network for this harder task\n",
    "model_24.add(LSTM(128, return_sequences=True))\n",
    "model_24.add(Dropout(0.2))\n",
    "model_24.add(LSTM(68, return_sequences=False))\n",
    "model_24.add(Dropout(0.2))\n",
    "\n",
    "# OUTPUT LAYER CHANGE:\n",
    "# Instead of 1 neuron, we need 24 neurons (one for each future hour)\n",
    "model_24.add(Dense(24))\n",
    "\n",
    "model_24.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 3. Training\n",
    "# ==========================================\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "history_24 = model_24.fit(\n",
    "    X_train_sub_24, y_train_sub_24,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(X_val_24, y_val_24),\n",
    "    callbacks=[early_stop], # Same callback as before\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 4. Evaluation (Complex for Multi-step)\n",
    "# ==========================================\n",
    "y_pred_scaled_24 = model_24.predict(X_test_24)\n",
    "\n",
    "# Inverse Transform\n",
    "# Since we predicted 24 values at once, we need to inverse transform carefully.\n",
    "# We will create a loop to inverse transform sample by sample or use a vectorized approach.\n",
    "# A simple way is to reuse the 'inverse_transform_target' concept but handle the 2D shape.\n",
    "\n",
    "# Create a placeholder matrix for inverse transformation\n",
    "# Shape: (Number of predictions * 24, Number of Features)\n",
    "# We flatten the predictions to treat them as a long list of single prices\n",
    "n_samples = y_pred_scaled_24.shape[0]\n",
    "n_steps = 24\n",
    "n_features = train_dfML.shape[1]\n",
    "\n",
    "# Reshape predictions to vertical list\n",
    "flat_preds = y_pred_scaled_24.reshape(-1, 1) # (Samples*24, 1)\n",
    "dummy_preds = np.zeros((len(flat_preds), n_features))\n",
    "dummy_preds[:, 0] = flat_preds.flatten()\n",
    "flat_real_preds = scaler.inverse_transform(dummy_preds)[:, 0]\n",
    "\n",
    "# Reshape back to (Samples, 24)\n",
    "y_pred_real_24 = flat_real_preds.reshape(n_samples, n_steps)\n",
    "\n",
    "# Do the same for actuals\n",
    "flat_actuals = y_test_24.reshape(-1, 1)\n",
    "dummy_actuals = np.zeros((len(flat_actuals), n_features))\n",
    "dummy_actuals[:, 0] = flat_actuals.flatten()\n",
    "flat_real_actuals = scaler.inverse_transform(dummy_actuals)[:, 0]\n",
    "y_test_real_24 = flat_real_actuals.reshape(n_samples, n_steps)\n",
    "\n",
    "# Calculate Metrics (Average over all 24 horizons)\n",
    "mae_24 = mean_absolute_error(y_test_real_24, y_pred_real_24)\n",
    "rmse_24 = np.sqrt(mean_squared_error(y_test_real_24, y_pred_real_24))\n",
    "\n",
    "# Robust MAPE\n",
    "mask_24 = y_test_real_24 != 0\n",
    "mape_24 = np.mean(np.abs((y_test_real_24[mask_24] - y_pred_real_24[mask_24]) / y_test_real_24[mask_24])) * 100\n",
    "\n",
    "print(f\"\\n24-Step Ahead Model Performance:\")\n",
    "print(f\"MAE:  {mae_24:.4f}\")\n",
    "print(f\"RMSE: {rmse_24:.4f}\")\n",
    "print(f\"MAPE: {mape_24:.4f}%\")\n",
    "\n",
    "# Plotting: Pick one random day (sample) to visualize the 24-hour curve\n",
    "sample_idx = 0 # First sample in test set\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(24), y_test_real_24[sample_idx], marker='o', label='Actual Day')\n",
    "plt.plot(range(24), y_pred_real_24[sample_idx], marker='x', linestyle='--', label='Predicted Day')\n",
    "plt.title(f'24-Hour Forecast for Sample #{sample_idx}')\n",
    "plt.xlabel('Hour of Day')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick Sanity Check\n",
    "print(\"Sample Target (First 24 hours to predict):\")\n",
    "print(y_train_24[0])\n",
    "\n",
    "# Check if we have too many zeros (which confuse the model)\n",
    "zeros_percent = (y_train_24 == 0).sum() / y_train_24.size * 100\n",
    "print(f\"Percentage of Zeros in Target Data: {zeros_percent:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO totalnie coś tu nie działa\n",
    "\n",
    "# ==========================================\n",
    "# Recursive Forecast Strategy (Better Shape)\n",
    "# ==========================================\n",
    "# Pick a random sample from the test set\n",
    "sample_idx = 0\n",
    "# Get the initial window (last 48 hours before the prediction starts)\n",
    "current_window = X_test[sample_idx].copy() # Shape: (48, features)\n",
    "\n",
    "recursive_predictions = []\n",
    "\n",
    "# Loop for 24 steps\n",
    "for i in range(24):\n",
    "    # 1. Predict the next ONE hour\n",
    "    # Reshape to (1, 48, features) for the model\n",
    "    next_pred_scaled = model.predict(current_window.reshape(1, WINDOW_SIZE, -1), verbose=0)\n",
    "\n",
    "    # Store the prediction (price is at index 0)\n",
    "    predicted_price = next_pred_scaled[0, 0]\n",
    "    recursive_predictions.append(predicted_price)\n",
    "\n",
    "    # 2. Update the Window for the next step\n",
    "    # We need to create a new row with [Predicted_Price, Future_Weather, ...]\n",
    "    # Since we don't have future weather in this simple loop, we can:\n",
    "    # Option A (Simple): Copy the weather from the last known step (Persistence)\n",
    "    # Option B (Better): If you have a test set with known future weather, grab it.\n",
    "\n",
    "    # Here we use Option A for simplicity:\n",
    "    new_row = current_window[-1].copy()\n",
    "    new_row[0] = predicted_price # Replace actual price with our predicted price\n",
    "\n",
    "    # Slide the window: Drop first hour, add new row at the end\n",
    "    current_window = np.vstack([current_window[1:], new_row])\n",
    "\n",
    "# ==========================================\n",
    "# Inverse Transform & Plotting\n",
    "# ==========================================\n",
    "# Convert list to array\n",
    "recursive_predictions = np.array(recursive_predictions).reshape(-1, 1)\n",
    "\n",
    "# Helper to inverse transform only the price column\n",
    "def inverse_price(predictions, scaler, n_features):\n",
    "    dummy = np.zeros((len(predictions), n_features))\n",
    "    dummy[:, 0] = predictions.flatten()\n",
    "    return scaler.inverse_transform(dummy)[:, 0]\n",
    "\n",
    "# Get Real Prices (Euros)\n",
    "pred_euros = inverse_price(recursive_predictions, scaler, train_dfML.shape[1])\n",
    "\n",
    "# Get Actual Prices for comparison (from y_test corresponding to sample_idx)\n",
    "# Note: You need to grab the correct 24 actual hours following sample_idx\n",
    "actual_euros = inverse_price(y_test[sample_idx:sample_idx+24], scaler, train_dfML.shape[1])\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(actual_euros, marker='o', label='Actual (Euros)')\n",
    "plt.plot(pred_euros, marker='x', linestyle='--', label='Recursive Prediction (Euros)')\n",
    "plt.title('Recursive 24-Hour Forecast')\n",
    "plt.ylabel('Price (€)')\n",
    "plt.xlabel('Hour')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139",
   "metadata": {},
   "source": [
    "Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Tuning Batch Size\n",
    "batch_sizes = [16, 32, 64]\n",
    "results = {}\n",
    "\n",
    "for bs in batch_sizes:\n",
    "    print(f\"Testing Batch Size: {bs}\")\n",
    "    # Re-build fresh model (to reset weights)\n",
    "    model = build_lstm_model(input_shape=(X_train.shape[1], X_train.shape[2]))\n",
    "\n",
    "    # Train\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=20, # Keep epochs lower for tuning to save time\n",
    "        batch_size=bs,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=[early_stop],\n",
    "        verbose=0 # Silent mode\n",
    "    )\n",
    "\n",
    "    # Store validation loss to compare\n",
    "    best_val_loss = min(history.history['val_loss'])\n",
    "    results[bs] = best_val_loss\n",
    "    print(f\"Batch Size {bs} - Best Val Loss: {best_val_loss:.5f}\")\n",
    "\n",
    "print(\"Best Configuration:\", min(results, key=results.get))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tunable_lstm(input_shape, units, num_layers, dropout_rate=0.2):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "\n",
    "    # First Layer (Always present)\n",
    "    # If num_layers is 1, return_sequences must be False. If >1, it must be True.\n",
    "    return_seq = (num_layers > 1)\n",
    "    model.add(LSTM(units=units, return_sequences=return_seq))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Second Layer (Conditional)\n",
    "    if num_layers == 2:\n",
    "        model.add(LSTM(units=units // 2, return_sequences=False))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Output Layer\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    optimizer = Adam(learning_rate=0.0001)\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Hyperparameter Tuning: Units & Layers\n",
    "# ==========================================\n",
    "\n",
    "# Define the grid of parameters to test\n",
    "# You can add more, but these are good starting points\n",
    "units_options = [32, 64, 128]\n",
    "layers_options = [1, 2]\n",
    "\n",
    "tuning_results = []\n",
    "\n",
    "print(\"Starting Hyperparameter Tuning...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for units in units_options:\n",
    "    for layers in layers_options:\n",
    "        print(f\"Testing: {units} Units | {layers} Layers...\")\n",
    "\n",
    "        # Build the specific model\n",
    "        model = build_tunable_lstm(\n",
    "            input_shape=(X_train.shape[1], X_train.shape[2]),\n",
    "            units=units,\n",
    "            num_layers=layers\n",
    "        )\n",
    "\n",
    "        # Train (Silent mode: verbose=0)\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=30, # Reduced epochs for faster tuning\n",
    "            batch_size=32, # Using your fixed best batch size\n",
    "            validation_data=(X_val, y_val),\n",
    "            callbacks=[early_stop],\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        # Get the best validation loss achieved during training\n",
    "        best_val_loss = min(history.history['val_loss'])\n",
    "\n",
    "        # Store result\n",
    "        tuning_results.append({\n",
    "            'units': units,\n",
    "            'layers': layers,\n",
    "            'val_loss': best_val_loss\n",
    "        })\n",
    "\n",
    "        print(f\"   -> Result: Best Val Loss = {best_val_loss:.5f}\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(\"Tuning Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert results to DataFrame for easy viewing\n",
    "results_df = pd.DataFrame(tuning_results)\n",
    "\n",
    "# Sort by lowest Validation Loss (best performance)\n",
    "results_df = results_df.sort_values(by='val_loss', ascending=True)\n",
    "\n",
    "print(\"\\nTop 3 Configurations:\")\n",
    "print(results_df.head(3))\n",
    "\n",
    "# Extract the winner\n",
    "best_config = results_df.iloc[0]\n",
    "print(f\"\\nWINNER: LSTM with {int(best_config['units'])} Units and {int(best_config['layers'])} Layers.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seasonal Naive: Predict value at time 't' using value at 't - 168' (7 days * 24 hours)\n",
    "seasonality = 168\n",
    "y_naive_pred = []\n",
    "y_naive_real = []\n",
    "\n",
    "# We can only predict for indices where we have data 168 hours ago\n",
    "# Using the test set (test_dfML)\n",
    "test_values = test_dfML.iloc[:, 0].values # Assuming price is col 0\n",
    "\n",
    "for i in range(seasonality, len(test_values)):\n",
    "    y_naive_pred.append(test_values[i - seasonality])\n",
    "    y_naive_real.append(test_values[i])\n",
    "\n",
    "# Calculate Metrics for Baseline\n",
    "mae_naive = mean_absolute_error(y_naive_real, y_naive_pred)\n",
    "rmse_naive = np.sqrt(mean_squared_error(y_naive_real, y_naive_pred))\n",
    "print(f\"Baseline (Seasonal Naive) - MAE: {mae_naive:.4f}, RMSE: {rmse_naive:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Conclusions and Recommendations\n",
    "\n",
    "### 6.1 Summary of Findings\n",
    "\n",
    "\n",
    "### 6.2 Best Model Selection\n",
    "\n",
    "### 6.3 Future Work\n",
    "\n",
    "\n",
    "### 6.4 Lessons Learned\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146",
   "metadata": {},
   "source": [
    "## Project Notes and Team Collaboration\n",
    "\n",
    "### Team Members\n",
    "\n",
    "- Julia Kardasz 1250264\n",
    "- Mateusz Nowak 1250296\n",
    "- Emilia Pawlowska 1250230"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
