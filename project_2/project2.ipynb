{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "702a5a61",
   "metadata": {},
   "source": [
    "#  Project\n",
    "\n",
    "**Project Goal:** \n",
    "\n",
    "**Dataset Period:**\n",
    "\n",
    "**Methodology:** \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebcd2ac",
   "metadata": {},
   "source": [
    "## 1. Business Understanding\n",
    "\n",
    "### 1.1 Business Objectives\n",
    "TODO\n",
    "\n",
    "### 1.2 Project Goals and Successs Criteria\n",
    "TODO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9613486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import math\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac81952",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Data Understanding\n",
    "\n",
    "### 2.1 Data Collection\n",
    "\n",
    "The first step is to load the datasets into the working environment. This involves importing the necessary libraries and reading the data file into a suitable data structure, namely, a DataFrame using Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd8ec37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "weather = pd.read_csv(\"weather.csv\", parse_dates=[\"time\"])\n",
    "energy = pd.read_csv(\"energy_dataset.csv\", parse_dates=[\"time\"])\n",
    "\n",
    "# Set 'time' as index\n",
    "weather = weather.set_index(\"time\")\n",
    "energy = energy.set_index(\"time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ad4fb2",
   "metadata": {},
   "source": [
    "### 2.2 Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa94635",
   "metadata": {},
   "source": [
    "##### Basic dataset information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435db824",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbac3a4a",
   "metadata": {},
   "source": [
    "The *energy* dataset contains 35064 entries and 24 features, representing hourly records of electricity generation from various sources, total system load, and the day-ahead market price. Each row corresponds to one hour of energy system operation, and the goal is to forecast the electricity price one hour and one day ahead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ea04a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b7b790",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c49fde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49fd4c8",
   "metadata": {},
   "source": [
    "The *weather* dataset also contains 35064 entries and 5 features representing hourly meteorological measurements such as temperature, pressure, humidity, and wind speed. Each row corresponds to one hour of weather conditions, and these variables are used as exogenous inputs to improve electricity price forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a93d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d550f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741e3c0d",
   "metadata": {},
   "source": [
    "### 2.3 Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9a1e11",
   "metadata": {},
   "source": [
    "#### 2.3.1 Target variable analysis\n",
    "\n",
    "The target variable `price_day_ahead` represents the eletricity market price for the upcoming hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9bdfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.hist(energy['price_day_ahead'], bins=50, edgecolor='black')\n",
    "plt.title(\"Histogram of Day-Ahead Electricity Price\")\n",
    "plt.xlabel(\"Price (€/MWh)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e8d5a1",
   "metadata": {},
   "source": [
    "The histogram shows a distribution that is very close to a normal distribution, although it is slightly right-skewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99557dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(energy['price_day_ahead'])\n",
    "plt.title(\"Time Series of Electricity Price (Day-Ahead)\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Price (€/MWh)\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b423a86",
   "metadata": {},
   "source": [
    "The time series plot shows strong short-term fluctuations and clear seasonal patterns, with occasional price spikes. Prices vary over time, indicating non-stationarity and the presence of both volatility and periodic behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30770685",
   "metadata": {},
   "source": [
    "#### 2.3.2 Feature distribution analysis\n",
    "\n",
    "Now we will perform feature distribution analysis to examine how the data values are spread across the datasets. We will use plots and histograms to visualise the distributions features. Box plots for will be skipped in this step, as they will be specifically used for outlier detection in paragraph `2.4.2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf1aaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_distribution(nonDiscreteFeatures, df):\n",
    "    nrows = math.ceil(len(nonDiscreteFeatures) / 2)\n",
    "    ncols = 2\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(16, nrows * 5))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, col in enumerate(nonDiscreteFeatures):\n",
    "        df[col].hist(bins=30, ax=axes[i])\n",
    "        axes[i].set_title(f'{col} Distribution')\n",
    "        axes[i].set_xlabel(col)\n",
    "        axes[i].set_ylabel('Frequency')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57035135",
   "metadata": {},
   "source": [
    "All of the features are numerical and continuous."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6357e0",
   "metadata": {},
   "source": [
    "##### Energy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2727235e",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_features = [col for col in energy.columns \n",
    "                   if col not in ['time', 'price_day_ahead']]\n",
    "feat_distribution(energy_features, energy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3842816",
   "metadata": {},
   "source": [
    "None of the features has a normal distribution. `generation_hydro_pumped_storage_consumption`, `generation_hydro_water_reservoir`, and `generation_solar` are strongly right-skewed, while `generation_wind_onshore` is moderately right-skewed. In contrast, `generation_waste` is left-skewed.\n",
    "Variables with skewed distributions will be handled in paragraph 3.4.3, because skewness can negatively affect the models used later in paragraph 4.2, particularly KNN, SVR, and Linear Regression, which rely on distance metrics or assumptions of linearity.\n",
    "\n",
    "`generation_marine`, `generation_geothermal`, `generation_fossil_oil_shale`, `generation_fossil_peat`, and `generation_fossil_coal-derived_gas` contain only zeros, which is consistent with the dataset description provided in paragraph 2.2.\n",
    "\n",
    "The data represented by the remaining variables generally show irregular, multimodal, or heavily skewed shapes, reflecting the diverse and highly variable nature of electricity generation across different sources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19938a67",
   "metadata": {},
   "source": [
    "##### Weather dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fd834c",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_features = [col for col in weather.columns if col != 'time']\n",
    "feat_distribution(weather_features, weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310226ca",
   "metadata": {},
   "source": [
    "`temperature` and `pressure` distribution is close to normal, whereas `humidity` is slightly left-skewed and `wind_speed` is right-skewed.\n",
    "\n",
    "Skeweness will be handled in paragraph DOK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b296c7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "skewed_cols = ['generation_hydro_pumped_storage_consumption','generation_hydro_water_reservoir','generation_solar','generation_wind_onshore','generation_waste','wind_speed']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6ebe76",
   "metadata": {},
   "source": [
    "### 2.4 Data Quality Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c922266c",
   "metadata": {},
   "source": [
    "#### 2.4.1 Identify missing values\n",
    "\n",
    "In the first place, we will check for missing values to ensure data completeness and avoid potential issues during analysis and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6d6d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# % missing values by column\n",
    "\n",
    "def missing_values_info(df):\n",
    "    nulls = df.isnull().sum()\n",
    "    percent = round(nulls / df.shape[0] * 100, 3)\n",
    "    \n",
    "    nullvalues = pd.concat([nulls, percent], axis=1)\n",
    "    nullvalues.columns = [\"Count\", \"%\"]\n",
    "    \n",
    "    return nullvalues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d6a4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_info(energy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76821270",
   "metadata": {},
   "source": [
    "The proportion of missing values varies across the energy-generation features. Most variables contain only a very small fraction of missing entries (around 0.05% each), including `generation_biomass`, `generation_fossil_gas`, `generation_solar`, `generation_wind_onshore`, and many others.\n",
    "A few features have slightly higher but still low missing rates, such as `generation_nuclear` at 0.048% and `total_load_actual` at 0.103%.\n",
    "\n",
    "Two variables — `generation_hydro_pumped_storage_aggregated` and `forecast_wind_offshore_eday_ahead` — have 100% missing values, meaning they contain no usable data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba8ad65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skipping the NaNs\n",
    "energy_features = [\n",
    "    f for f in energy_features\n",
    "    if energy[f].notna().sum() > 0\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c2c31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_info(weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7cdb60",
   "metadata": {},
   "source": [
    "There are no missing values in `weather` dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90f1656",
   "metadata": {},
   "source": [
    "#### 2.4.2 Identify outliers\n",
    "\n",
    "Based on dataframes information in paragraph `2.2` there might be potential outliers such as values at the extreme ends of the distributions (e.g., very high generation levels or unusually low/high prices). These points can disproportionately influence analysis and model results. That's why now we will identify outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e193c6e7",
   "metadata": {},
   "source": [
    "##### 2.4.2.1 Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede69c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,5))\n",
    "plt.boxplot(\n",
    "    energy['price_day_ahead'],\n",
    "    vert=True,\n",
    "    patch_artist=True,\n",
    "    boxprops=dict(facecolor='lightblue', color='blue'),\n",
    "    medianprops=dict(color='red'),\n",
    "    whiskerprops=dict(color='blue'),\n",
    "    capprops=dict(color='blue'),\n",
    "    flierprops=dict(marker='o', markersize=4, markerfacecolor='blue')\n",
    ")\n",
    "plt.title(\"Boxplot of Day-Ahead Electricity Price\")\n",
    "plt.ylabel(\"Price (€/MWh)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9e2571",
   "metadata": {},
   "source": [
    "The boxplot shows clear price spikes, confirming the presence of outliers in the target variable. These extreme values reflect real market volatility but may negatively affect several forecasting models. Therefore, while they are kept in the dataset, they will be handled later in paragraph `3.4.3` DOK through appropriate preprocessing to minimise their impact on model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78663e1",
   "metadata": {},
   "source": [
    "##### 2.4.2.2 Energy features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82f7988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplots(numeric_features, df):\n",
    "    num_plots = len(numeric_features)\n",
    "    cols = 2\n",
    "    rows = math.ceil(num_plots / cols)\n",
    "\n",
    "    plt.figure(figsize=(cols * 5, rows * 4))\n",
    "\n",
    "    for i, feature in enumerate(numeric_features):\n",
    "        plt.subplot(rows, cols, i + 1)\n",
    "        sns.boxplot(y=df[feature])\n",
    "        plt.title(f\"Boxplot: {feature}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def outliers_detection(numericFeatures, df):\n",
    "    Q1 = df[numericFeatures].quantile(0.25)\n",
    "    Q3 = df[numericFeatures].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    outliers = ((df[numericFeatures] < (Q1 - 1.5 * IQR)) | (df[numericFeatures] > (Q3 + 1.5 * IQR)))\n",
    "    print(\"Number of outliers per numeric feature:\")\n",
    "    print(outliers.sum())\n",
    "\n",
    "    outliers_cols = outliers.any()\n",
    "    outliers_cols = outliers_cols[outliers_cols].index.tolist()\n",
    "    print(\"\\nColumns containing outliers:\")\n",
    "    print(outliers_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c21b818",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplots(energy_features, energy)\n",
    "outliers_detection(energy_features, energy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cee5a6a",
   "metadata": {},
   "source": [
    "We performed outliers detection on all numerical features using the Interquartile Range (IQR) method and visualized it using boxplots.\n",
    "\n",
    "Features such as `generation_fossil_gas`, `generation_hydro_pumped_storage_consumption` and `generation_other` contain a high number of outlier values.\n",
    "`generation_wind_onshore`, `generation_waste`,`generation_hydro_water_reservoir` and `generation_fossil_oil` also contained a noticeable number out outliers.\n",
    "`generation_biomass` contains a few outliers.\n",
    "The rest of the features of `energy` dataset showed no outliers according to the IQR method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecca92d",
   "metadata": {},
   "source": [
    "##### 2.4.2.3 Weather features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2333f0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplots(weather_features, weather)\n",
    "outliers_detection(weather_features, weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e03d54",
   "metadata": {},
   "source": [
    "`pressure` and `wind_speed` contain a noticeable number of outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17f48e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_cols = ['pressure', \n",
    "                 'wind_speed', \n",
    "                 'generation_fossil_gas', \n",
    "                 'generation_hydro_pumped_storage_consumption', \n",
    "                 'generation_other', \n",
    "                 'generation_wind_onshore', \n",
    "                 'generation_waste',\n",
    "                 'generation_hydro_water_reservoir',\n",
    "                 'generation_biomass',\n",
    "                 'generation_fossil_oil' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db7ee31",
   "metadata": {},
   "source": [
    "#### 2.4.3 Check data duplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f897901f",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy.index.duplicated().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575a221c",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.index.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04217000",
   "metadata": {},
   "source": [
    "There are no duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af05f28c",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Data Preparation\n",
    "\n",
    "### 3.1 Data Cleaning\n",
    "\n",
    "#### 3.1.1 Missing values\n",
    "\n",
    "The first thing to be perfomed is to handle missing values indicated in paragraph `2.4.1`.\n",
    "\n",
    "The missing values cannot be romoved that's why the NaNs will be filled in and columns only with NaNs will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbf34ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Remaining NaNs in energy:\", energy.isna().sum().sum())\n",
    "\n",
    "# Drop columns that contain only NaN values\n",
    "energy = energy.dropna(axis=1, how='all')\n",
    "\n",
    "# Interpolate missing values (time-series aware)\n",
    "energy.index = pd.to_datetime(energy.index, errors='coerce', utc=True)\n",
    "energy = energy.interpolate(method='time')\n",
    "\n",
    "# Forward-fill remaining NaNs (edge cases)\n",
    "energy = energy.ffill().bfill()\n",
    "\n",
    "print(\"Remaining NaNs in energy:\", energy.isna().sum().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45092e73",
   "metadata": {},
   "source": [
    "#### 3.1.2 Handling outliers\n",
    "\n",
    "To remove outliers identified in paragraph `2.4.2` we will perform winsorization and use **Robust Scaler** during `Data Transformation` in paragraph `3.3`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4eb9fd",
   "metadata": {},
   "source": [
    "### 3.2 Bivariate analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce303e26",
   "metadata": {},
   "source": [
    "Here we will skip features that consist only of values 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b86e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis = energy.join(weather, how=\"inner\")\n",
    "\n",
    "# remove columns that are entirely zero\n",
    "non_zero_cols = df_analysis.columns[(df_analysis != 0).any()]\n",
    "\n",
    "# keep only numeric features\n",
    "num_df = df_analysis[non_zero_cols].select_dtypes(include=\"number\")\n",
    "\n",
    "# compute correlation with price\n",
    "corr = num_df.corr()[\"price_day_ahead\"].drop(labels=[\"price_day_ahead\"]).sort_values()\n",
    "\n",
    "plt.figure(figsize=(8,12))\n",
    "corr.plot(kind=\"barh\")\n",
    "plt.title(\"Correlation with Day-Ahead Price\")\n",
    "plt.xlabel(\"Correlation\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2939dd",
   "metadata": {},
   "source": [
    "The diagram shows that some variables are correlated positively, some nagetively and some are only slightly or not correlated with the target variable at all."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70543979",
   "metadata": {},
   "source": [
    "#### Correlation between the eletricity price and the day of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b3e5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(energy.index))\n",
    "# print(energy.index[:5])\n",
    "\n",
    "weekday_price = energy['price_day_ahead'].groupby(energy.index.to_series().dt.dayofweek).mean()\n",
    "print(weekday_price)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "weekday_price.plot(kind='bar')\n",
    "plt.title(\"Average Day-Ahead Electricity Price by Day of the Week\")\n",
    "plt.ylabel(\"Price (€/MWh)\")\n",
    "plt.xlabel(\"Day of Week (0=Mon, 6=Sun)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805ca102",
   "metadata": {},
   "source": [
    "There's no strong dependency between the day of the week and the eletricity price, however the price tends to be lower on the weekends."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317c14d8",
   "metadata": {},
   "source": [
    "##### Correlation between the temperature and the eletricity price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b3d9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_analysis[\"temperature\"]\n",
    "y = df_analysis[\"price_day_ahead\"]\n",
    "\n",
    "# smooth curve\n",
    "low = lowess(y, x, frac=0.15)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(x, y, s=5, alpha=0.1)\n",
    "plt.plot(low[:,0], low[:,1], linewidth=3)\n",
    "\n",
    "plt.title(\"LOWESS Smoothed Relationship: Temperature vs Price\")\n",
    "plt.xlabel(\"Temperature (K)\")\n",
    "plt.ylabel(\"Day-Ahead Price (€/MWh)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54314095",
   "metadata": {},
   "source": [
    "There's no significant correlation between the eletricity price and the temperature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546cd91c",
   "metadata": {},
   "source": [
    "### 3.3 Data Transformation\n",
    "\n",
    "Since all the features are numerical they don't have to be encoded in any way.\n",
    "\n",
    "#### 3.3.1 Dropping unnecessary variables\n",
    "\n",
    "There are variables with all 0 values. They will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5835f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = energy.join(weather, how=\"inner\")\n",
    "\n",
    "dfML = df.copy()\n",
    "\n",
    "zero_cols = dfML.columns[(dfML == 0).all()]\n",
    "print(\"Dropped columns with all zeros:\", list(zero_cols))\n",
    "\n",
    "dfML = dfML.drop(columns=zero_cols)\n",
    "\n",
    "dfML.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3e898d",
   "metadata": {},
   "source": [
    "\n",
    "#### 3.3.1 Handling variables with skewed distribution\n",
    "\n",
    "Since not all of the skewed distrubutions concern variables with positive values we will use **Yeo-Johnson** scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52b657b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast to float before transformation to avoid dtype issues\n",
    "dfML = dfML.copy()\n",
    "\n",
    "for col in skewed_cols:\n",
    "    dfML[col] = dfML[col].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad35b1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = PowerTransformer(method='yeo-johnson')\n",
    "\n",
    "print(df[skewed_cols].dtypes)\n",
    "\n",
    "dfML.loc[:, skewed_cols] = pt.fit_transform(dfML.loc[:, skewed_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c7a8e3",
   "metadata": {},
   "source": [
    "#### 3.3.2 Handling outliers\n",
    "\n",
    "As indicated in paragraph `3.1`, we will use **Robust Scaler** to handle outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12245e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = RobustScaler()\n",
    "\n",
    "print(outliers_cols)\n",
    "print(type(outliers_cols))\n",
    "\n",
    "# Fit the scaler on the numeric features and transform\n",
    "dfML.loc[:,outliers_cols] = scaler.fit_transform(dfML[outliers_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdf68d6",
   "metadata": {},
   "source": [
    "### 3.4 Data Splitting\n",
    "\n",
    "To evaluate the models used in paragraph `4` we have to split dataset into a train and a test set. We will use an 75/25 split ratio (the whole dataset represents 4 years of data and the test set will consist of last 12 months) to ensure sufficient amount of data for training while retaining enough samples for meaningful evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e96aa765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split date: 2017-12-31 22:00:00+00:00\n",
      "Train: (26304, 20)\n",
      "Test: (8760, 20)\n"
     ]
    }
   ],
   "source": [
    "# Last 12 months for test\n",
    "split_date = dfML.index.max() - pd.DateOffset(years=1)\n",
    "\n",
    "train = dfML[dfML.index <= split_date]\n",
    "test  = dfML[dfML.index > split_date]\n",
    "\n",
    "print(\"Split date:\", split_date)\n",
    "print(\"Train:\", train.shape)\n",
    "print(\"Test:\", test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d807cd",
   "metadata": {},
   "source": [
    "### 3.5 Feature selection\n",
    "\n",
    "#### Embedded method - Lasso regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34259fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_regularization(df):\n",
    "\n",
    "    X = df.iloc[:,:-1].copy()          \n",
    "    y = df.iloc[:,-1].copy() \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    # fit a Logistic Regression model and feature selection altogether \n",
    "    # select the Lasso (l1) penalty.\n",
    "    # The selectFromModel class from sklearn, selects the features which coefficients are non-zero\n",
    "\n",
    "    sel_ = SelectFromModel(LogisticRegression(C=0.5, penalty='l1', solver='liblinear', random_state=10))\n",
    "\n",
    "    sel_.fit(scaler.transform(X_train), y_train)\n",
    "\n",
    "    # make a list with the selected features\n",
    "    selected_feat = X_train.columns[(sel_.get_support())]\n",
    "    \n",
    "    print(\"Number of features which coefficient was shrank to zero: \", np.sum(sel_.estimator_.coef_ == 0))\n",
    "    # identify the removed features like this:\n",
    "    removed_feats = X_train.columns[(sel_.estimator_.coef_ == 0).ravel().tolist()]\n",
    "    print('Removed features by Lasso: ',removed_feats) \n",
    "\n",
    "    return X_train.columns[(sel_.estimator_.coef_ != 0).ravel().tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5593c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lasso_SelectedColumns = lasso_regularization(train_dfML)\n",
    "\n",
    "Lasso_SelectedColumns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e4ca55",
   "metadata": {},
   "source": [
    "print(f\"Removed features by Filter methods: {FilterColumns}\")\n",
    "\n",
    "df1 = train_dfML.copy()\n",
    "df1_imbalance = train_imbalance.copy()\n",
    "\n",
    "print(df1.columns.tolist())\n",
    "\n",
    "df1.drop(columns=FilterColumns, axis=1, inplace=True)\n",
    "df1_imbalance.drop(columns=FilterColumns, axis=1, inplace=True)\n",
    "\n",
    "df1_test = test_dfML.copy()\n",
    "df1_test.drop(columns=FilterColumns, axis=1, inplace=True)\n",
    "\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce48348c",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a777ba0",
   "metadata": {},
   "source": [
    "With these methods, we prepared a dataframes for future testing and tuning to compare different models and select the one with the best performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef51de0",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Modelling\n",
    "\n",
    "### 4.1 Statistical Models\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cfcca5",
   "metadata": {},
   "source": [
    "### 4.2 Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4fe759",
   "metadata": {},
   "source": [
    "#### 3.5.2 Embedded method - Lasso regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d8be7d",
   "metadata": {},
   "source": [
    "### 4.3 Deep Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6f8e0c",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Conclusions and Recommendations\n",
    "\n",
    "### 6.1 Summary of Findings\n",
    "\n",
    "\n",
    "### 6.2 Best Model Selection\n",
    "\n",
    "### 6.3 Future Work\n",
    "\n",
    "\n",
    "### 6.4 Lessons Learned\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21e6fe3",
   "metadata": {},
   "source": [
    "## Project Notes and Team Collaboration\n",
    "\n",
    "### Team Members\n",
    "\n",
    "- Julia Kardasz 1250264\n",
    "- Mateusz Nowak 1250296\n",
    "- Emilia Pawlowska 1250230"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
