{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "#  Electricity Price Forecasting – Comparative Modeling Project\n",
    "\n",
    "**Project Goal:** Develop and compare statistical, machine learning, and deep learning models to forecast hourly electricity prices one-step ahead and 24-steps ahead.\n",
    "\n",
    "**Dataset Period:** 2015–2018 (4 years of hourly electricity prices, energy generation, and weather data)\n",
    "\n",
    "**Methodology:** CRISP-DM (Cross-Industry Standard Process for Data Mining)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## 1. Business Understanding\n",
    "\n",
    "### 1.1 Business Objectives\n",
    "Electricity is a critical resource for modern societies, and its price directly affects consumers, producers, and energy market participants. With the liberalization of electricity markets, prices fluctuate on an hourly basis depending on supply, demand, weather conditions, and generation sources. These fluctuations introduce uncertainty for grid operators, energy traders, and policy makers, making accurate price forecasting an essential task.\n",
    "\n",
    "The objective of this project is to develop and compare different forecasting models capable of predicting electricity prices one hour ahead and one day ahead (24 hours). By leveraging historical electricity prices together with exogenous variables related to energy generation and weather conditions, the models aim to capture both short-term dynamics and daily seasonal patterns. Accurate forecasts can support better decision-making in energy trading, grid management, and operational planning, ultimately contributing to market efficiency and system stability.\n",
    "\n",
    "### 1.2 Project Goals and Successs Criteria\n",
    "From a data mining perspective, this problem is formulated as a time-series regression task, where the target variable is the electricity price at future time steps. The models are trained using four years of hourly data (2015–2018), with the final 12 months reserved as an out-of-sample test set to realistically evaluate forecasting performance.\n",
    "\n",
    "The main goal of the project is not only to produce accurate forecasts, but also to compare different modelling paradigms, including statistical models, machine learning models, and deep learning models, under the same experimental setup. This comparative analysis allows us to assess the trade-offs between accuracy, stability, complexity, and interpretability.\n",
    "\n",
    "Model performance is evaluated using standard regression error metrics: Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), and Mean Absolute Percentage Error (MAPE). Additionally, all models are compared against a Seasonal Naïve baseline to ensure that improvements are meaningful and not trivial.\n",
    "\n",
    "The success criteria for this project are defined as follows:\n",
    "- Achieving a clear improvement over the Seasonal Naïve baseline for both 1-step and 24-step forecasts\n",
    "- Maintaining stable performance across time-series cross-validation folds\n",
    "- Producing forecasts that follow the main temporal patterns and seasonality of electricity prices\n",
    "- Balancing predictive performance with computational efficiency, especially for multi-step forecasting\n",
    "- Ensuring that the selected model is practical and interpretable enough to be used in real-world energy forecasting scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "from sklearn.preprocessing import PowerTransformer, RobustScaler, StandardScaler, PowerTransformer\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import Lasso, LogisticRegression, LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer, mean_squared_error, mean_absolute_percentage_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.base import clone\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import (\n",
    "    BaggingRegressor,\n",
    "    GradientBoostingRegressor,\n",
    "    RandomForestRegressor,\n",
    ")\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "import math\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.graphics.tsaplots import plot_pacf, plot_acf\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "import scipy.stats as stats\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Data Understanding\n",
    "\n",
    "### 2.1 Data Collection\n",
    "\n",
    "The first step is to load the datasets into the working environment. This involves importing the necessary libraries and reading the data file into a suitable data structure, namely, a DataFrame using Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "weather = pd.read_csv(\"weather.csv\", parse_dates=[\"time\"])\n",
    "energy = pd.read_csv(\"energy_dataset.csv\", parse_dates=[\"time\"])\n",
    "\n",
    "# Set 'time' as index\n",
    "weather = weather.set_index(\"time\")\n",
    "energy = energy.set_index(\"time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### 2.2 Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "##### Basic dataset information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "The *energy* dataset contains 35064 entries and 24 features, representing hourly records of electricity generation from various sources, total system load, and the day-ahead market price. Each row corresponds to one hour of energy system operation, and the goal is to forecast the electricity price one hour and one day ahead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "The *weather* dataset also contains 35064 entries and 5 features representing hourly meteorological measurements such as temperature, pressure, humidity, and wind speed. Each row corresponds to one hour of weather conditions, and these variables are used as exogenous inputs to improve electricity price forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### 2.3 Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "#### 2.3.1 Target variable analysis\n",
    "\n",
    "The target variable `price_day_ahead` represents the eletricity market price for the upcoming hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col='price_day_ahead'\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.hist(energy[target_col], bins=50, edgecolor='black')\n",
    "plt.title(\"Histogram of Day-Ahead Electricity Price\")\n",
    "plt.xlabel(\"Price (€/MWh)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "The histogram shows a distribution that is very close to a normal distribution, although it is slightly right-skewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(energy[target_col])\n",
    "plt.title(\"Time Series of Electricity Price (Day-Ahead)\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Price (€/MWh)\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "The time series plot shows strong short-term fluctuations and clear seasonal patterns, with occasional price spikes. Prices vary over time, indicating non-stationarity and the presence of both volatility and periodic behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "#### 2.3.2 Feature distribution analysis\n",
    "\n",
    "Now we will perform feature distribution analysis to examine how the data values are spread across the datasets. We will use plots and histograms to visualise the distributions features. Box plots for will be skipped in this step, as they will be specifically used for outlier detection in paragraph `2.4.2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_distribution(nonDiscreteFeatures, df):\n",
    "    nrows = math.ceil(len(nonDiscreteFeatures) / 2)\n",
    "    ncols = 2\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(16, nrows * 5))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, col in enumerate(nonDiscreteFeatures):\n",
    "        df[col].hist(bins=30, ax=axes[i])\n",
    "        axes[i].set_title(f'{col} Distribution')\n",
    "        axes[i].set_xlabel(col)\n",
    "        axes[i].set_ylabel('Frequency')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "All of the features are numerical and continuous."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "##### Energy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_features = [col for col in energy.columns \n",
    "                   if col not in ['time', 'price_day_ahead']]\n",
    "feat_distribution(energy_features, energy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "None of the features has a normal distribution. `generation_hydro_pumped_storage_consumption`, `generation_hydro_water_reservoir`, and `generation_solar` are strongly right-skewed, while `generation_wind_onshore` is moderately right-skewed. In contrast, `generation_waste` is left-skewed.\n",
    "Variables with skewed distributions will be handled in paragraph `3.4.3`, because skewness can negatively affect the models used later in paragraph `4.2`, particularly KNN, SVR, and Linear Regression, which rely on distance metrics or assumptions of linearity.\n",
    "\n",
    "`generation_marine`, `generation_geothermal`, `generation_fossil_oil_shale`, `generation_fossil_peat`, and `generation_fossil_coal-derived_gas` contain only zeros, which is consistent with the dataset description provided in paragraph `2.2`.\n",
    "\n",
    "The data represented by the remaining variables generally show irregular, multimodal, or heavily skewed shapes, reflecting the diverse and highly variable nature of electricity generation across different sources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "##### Weather dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_features = [col for col in weather.columns if col != 'time']\n",
    "feat_distribution(weather_features, weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "`temperature` and `pressure` distribution is close to normal, whereas `humidity` is slightly left-skewed and `wind_speed` is right-skewed.\n",
    "\n",
    "Skeweness will be handled in paragraph `3.3.1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "skewed_cols = ['generation_hydro_pumped_storage_consumption','generation_hydro_water_reservoir','generation_solar','generation_wind_onshore','generation_waste','wind_speed']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "### 2.4 Data Quality Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "#### 2.4.1 Identify missing values\n",
    "\n",
    "In the first place, we will check for missing values to ensure data completeness and avoid potential issues during analysis and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# % missing values by column\n",
    "\n",
    "def missing_values_info(df):\n",
    "    nulls = df.isnull().sum()\n",
    "    percent = round(nulls / df.shape[0] * 100, 3)\n",
    "    \n",
    "    nullvalues = pd.concat([nulls, percent], axis=1)\n",
    "    nullvalues.columns = [\"Count\", \"%\"]\n",
    "    \n",
    "    return nullvalues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_info(energy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "The proportion of missing values varies across the energy-generation features. Most variables contain only a very small fraction of missing entries (around 0.05% each), including `generation_biomass`, `generation_fossil_gas`, `generation_solar`, `generation_wind_onshore`, and many others.\n",
    "A few features have slightly higher but still low missing rates, such as `generation_nuclear` at 0.048% and `total_load_actual` at 0.103%.\n",
    "\n",
    "Two variables — `generation_hydro_pumped_storage_aggregated` and `forecast_wind_offshore_eday_ahead` — have 100% missing values, meaning they contain no usable data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skipping the NaNs\n",
    "energy_features = [\n",
    "    f for f in energy_features\n",
    "    if energy[f].notna().sum() > 0\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_info(weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "There are no missing values in `weather` dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "#### 2.4.2 Identify outliers\n",
    "\n",
    "Based on dataframes information in paragraph `2.2` there might be potential outliers such as values at the extreme ends of the distributions (e.g., very high generation levels or unusually low/high prices). These points can disproportionately influence analysis and model results. That's why now we will identify outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Rolling Window Analysis: calculate rolling mean and standard deviation. Values\n",
    "that deviate significantly from the rolling mean (e.g., beyond ±3 standard\n",
    "deviations) may be considered outliers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "##### 2.4.2.1 Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,5))\n",
    "plt.boxplot(\n",
    "    energy[target_col],\n",
    "    vert=True,\n",
    "    patch_artist=True,\n",
    "    boxprops=dict(facecolor='lightblue', color='blue'),\n",
    "    medianprops=dict(color='red'),\n",
    "    whiskerprops=dict(color='blue'),\n",
    "    capprops=dict(color='blue'),\n",
    "    flierprops=dict(marker='o', markersize=4, markerfacecolor='blue')\n",
    ")\n",
    "plt.title(\"Boxplot of Day-Ahead Electricity Price\")\n",
    "plt.ylabel(\"Price (€/MWh)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "The boxplot shows clear price spikes, confirming the presence of outliers in the target variable. These extreme values reflect real market volatility but may negatively affect several forecasting models. Therefore, while they are kept in the dataset, they will be handled later in paragraph `3.4.3` through appropriate preprocessing to minimise their impact on model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "##### 2.4.2.2 Energy features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplots(numeric_features, df):\n",
    "    num_plots = len(numeric_features)\n",
    "    cols = 2\n",
    "    rows = math.ceil(num_plots / cols)\n",
    "\n",
    "    plt.figure(figsize=(cols * 5, rows * 4))\n",
    "\n",
    "    for i, feature in enumerate(numeric_features):\n",
    "        plt.subplot(rows, cols, i + 1)\n",
    "        sns.boxplot(y=df[feature])\n",
    "        plt.title(f\"Boxplot: {feature}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def outliers_detection(numericFeatures, df):\n",
    "    Q1 = df[numericFeatures].quantile(0.25)\n",
    "    Q3 = df[numericFeatures].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    outliers = ((df[numericFeatures] < (Q1 - 1.5 * IQR)) | (df[numericFeatures] > (Q3 + 1.5 * IQR)))\n",
    "    print(\"Number of outliers per numeric feature:\")\n",
    "    print(outliers.sum())\n",
    "\n",
    "    outliers_cols = outliers.any()\n",
    "    outliers_cols = outliers_cols[outliers_cols].index.tolist()\n",
    "    print(\"\\nColumns containing outliers:\")\n",
    "    print(outliers_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplots(energy_features, energy)\n",
    "outliers_detection(energy_features, energy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "We performed outliers detection on all numerical features using the Interquartile Range (IQR) method and visualized it using boxplots.\n",
    "\n",
    "Features such as `generation_fossil_gas`, `generation_hydro_pumped_storage_consumption` and `generation_other` contain a high number of outlier values.\n",
    "`generation_wind_onshore`, `generation_waste`,`generation_hydro_water_reservoir` and `generation_fossil_oil` also contained a noticeable number out outliers.\n",
    "`generation_biomass` contains a few outliers.\n",
    "The rest of the features of `energy` dataset showed no outliers according to the IQR method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "##### 2.4.2.3 Weather features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplots(weather_features, weather)\n",
    "outliers_detection(weather_features, weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "`pressure` and `wind_speed` contain a noticeable number of outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_cols = ['pressure', \n",
    "                 'wind_speed', \n",
    "                 'generation_fossil_gas', \n",
    "                 'generation_hydro_pumped_storage_consumption', \n",
    "                 'generation_other', \n",
    "                 'generation_wind_onshore', \n",
    "                 'generation_waste',\n",
    "                 'generation_hydro_water_reservoir',\n",
    "                 'generation_biomass',\n",
    "                 'generation_fossil_oil' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "#### 2.4.3 Check data duplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy.index.duplicated().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.index.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "There are no duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Data Preparation\n",
    "\n",
    "### 3.1 Data Cleaning\n",
    "\n",
    "#### 3.1.1 Missing values\n",
    "\n",
    "The first thing to be perfomed is to handle missing values indicated in paragraph `2.4.1`.\n",
    "\n",
    "The missing values cannot be romoved that's why the NaNs will be filled in and columns only with NaNs will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Remaining NaNs in energy:\", energy.isna().sum().sum())\n",
    "\n",
    "# Drop columns that contain only NaN values\n",
    "energy = energy.dropna(axis=1, how='all')\n",
    "\n",
    "# Interpolate missing values (time-series aware)\n",
    "energy.index = pd.to_datetime(energy.index, errors='coerce', utc=True)\n",
    "energy = energy.interpolate(method='time')\n",
    "\n",
    "# Forward-fill remaining NaNs (edge cases)\n",
    "energy = energy.ffill().bfill()\n",
    "\n",
    "print(\"Remaining NaNs in energy:\", energy.isna().sum().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58",
   "metadata": {},
   "source": [
    "#### 3.1.2 Handling outliers\n",
    "\n",
    "To remove outliers identified in paragraph `2.4.2` we will perform winsorization and use **Robust Scaler** during `Data Transformation` in paragraph `3.3`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "### 3.2 Bivariate analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60",
   "metadata": {},
   "source": [
    "Here we will skip features that consist only of values 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis = energy.join(weather, how=\"inner\")\n",
    "\n",
    "# remove columns that are entirely zero\n",
    "non_zero_cols = df_analysis.columns[(df_analysis != 0).any()]\n",
    "\n",
    "# keep only numeric features\n",
    "num_df = df_analysis[non_zero_cols].select_dtypes(include=\"number\")\n",
    "\n",
    "# compute correlation with price\n",
    "corr = num_df.corr()[target_col].drop(labels=[target_col]).sort_values()\n",
    "\n",
    "plt.figure(figsize=(8,12))\n",
    "corr.plot(kind=\"barh\")\n",
    "plt.title(\"Correlation with Day-Ahead Price\")\n",
    "plt.xlabel(\"Correlation\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "The diagram shows that some variables are correlated positively, some nagetively and some are only slightly or not correlated with the target variable at all."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63",
   "metadata": {},
   "source": [
    "#### Correlation between the eletricity price and the day of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(energy.index))\n",
    "# print(energy.index[:5])\n",
    "\n",
    "weekday_price = energy['price_day_ahead'].groupby(energy.index.to_series().dt.dayofweek).mean()\n",
    "print(weekday_price)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "weekday_price.plot(kind='bar')\n",
    "plt.title(\"Average Day-Ahead Electricity Price by Day of the Week\")\n",
    "plt.ylabel(\"Price (€/MWh)\")\n",
    "plt.xlabel(\"Day of Week (0=Mon, 6=Sun)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65",
   "metadata": {},
   "source": [
    "There's no strong dependency between the day of the week and the eletricity price, however the price tends to be lower on the weekends."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66",
   "metadata": {},
   "source": [
    "##### Correlation between the temperature and the eletricity price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_analysis[\"temperature\"]\n",
    "y = df_analysis[target_col]\n",
    "\n",
    "# smooth curve\n",
    "low = lowess(y, x, frac=0.15)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.scatter(x, y, s=5, alpha=0.1)\n",
    "plt.plot(low[:,0], low[:,1], linewidth=3)\n",
    "\n",
    "plt.title(\"LOWESS Smoothed Relationship: Temperature vs Price\")\n",
    "plt.xlabel(\"Temperature (K)\")\n",
    "plt.ylabel(\"Day-Ahead Price (€/MWh)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "There's no significant correlation between the eletricity price and the temperature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69",
   "metadata": {},
   "source": [
    "### 3.3 Data Transformation\n",
    "\n",
    "Since all the features are numerical they don't have to be encoded in any way.\n",
    "\n",
    "#### 3.3.1 Dropping unnecessary variables\n",
    "\n",
    "There are variables with all 0 values. They will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = energy.join(weather, how=\"inner\")\n",
    "\n",
    "dfML = df.copy()\n",
    "\n",
    "zero_cols = dfML.columns[(dfML == 0).all()]\n",
    "print(\"Dropped columns with all zeros:\", list(zero_cols))\n",
    "\n",
    "dfML = dfML.drop(columns=zero_cols)\n",
    "\n",
    "dfML.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71",
   "metadata": {},
   "source": [
    "\n",
    "#### 3.3.1 Handling variables with skewed distribution\n",
    "\n",
    "Since not all of the skewed distrubutions concern variables with positive values we will use **Yeo-Johnson** scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast to float before transformation to avoid dtype issues\n",
    "dfML = dfML.copy()\n",
    "\n",
    "for col in skewed_cols:\n",
    "    dfML[col] = dfML[col].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = PowerTransformer(method='yeo-johnson')\n",
    "\n",
    "print(df[skewed_cols].dtypes)\n",
    "\n",
    "dfML.loc[:, skewed_cols] = pt.fit_transform(dfML.loc[:, skewed_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74",
   "metadata": {},
   "source": [
    "#### 3.3.2 Handling outliers\n",
    "\n",
    "As indicated in paragraph `3.1`, we will use **Robust Scaler** to handle outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = RobustScaler()\n",
    "\n",
    "print(outliers_cols)\n",
    "print(type(outliers_cols))\n",
    "\n",
    "# Fit the scaler on the numeric features and transform\n",
    "dfML.loc[:,outliers_cols] = scaler.fit_transform(dfML[outliers_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76",
   "metadata": {},
   "source": [
    "### 3.4 Data Splitting\n",
    "\n",
    "To evaluate the models that will be used in paragraph `4` we have to split dataset into a train and a test set. We will use an 75/25 split ratio (the whole dataset represents 4 years of data and the test set will consist of last 12 months) to ensure sufficient amount of data for training while retaining enough samples for meaningful evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last 12 months for test\n",
    "split_date = dfML.index.max() - pd.DateOffset(years=1)\n",
    "\n",
    "train_dfML = dfML[dfML.index <= split_date]\n",
    "test_dfML  = dfML[dfML.index > split_date]\n",
    "\n",
    "print(\"Split date:\", split_date)\n",
    "print(\"Train:\", train_dfML.shape)\n",
    "print(\"Test:\", test_dfML.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78",
   "metadata": {},
   "source": [
    "### 3.5 Feature selection\n",
    "\n",
    "#### Embedded method - Lasso regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_regularization(df, target_col=\"price_day_ahead\"):\n",
    "\n",
    "    X = df.drop(columns=[target_col]).copy()\n",
    "    y = df[target_col].copy()\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    lasso = Lasso(alpha=0.01, random_state=42, max_iter=5000)\n",
    "\n",
    "    sel_ = SelectFromModel(lasso)\n",
    "    sel_.fit(X_scaled, y)\n",
    "\n",
    "    selected_feat = X.columns[sel_.get_support()]\n",
    "    removed_feat = X.columns[~sel_.get_support()]\n",
    "\n",
    "    print(f\"Selected features ({len(selected_feat)}):\")\n",
    "    print(selected_feat.tolist())\n",
    "\n",
    "    print(f\"\\nRemoved features ({len(removed_feat)}):\")\n",
    "    print(removed_feat.tolist())\n",
    "\n",
    "    return selected_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lasso_SelectedColumns = lasso_regularization(train_dfML)\n",
    "\n",
    "Lasso_SelectedColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dfML = train_dfML[list(Lasso_SelectedColumns) + [target_col]]\n",
    "test_dfML  = test_dfML[list(Lasso_SelectedColumns) + [target_col]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82",
   "metadata": {},
   "source": [
    ":asso regularization removed DOK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83",
   "metadata": {},
   "source": [
    "We prepared dataframes for future testing and tuning to compare different models and select the one with the best performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Modelling\n",
    "\n",
    "### 4.1 Statistical Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85",
   "metadata": {},
   "source": [
    "For the statistical modelling we will use SARIMA and SARIMAX models in order to predict future electricity prices. Since these methods are computationally heavy when applied to long hourly time series, a subset of the data covering two consecutive years will be selected. This period needs to be sufficiently long to capture the most relevant seasonal patterns, while keeping the computational cost manageable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86",
   "metadata": {},
   "source": [
    "#### 4.1.1 Subset selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87",
   "metadata": {},
   "source": [
    "In order to select the appropriate period for further analysis, we visualized subsequent pairs of years: 2015-2016 and 2016-2017. The year 2018 was not taken into account due to its role as a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dfML.index = pd.to_datetime(test_dfML.index)\n",
    "train_dfML.index = pd.to_datetime(train_dfML.index)\n",
    "\n",
    "periods = [\n",
    "    ('2015-01-01', '2016-12-31'),\n",
    "    ('2016-01-01', '2017-12-31')\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for i, (start, end) in enumerate(periods, 1):\n",
    "    plt.subplot(2, 1, i)\n",
    "    train_dfML.loc[start:end, 'price_day_ahead'].plot()\n",
    "    plt.title(f'Price Day-Ahead: {start[:4]}-{end[:4]}')\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89",
   "metadata": {},
   "source": [
    "Based on a visual assessment of subsequent annual periods, we decided to select 2016-2017 for model training. Compared to 2015-2016, this period is characterized by better consistency of the training data distribution with the 2018 test data, more stable price dynamics, and clearer seasonal patterns. However, the 2015-2016 period could also be considered a valid alternative, since it displays relevant seasonal characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = '2016-01-01'\n",
    "end ='2017-12-31'\n",
    "train_stat= train_dfML.loc[start:end, :]\n",
    "train_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_stat['price_day_ahead'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92",
   "metadata": {},
   "source": [
    "##### Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93",
   "metadata": {},
   "source": [
    "In order to better understand the underlying structure of the electricity price time series, a seasonal-trend decomposition was performed. It was applied with the use of STL method. Such approach enable us to isolate trend, seasonal, and residual components and to better assess the presence of recurring patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94",
   "metadata": {},
   "outputs": [],
   "source": [
    "stl = STL(train_stat['price_day_ahead'], period=24, robust=True)\n",
    "res = stl.fit()\n",
    "\n",
    "fig = res.plot()\n",
    "fig.suptitle(\n",
    "    'STL Decomposition of Day-Ahead Electricity Price (2016-2017)',\n",
    "    fontsize=14\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95",
   "metadata": {},
   "source": [
    "Based on the original series, it can be observed that electricity prices exhibit high short-term variability and frequent price spikes, which are typical characteristics of electricity markets. The trend component indicates a moderate increase in the price level over the analysed period, providing initial evidence of non-stationarity in the data. Due to the large number of data points (hourly observations over a two-year period), the seasonal component is not clearly visible at this scale. When it comes to residual component, it does not display a clear seasonal structure. However, it contains episodes of extreme deviations, which may be associated with exceptional events affecting electricity prices.\n",
    "\n",
    "In order to better visualise the structure of the data, and in particular the daily seasonal pattern, an additional decomposition was performed at the scale of the first month of the analysed period. This allowed for a clearer identification of recurring price patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_series = train_stat['price_day_ahead'].loc['2016-01-01':'2016-01-31']\n",
    "\n",
    "stl_short = STL(short_series, period=24, robust=True)\n",
    "res_short = stl_short.fit()\n",
    "\n",
    "fig = res_short.plot()\n",
    "fig.suptitle(\n",
    "    'STL Decomposition of Day-Ahead Electricity Price (January 2016)',\n",
    "    fontsize=14\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97",
   "metadata": {},
   "source": [
    "The decomposition of the time series at a monthly scale, specifically for the first month of the analysed data, allows for a much clearer identification of short-term patterns. The seasonal component shows a regular daily price cycle with repeating patterns across consecutive days. The seasonal amplitude is relatively stable, although some days exhibit stronger fluctuations. The residual component contains occasional short-term deviations, which may be related to sudden market events or random noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.seasonal.iloc[:72].plot(\n",
    "    title='Seasonal component first 72 hours'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99",
   "metadata": {},
   "source": [
    "The chart above provides additional confirmation of the presence of a clear daily seasonal pattern, as illustrated over a three-day period."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100",
   "metadata": {},
   "source": [
    "#### 4.1.2 Stationarity testing (ADF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101",
   "metadata": {},
   "source": [
    "In order to use the selected dataset in models such as SARIMA/SARIMAX used to predict future electricity prices, it is necessary to ensure its stationarity i.e. that its statistical properties, such as the mean, variance, and autocorrelation structure, remain constant over time. To assess whether this condition is satisfied, the Augmented Dickey-Fuller (ADF) test was performed.\n",
    "\n",
    "It is a statistical test used to examine the presence of a unit root in a time series. The null hypothesis (H₀) states that the series contains a unit root and is therefore non-stationary. At the same time, the alternative hypothesis (H₁) assumes that the series is stationary. A sufficiently small p-value (smaller than 0.05) leads to the rejection of the null hypothesis, indicating that the data meet the criteria to be used in forcast models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adf_test(series):\n",
    "    results = adfuller(series)\n",
    "    print(f\"ADF statistic: {results[0]}\")\n",
    "    print(f\"p-value: {results[1]}\")\n",
    "    print('Critical values: ')\n",
    "    for thres, adf_stat in results[4].items():\n",
    "        print(thres, adf_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103",
   "metadata": {},
   "outputs": [],
   "source": [
    "adf_test(train_stat['price_day_ahead'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104",
   "metadata": {},
   "source": [
    "The Augmented Dickey-Fuller test yielded a test statistic of −7.42, which is substantially lower than all reported critical values ​​at the 1%, 5%, and 10% significance levels, and a very low p-value. Although these results suggest rejection of the null hypothesis of a unit root, prior analysis of the time series indicates that the data may not meet the assumptions of stationarity. This is evidenced by the observed changes in the mean and variability over time.\n",
    "\n",
    "Therefore, to further verify the stationarity of the series, moving statistics in the form of the moving average and moving standard deviation were analyzed. This visual inspection allows for the assessment of potential changes in the statistical properties of the series over time and provides additional confirmation of its stationarity or non-stationarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_mean_sd(series):\n",
    "    rolling_mean = series.rolling(window=168).mean()\n",
    "    rolling_std = series.rolling(window=168).std()\n",
    "\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(12, 8), sharex=True)\n",
    "\n",
    "    axes[0].plot(series, alpha=0.25, label='Original')\n",
    "    axes[0].plot(rolling_mean, color='orange', linewidth=2, label='Rolling Mean (7 days)')\n",
    "    axes[0].set_title('Rolling Mean (7 days Window)')\n",
    "    axes[0].legend()\n",
    "    axes[1].plot(rolling_std, color='green', linewidth=2, label='Rolling Std (7 days)')\n",
    "    axes[1].set_title('Rolling Standard Deviation (7 days Window)')\n",
    "    axes[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106",
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_mean_sd(train_stat['price_day_ahead'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107",
   "metadata": {},
   "source": [
    "The chart above indicates noticeable changes in the level of the rolling mean over the analysed period. Similarly, the rolling standard deviation varies over time, revealing time-varying volatility. Based on both statistics, it can be concluded that the series does not satisfy the stationarity assumptions, which contradicts the result of the ADF test.\n",
    "\n",
    "Although the ADF test is useful in many cases, it may produce misleading results for hourly data with strong daily seasonality. The pronounced 24-hour seasonal pattern implies that observations at time t are highly correlated with those at time t − 24, which can mask non-stationary behaviour that is clearly visible in rolling statistics. Taking these observations into account, the non-stationary dataset requires appropriate transformations prior to modelling.\n",
    "\n",
    "Therefore, seasonal differentiation with a 24-hour lag was applied to eliminate the daily seasonal component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seas_diff = train_stat['price_day_ahead'].diff(24).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109",
   "metadata": {},
   "outputs": [],
   "source": [
    "adf_test(train_seas_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110",
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_mean_sd(train_seas_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111",
   "metadata": {},
   "source": [
    "After applying seasonal differencing, the ADF test was rerun to confirm the stationarity condition. The test statistic achieved a value much lower than all critical values, and the p-value was effectively zero, leading to a clear rejection of the null hypothesis of a unit root. The stationarity is also confirmed in this case by the plots. The rolling mean oscillates around zero and no longer shows changes in its level, indicating that the daily seasonal component has been effectively removed. The rolling standard deviation also appears more stable over time compared to the original series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_seas_diff.loc['2016-01-01':'2016-01-31'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113",
   "metadata": {},
   "source": [
    "#### 4.1.3 ACF/PACF analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114",
   "metadata": {},
   "source": [
    "The autocorrelation function (ACF) is a key tool in time series analysis, measuring how a series correlates with lagged versions of itself and revealing patterns, trends, seasonality, and dependencies. In other words, it indicates how strongly the current value of the series is related to its past observations.\n",
    "\n",
    "In the case of the analysed series after seasonal differencing, it can be observed that prices are still dependent on values from the previous few hours, as indicated by high ACF values at small lags (which is a typical characteristic of electricity price markets). Moreover, the gradual decline of the ACF suggests the presence of an autoregressive (AR) component in the data.\n",
    "\n",
    "On the other hand, the lack of a sharp cutoff in the ACF indicates that a moving average (MA) component is unlikely. Additionally, the absence of pronounced seasonal peaks at lags such as 24 or 48 confirms that the daily seasonality has been effectively removed. This pattern suggests that a low-order autoregressive component should be considered in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plot_acf(train_seas_diff)\n",
    "plt.title('ACF of price_day_ahead after seasonal differencing (lag=24)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116",
   "metadata": {},
   "source": [
    "The PACF (Partial Autocorrelation Function) statistics measure the direct correlation between the current value of a time series and its past values, after removing the influence of all intermediate lags, helping to identify the order (p) of autoregressive (AR) models. The plot below shows the values ​​in each lag and the shaded blue area, which represents the 95% confidence interval. Any spikes exceeding this range indicate statistically significant partial autocorrelations.\n",
    "\n",
    "In the analyzed time series, after seasonal differentiation, a significant spike at lag 1 (non-seasonal AR(1)) indicates that electricity prices remain strongly dependent on the previous hour, which is typical for electricity markets. Subsequent larger spikes occur around lags 24 and 48 indicate a seasonal autoregressive effect corresponding to the daily cycle, confirming the need for a seasonal AR component with a 24-hour period. Most of the remaining lags are within the confidence limits, indicating that higher-order autoregressive components are not required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plot_pacf(\n",
    "    train_seas_diff,\n",
    "    lags=50,\n",
    "    method='ywm'\n",
    ")\n",
    "plt.title('PACF of price_day_ahead after seasonal differencing (lag=24)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118",
   "metadata": {},
   "source": [
    "#### 4.1.4 SARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119",
   "metadata": {},
   "source": [
    "To implement statistical models such as SARIMA, which are needed to predict future electricity prices, it is necessary to find appropriate parameters. For this purpose, we used the results of stationarity analysis, seasonal decomposition, and plots of the autocorrelation (ACF) and partial autocorrelation (PACF) functions.\n",
    "\n",
    "SARIMA parameters define both the non-seasonal and seasonal components of a time series model, denoted as SARIMA(p,d,q)(P,D,Q)s, where (p,d,q) are the non-seasonal orders (Autoregressive, Differencing, Moving Average), (P,D,Q) are the seasonal orders (Seasonal AR, Seasonal Difference, Seasonal MA), and s is the seasonal period length.\n",
    "\n",
    "In the previous analysis, the need for differencing was identified due to the non-stationarity of the original time series caused by the presence of strong daily seasonality and time-varying mean and variance. For this purpose, seasonal differencing with a lag of 24 hours, corresponding to the daily cycle observed in the data, was performed. On this basis, the seasonal differencing order was set to D = 1. No need for additional non-seasonal differencing was observed, resulting in d = 0.\n",
    "\n",
    "Inspection of the plot generated using ACF revealed that there was no sharp cutoffs and no visible seasonality. It shows that values ​​gradually decreased in subsequent lags, suggesting the absence of a dominant moving average component. As a result, the non-seasonal moving average order was set to q = 0 and the seasonal order to Q = 0.\n",
    "\n",
    "The PACF revealed a strong spike at lag 1, indicating a short-term dependence on the previous hour and confirmed the need to include a non-seasonal autoregressive component of order p = 1. Furthermore, spikes were observed around lags 24 and 48, suggesting a seasonal autoregressive effect associated with the daily cycle. Based on this, we can conclude that a seasonal autoregressive order should be equal to P = 1.\n",
    "\n",
    "Based on these observations, the final model specification was selected as **SARIMA(1,0,0)(1,1,0,24).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120",
   "metadata": {},
   "source": [
    "To implement a model that would predict electricity prices both 1-step ahead and 24-step ahead, two SARIMA models were created. The first model was trained in the standard manner using the training dataset to estimate the model parameters without relying on future information. Then, a second model was defined on the combined training and test data. However, this model was not re-estimated. Instead, the parameters obtained from the first model were applied to it using the filter() method.\n",
    "\n",
    "This two-stage approach allows for estimating model parameters based solely on training data while simultaneously generating forecasts for the entire analyzed time period. In this configuration, the model can be used both for one-step-ahead forecasts, in which the model state is updated with each new observation, and for multi-step-ahead forecasts (e.g. 24-step-ahead), where each subsequent forecast is based on previously predicted values. This solution allows for a realistic assessment of forecast quality across various time horizons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_stat['price_day_ahead']\n",
    "y_test  = test_dfML['price_day_ahead']\n",
    "y_all = pd.concat([y_train, y_test])\n",
    "\n",
    "sarima_model = SARIMAX(\n",
    "    y_train,\n",
    "    order=(1,0,0),\n",
    "    seasonal_order=(1,1,0,24),\n",
    "    enforce_stationarity=False,\n",
    "    enforce_invertibility=False\n",
    ")\n",
    "sarima_res_train = sarima_model.fit()\n",
    "\n",
    "sarima_model_all = SARIMAX(\n",
    "    y_all,\n",
    "    order=(1,0,0),\n",
    "    seasonal_order=(1,1,0,24),\n",
    "    enforce_stationarity=False,\n",
    "    enforce_invertibility=False\n",
    ")\n",
    "sarima_res_all = sarima_model_all.filter(sarima_res_train.params)\n",
    "\n",
    "sarima_res_all.plot_diagnostics(figsize=(12, 8))\n",
    "plt.show()\n",
    "print(sarima_res_all.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122",
   "metadata": {},
   "source": [
    "Diagnostic plots were generated in order to perform an initial assessment of model adequacy and verify that no strong autocorrelation or systematic patterns remain unmodelled. The diagnostics include the standardized residuals over time, the histogram of residuals with an estimated density, the normal Q-Q plot, and the correlationogram of residuals. Overall, the diagnostic plots indicate that the chosen SARIMA specification provides a reasonable initial fit to the data and can be used later in forecasting. A more detailed analysis of the residual properties will be performed in a dedicated residual analysis section later in the report."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123",
   "metadata": {},
   "source": [
    "#### 4.1.5 SARIMAX using relevant exogenous variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124",
   "metadata": {},
   "source": [
    "To train the SARIMAX model, a set of exogenous variables is required. In the case of the analyzed time series, the aforementioned subset was selected based on the economic relevance of individual variables and their observed correlation with electricity prices. It consists of:\n",
    "- total electricity demand (total_load_actual)\n",
    "- onshore wind generation (generation_wind_onshore)\n",
    "- fossil gas generation (generation_fossil_gas).\n",
    "\n",
    "The corresponding exogenous datasets were then extracted for both the training and test periods. Finally, missing-value checks were performed to ensure data consistency prior to model estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_stat['price_day_ahead']\n",
    "y_test  = test_dfML['price_day_ahead']\n",
    "exog_cols = [\n",
    "    'total_load_actual',\n",
    "    'generation_wind_onshore',\n",
    "    'generation_fossil_gas'\n",
    "]\n",
    "X_train = train_stat[exog_cols]\n",
    "X_test = test_dfML[exog_cols]\n",
    "\n",
    "print(y_train.isna().sum())\n",
    "print(X_train.isna().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126",
   "metadata": {},
   "source": [
    "To extend the model with additional external information, the SARIMAX model was applied. In contrast to the classical SARIMA approach, SARIMAX incorporates not only price_day_ahead data but also exogenous variables. As in the case of SARIMA, the implementation was divided into two stages.\n",
    "\n",
    "In the first stage, the SARIMAX model was trained exclusively on the training dataset, using the corresponding exogenous variables from the same dataset. Next, a model based on the combined training dataset and test data with associated exogenous variables, was constructed. This second model was not re-estimated. Instead, the parameters obtained from the training model were reused. Diagnostic plots were also generated and, similarly to the SARIMA case, they indicate a reasonable initial fit of the model to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_all = pd.concat([y_train, y_test])\n",
    "X_all = pd.concat([X_train, X_test])\n",
    "\n",
    "sarimax_model = SARIMAX(\n",
    "    y_train,\n",
    "    exog=X_train,\n",
    "    order=(1,0,0),\n",
    "    seasonal_order=(1,1,0,24),\n",
    "    enforce_stationarity=False,\n",
    "    enforce_invertibility=False\n",
    ")\n",
    "\n",
    "sarimax_res_train = sarimax_model.fit()\n",
    "\n",
    "sarimax_model_all = SARIMAX(\n",
    "    y_all,\n",
    "    exog=X_all,\n",
    "    order=(1,0,0),\n",
    "    seasonal_order=(1,1,0,24),\n",
    "    enforce_stationarity=False,\n",
    "    enforce_invertibility=False\n",
    ")\n",
    "sarimax_res_all = sarimax_model_all.filter(sarimax_res_train.params)\n",
    "\n",
    "sarimax_res_all.plot_diagnostics(figsize=(12, 8))\n",
    "plt.show()\n",
    "print(sarimax_res_all.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128",
   "metadata": {},
   "source": [
    "#### 4.1.6 Residual diagnostics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129",
   "metadata": {},
   "source": [
    "In order to evaluate the adequacy of the time series models, we conducted a residual analysis. This step allows us to verify whether the model has successfully captured the underlying structure of the data and whether the remaining unexplained component behaves like random noise. If the residuals exhibit no systematic patterns, constant variance, and no significant autocorrelation, the model can be considered suitable for the forecasting process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_sarima = sarima_res_all.resid\n",
    "df_residuals = train_stat.copy()\n",
    "df_residuals['residuals'] = residuals_sarima\n",
    "df_residuals['fittedvales'] = sarima_res_all.fittedvalues\n",
    "df_residuals[['price_day_ahead','fittedvales','residuals']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(residuals_sarima)\n",
    "plt.axhline(0, color='black')\n",
    "plt.title(\"Residuals over time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132",
   "metadata": {},
   "source": [
    "The plot above presents the residuals of the SARIMA model over time. Most residual values are centered around zero, which indicates the absence of systematic bias and suggests that the model captures the main structure of the data reasonably well. However, several spikes can also be observed, with residuals ranging approximately from -60 to 40. These extreme deviations indicate periods where the model fails to fully explain sudden changes in electricity prices. Such anomalies are likely driven by market-specific characteristics and may be associated with exceptional events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf(residuals_sarima, lags=50)\n",
    "plt.title(\"ACF of residuals\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134",
   "metadata": {},
   "source": [
    "The ACF of the SARIMA residuals shows that most autocorrelations are small and within the 95% confidence interval. However, slight peaks at lags 24 and 48 are still visible, which correspond to the daily seasonality in the hourly data. The presence of weak seasonal autocorrelation in the residuals indicates that the model captures the main dynamics of the series, but a small amount of daily dependence remains in the residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plot_pacf(\n",
    "    residuals_sarima,\n",
    "    lags=50,\n",
    "    method='ywm'\n",
    ")\n",
    "plt.title('PACF for residuals')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136",
   "metadata": {},
   "source": [
    "The PACF of the residuals shows that most lags are close to zero. Small spikes are visible at lags 24 and 48, consistent with the hourly structure of the data and reflecting weak, persistent daily seasonality. However, these values are small and do not justify adding additional AR terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb_test = acorr_ljungbox(residuals_sarima, lags=[24], return_df=True)\n",
    "print(lb_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138",
   "metadata": {},
   "source": [
    "To examine whether autocorrelation remains in the residuals, the Ljung-Box test was applied. According to this method, the null hypothesis (H₀) of the test states that the residuals are not autocorrelated, while the alternative hypothesis indicates the presence of serial dependence. A p-value below the 0.05 leads to rejection of the null hypothesis. In case of the SARIMA model, the obtained p-value is equal to 0, which suggests the presence of residual autocorrelation. In most cases, such a result would indicate that the model may require further refinement before being used for forecasting.\n",
    "\n",
    "However, in the context of hourly electricity price data, the Ljung-Box test may be too sensitive and produce misleading results due to the large sample size, strong seasonality and complex dependency structure of the series. The ACF and PACF plots show that the remaining autocorrelation is weak. Therefore, the Ljung-Box test result is interpreted with caution and does not invalidate the model for forecasting purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139",
   "metadata": {},
   "source": [
    "##### SARIMAX exogenous variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140",
   "metadata": {},
   "source": [
    "As with the SARIMA model, residual analysis was also performed for the SARIMAX model with exogenous variables. This analysis allows us to assess whether the residuals behave like random noise or whether further modifications to the model structure are required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = sarimax_res_all.resid\n",
    "df_residuals = train_stat.copy()\n",
    "df_residuals['residuals'] = residuals\n",
    "df_residuals['fittedvales'] = sarimax_res_all.fittedvalues\n",
    "df_residuals[['price_day_ahead','fittedvales','residuals']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(residuals)\n",
    "plt.axhline(0, color='black')\n",
    "plt.title(\"Residuals over time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143",
   "metadata": {},
   "source": [
    "The plot shows how the residual component changes over time. The residuals oscillate around zero and do not exhibit a long-term trend. However, some spikes are present, indicating that the model does not fully capture extreme price changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(residuals)\n",
    "plt.title(\"Distribution of residuals\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145",
   "metadata": {},
   "source": [
    "For the purpose of showing the distribution of residuals, the histogram above was created. Based on it, it can be concluded that the residuals are strongly concentrated around zero, indicating that most prediction errors are small. However, the presence of noticeable, though relatively light, tails suggests that the model occasionally struggles to capture sudden and extreme price changes, which are common in electricity markets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "plt.title(\"Q-Q plot of residuals\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147",
   "metadata": {},
   "source": [
    "The Q-Q plot shows how the distribution of residuals compares to a normal distribution. While the residuals follow the reference line reasonably well in the central part, deviations appear in the tails. This indicates the presence of extreme values, which is consistent with the characteristics of electricity price markets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf(residuals, lags=50)\n",
    "plt.title(\"ACF of residuals\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149",
   "metadata": {},
   "source": [
    "According to the ACF chart, most of the lag values oscillate around 0, indicating that the majority of temporal dependence has been removed by the model. However, small spikes can be observed at lags around 24 and 48, which correspond to daily seasonality in hourly data. This suggests that some seasonal structure remains in the residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plot_pacf(\n",
    "    residuals,\n",
    "    lags=50,\n",
    "    method='ywm'\n",
    ")\n",
    "plt.title('PACF for residuals')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151",
   "metadata": {},
   "source": [
    "The PACF of the residuals shows that most of the partial autocorrelations are close to zero. This indicates no strong, remaining direct dependencies between the residuals. Although a few spikes are visible at larger lags, (24, 48) these are relatively small and do not suggest the need for additional autoregressive terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb_test = acorr_ljungbox(residuals, lags=[24], return_df=True)\n",
    "print(lb_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153",
   "metadata": {},
   "source": [
    "The Ljung-Box test was applied to the residuals at lag 24 to assess the presence of remaining autocorrelation. The very small p-value indicates that the null hypothesis of no autocorrelation should be rejected. This means that some temporal dependence may still be present in the residual. Given the complexity of the electricty market and the results of the ACF an PACF diagnostics, this outcome is interpreted as not a critical flaw of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154",
   "metadata": {},
   "source": [
    "#### 4.1.7 Forecast 1-step ahead and 24-step ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test  = test_dfML['price_day_ahead']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156",
   "metadata": {},
   "source": [
    "##### 1-step ahead forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157",
   "metadata": {},
   "source": [
    "To perform one-step-ahead forecasting using the SARIMA model, forecasts are generated sequentially for each hour of the test period. Setting dynamic=False ensures that the model's state is updated with each new observed value, closely replicating a real-time forecasting scenario in which the most recent observations are always available.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sarima = sarima_res_all.get_prediction(\n",
    "    start=y_test.index[0],\n",
    "    end=y_test.index[-1],\n",
    "    dynamic=False\n",
    ")\n",
    "\n",
    "y_hat_sarima = pred_sarima.predicted_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(y_test, label=\"True\")\n",
    "plt.plot(y_hat_sarima, label=\"SARIMA 1h-ahead\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160",
   "metadata": {},
   "source": [
    "The generated plot shows that SARIMA forecasts largely match observed electricity prices, accurately capturing both short-term fluctuations and the overall price level. The model's greatest challenge lies in larger deviations caused by sudden price spikes or drops (typical of this market), but these differences remain within an acceptable range."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161",
   "metadata": {},
   "source": [
    "Similar to the previous model, the SARIMAX model also employs a one-step-ahead forecasting procedure, additionally incorporating exogenous variables such as total load and generation from selected energy sources. As with the SARIMA model, the model state is updated at each step using the actual observed price and its corresponding input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sarimax = sarimax_res_all.get_prediction(\n",
    "    start=y_test.index[0],\n",
    "    end=y_test.index[-1],\n",
    "    exog=X_test,\n",
    "    dynamic=False\n",
    ")\n",
    "\n",
    "y_hat_sarimax = pred_sarimax.predicted_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(y_test, label=\"True\")\n",
    "plt.plot(y_hat_sarimax, label=\"SARIMAX 1h-ahead\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164",
   "metadata": {},
   "source": [
    "The plot shows that the obtained results closely match the actual data from the test set. A slight improvement is visible in the case of larger deviations compared to the standard SARIMA model, indicating that the selected exogenous variables improved the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165",
   "metadata": {},
   "source": [
    "##### 24-steps ahead"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166",
   "metadata": {},
   "source": [
    "To use the SARIMA model to predict electricity prices 24 steps ahead, a rolling forecast strategy was employed. This approach works as follows: At the beginning of each test day, the model generates a forecast for the next 24 hours, without access to actual observations during this time period. This is achieved by setting dynamic=start_point, which ensures that subsequent hourly forecasts are based on previously forecasted values ​​rather than actual prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167",
   "metadata": {},
   "outputs": [],
   "source": [
    "sarima_predictions_list = []\n",
    "\n",
    "for i in range(0, len(y_test), 24):\n",
    "    start_point = y_test.index[i]\n",
    "\n",
    "    pred = sarima_res_all.get_prediction(\n",
    "        start=start_point,\n",
    "        end=start_point + pd.Timedelta(hours=23),\n",
    "        exog=X_test,\n",
    "        dynamic=start_point\n",
    "    )\n",
    "\n",
    "    sarima_predictions_list.append(pred.predicted_mean)\n",
    "\n",
    "y_hat_24h_sarima = pd.concat(sarima_predictions_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,4))\n",
    "plt.plot(y_test, label=\"Real\", alpha=0.6)\n",
    "plt.plot(y_hat_24h_sarima, label=\"24-step ahead rolling (SARIMA)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169",
   "metadata": {},
   "source": [
    "The resulting forecasts match the test data quite well, but it is clear that the prediction quality has deteriorated visually compared to the 1-day-ahead forecasts. They still reflect the overall level and daily structure of electricity prices. However, they exhibit greater deviations during periods of sudden price spikes or drops."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170",
   "metadata": {},
   "source": [
    "A similar method was used to test 24-step rolling forecasts using the SARIMAX model. The only difference here is the addition of exogenous data. As in SARIMA, the test data is divided into 24-hour blocks, each with a starting point, and then the corresponding 24-hour exog_block is selected from the exogenous data. Finally, a prediction is generated for the current hour to the next 23 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171",
   "metadata": {},
   "outputs": [],
   "source": [
    "sarimax_predictions_list = []\n",
    "\n",
    "for i in range(0, len(y_test), 24):\n",
    "    start_point = y_test.index[i]\n",
    "\n",
    "    exog_block = X_test.loc[start_point : start_point + pd.Timedelta(hours=23)]\n",
    "\n",
    "    pred = sarimax_res_all.get_prediction(\n",
    "        start=start_point,\n",
    "        end=start_point + pd.Timedelta(hours=23),\n",
    "        exog=exog_block,\n",
    "        dynamic=start_point\n",
    "    )\n",
    "\n",
    "    sarimax_predictions_list.append(pred.predicted_mean)\n",
    "\n",
    "y_hat_24h_sarimax = pd.concat(sarimax_predictions_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,4))\n",
    "plt.plot(y_test, label=\"Real\", alpha=0.6)\n",
    "plt.plot(y_hat_24h_sarimax, label=\"24-step ahead rolling (SARIMAX)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173",
   "metadata": {},
   "source": [
    "The plot compares actual electricity prices with the 24-hour rolling forecast of the SARIMAX model. As with SARIMA, it shows that the model accurately reflects the overall price level and short-term dynamics, but it exhibits larger deviations compared to single-step forecasts. However, this is typical of multi-step forecasts, where the error accumulates over subsequent time horizons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174",
   "metadata": {},
   "source": [
    "#### 4.1.8 Evaluation metrcis and comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y_true, y_pred):\n",
    "    idx = y_true.index.intersection(y_pred.index)\n",
    "    y_t = y_true.loc[idx]\n",
    "    y_p = y_pred.loc[idx]\n",
    "\n",
    "    mae = np.mean(np.abs(y_t - y_p))\n",
    "    rmse = np.sqrt(np.mean((y_t - y_p) ** 2))\n",
    "    mape = np.mean(\n",
    "        np.abs((y_t - y_p) / y_t.replace(0, np.nan))\n",
    "    ) * 100\n",
    "\n",
    "    return mae, rmse, mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "results.append(('SARIMA', '1-step', *compute_metrics(y_test, y_hat_sarima)))\n",
    "results.append(('SARIMAX', '1-step', *compute_metrics(y_test, y_hat_sarimax)))\n",
    "results.append(('SARIMA', '24-step', *compute_metrics(y_test, y_hat_24h_sarima)))\n",
    "results.append(('SARIMAX', '24-step',*compute_metrics(y_test, y_hat_24h_sarimax)))\n",
    "df_stat_results = pd.DataFrame(results, columns=['Model', 'step', 'MAE', 'RMSE', 'MAPE'])\n",
    "df_stat_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177",
   "metadata": {},
   "source": [
    "To evaluate and compare the statistical models, standard error measures (MAE, RMSE, and MAPE) were calculated for each combination. The obtained results show that for both one-step-ahead and multi-step-ahead forecasts, the SARIMAX model achieves lower values ​​for all error measures than the classic SARIMA model. This indicates the benefit of including exogenous variables. Furthermore, for 24-step forecasts, the errors are significantly larger for both models, which is a natural consequence of the cumulative errors in multi-step forecasts.\n",
    "\n",
    "In summary, both models produced satisfactory results, and the addition of exogenous variables improves the quality of forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SARIMA AIC :\", sarima_res_train.aic)\n",
    "print(\"SARIMAX AIC:\", sarimax_res_train.aic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179",
   "metadata": {},
   "source": [
    "The displayed AIC (Akaike Information Criterion) values ​​are used to compare how well a model fits data against its complexity. In this case, the SARIMAX model achieves a significantly lower AIC than the classic SARIMA model, indicating that after including exogenous variables, the model better describes the data, despite the larger number of parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180",
   "metadata": {},
   "source": [
    "### 4.2 Machine Learning Models\n",
    "\n",
    "In this project, several machine learning regression models are trained and hyperparameter-tuned using time-series cross-validation to predict electricity prices. Their performance is then compared using error metrics in order to select the model that generalizes best for final forecasting.\n",
    "\n",
    "#### 4.2.1 Build supervised sliding-window datasets\n",
    "\n",
    "We will be using two functions two build sliding-window datasets. `make_sliding_window` is used for single-step predicitons and `slideWindow` for multi-step predictions. Later these functions will be used to build the sliding-window datasets after choosing the best window size in paragraph `4.2.2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sliding_window(series, window_size, horizon=1): # for single-step\n",
    "    X, y = [], []\n",
    "    for i in range(len(series) - window_size - horizon + 1):\n",
    "        X.append(series[i:i + window_size])\n",
    "        y.append(series[i + window_size + horizon - 1])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "def slideWindow(time_series, window_in, horizon): # for multi-step\n",
    "    if (len(time_series) - window_in - horizon + 1) <= 0:\n",
    "       raise ValueError(\"Time series too short for window size or horizon.\")\n",
    "    \n",
    "    d = time_series.values\n",
    "    X, y = [], []\n",
    "\n",
    "    for start in range(len(time_series)-window_in):\n",
    "        end = start + window_in\n",
    "        out = end + horizon\n",
    "        X.append(d[start:end].reshape(-1))\n",
    "        y.append(d[end:out].ravel()) # ravel() is equivalent to reshape(-1): returnscontiguous flattened array\n",
    "        cols_x = [f'x{i}' for i in range(1, window_in+1)]\n",
    "        cols_y = [f'y{i}' for i in range(1, horizon+1)]\n",
    "        df_X = pd.DataFrame(X, columns=cols_x)\n",
    "        df_y = pd.DataFrame(y, columns=cols_y)\n",
    "\n",
    "    return pd.concat([df_X, df_y], axis=1).dropna()\n",
    "\n",
    "def slideWindow2(time_series, window_in, horizon): # improved performance\n",
    "    if (len(time_series) - window_in - horizon + 1) <= 0:\n",
    "        raise ValueError(\"Time series too short for window size or horizon.\")\n",
    "\n",
    "    d = time_series.values\n",
    "    n_samples = len(d) - window_in - horizon + 1\n",
    "\n",
    "    X = np.empty((n_samples, window_in))\n",
    "    y = np.empty((n_samples, horizon))\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        X[i] = d[i : i + window_in]\n",
    "        y[i] = d[i + window_in : i + window_in + horizon]\n",
    "\n",
    "    cols_x = [f\"x{i}\" for i in range(1, window_in + 1)]\n",
    "    cols_y = [f\"y{i}\" for i in range(1, horizon + 1)]\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        np.hstack([X, y]),\n",
    "        columns=cols_x + cols_y\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182",
   "metadata": {},
   "source": [
    "#### 4.2.2 Several window sizes comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183",
   "metadata": {},
   "source": [
    "Now we will compare three window sizes (one day, two days and one week) to find the most efficient one. For that we will use Random Forest because it's the least sensitive to data changes and variance is reduced by averaging.\n",
    "To compare the results we will use MAE - Mean Aboslute Error - because it has low sensitivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_sizes = [24, 48, 168]   # 1 day, 2 days, 1 week\n",
    "horizons = [1, 24] # the number of time steps into the future to forecast at any point in time\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "results = []\n",
    "\n",
    "for w in window_sizes:\n",
    "\n",
    "    X, y = make_sliding_window(train_dfML[target_col].values, window_size=w, horizon=1)\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(tscv.split(X)):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        model = RandomForestRegressor(\n",
    "            n_estimators=50,\n",
    "            max_depth=10,\n",
    "            random_state=42,\n",
    "            n_jobs=-1 # enable paralelism\n",
    "        )\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_val)\n",
    "        mae = mean_absolute_error(y_val, y_pred)\n",
    "\n",
    "        results.append({\n",
    "            \"window\": w,\n",
    "            \"fold\": fold,\n",
    "            \"MAE\": mae\n",
    "        })\n",
    "        print(f\"Window {w}, Fold {fold}\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df.groupby(\"window\")[\"MAE\"].mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185",
   "metadata": {},
   "source": [
    "Mean Aboslute Error (MAE) is the lowest for 24-hour long window, which means that using the previous full day of information allows the model to make more accurate predictions on average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186",
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_WINDOW = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = make_sliding_window(\n",
    "    train_dfML[target_col].values,\n",
    "    window_size=BEST_WINDOW,\n",
    "    horizon=1\n",
    ")\n",
    "\n",
    "print(\"One Day Sliding Window Created for 1 step for the training set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = make_sliding_window(\n",
    "    test_dfML[target_col].values,\n",
    "    window_size=BEST_WINDOW,\n",
    "    horizon=1\n",
    ")\n",
    "\n",
    "print(\"One Day Sliding Window Created for 1 step for the testing set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sw_multi_step_train = slideWindow2(\n",
    "        train_dfML[target_col],\n",
    "        window_in=BEST_WINDOW,\n",
    "        horizon=24\n",
    "    )\n",
    "\n",
    "print(\"One Day Sliding Window Created for 24 step for the training set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sw_multi_step_test = slideWindow2(\n",
    "        test_dfML[target_col],\n",
    "        window_in=BEST_WINDOW,\n",
    "        horizon=24\n",
    "    )\n",
    "\n",
    "print(\"One Day Sliding Window Created for 24 step for the testing set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191",
   "metadata": {},
   "source": [
    "#### 4.2.3 Model selection and tuning\n",
    "\n",
    "Model selection is performed using 1-step ahead predictions, as this setting provides a fair and computationally efficient basis for comparing different algorithms. All models are trained on supervised sliding-window datasets and evaluated using time-series cross-validation, ensuring that temporal order is preserved and data leakage is avoided.\n",
    "\n",
    "The following regression algorithms are considered: Linear Regression, Decision Tree Regressor, k-Nearest Neighbours (KNN), Support Vector Regression (SVR), Bagging Regressor, Gradient Boosting Regressor, Random Forest Regressor, XGBoost Regressor, and LightGBM Regressor. For models sensitive to feature scaling (Linear Regression, KNN, and SVR), a StandardScaler is included using a pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_stage1 = {\n",
    "    \"LinearRegression\": Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\", LinearRegression())\n",
    "    ]),\n",
    "\n",
    "    \"DecisionTree\": DecisionTreeRegressor(random_state=42),\n",
    "\n",
    "    \"KNN\": Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\", KNeighborsRegressor())\n",
    "    ]),\n",
    "\n",
    "    \"SVR\": Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\", SVR())\n",
    "    ]),\n",
    "\n",
    "    \"Bagging\": BaggingRegressor(random_state=42),\n",
    "\n",
    "    \"GradientBoosting\": GradientBoostingRegressor(random_state=42),\n",
    "\n",
    "    \"RandomForest\": RandomForestRegressor(\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "\n",
    "    \"XGBoost\": XGBRegressor(\n",
    "        objective=\"reg:squarederror\",\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "\n",
    "    \"LightGBM\": LGBMRegressor(\n",
    "        random_state=42\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_mape(y_true, y_pred, eps=1e-8):\n",
    "    y_true = np.maximum(np.abs(y_true), eps)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {\n",
    "    \"mae\": \"neg_mean_absolute_error\",\n",
    "    \"rmse\": make_scorer(\n",
    "        lambda y, yhat: np.sqrt(mean_squared_error(y, yhat)),\n",
    "        greater_is_better=False\n",
    "    ),\n",
    "    \"mape\": make_scorer(\n",
    "        safe_mape,\n",
    "        greater_is_better=False\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195",
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "stage1_results = []\n",
    "\n",
    "feature_names = [f\"x{i}\" for i in range(1, X_train.shape[1] + 1)]\n",
    "\n",
    "for name, model in models_stage1.items():\n",
    "    fold_mae = []\n",
    "    fold_rmse = []\n",
    "    fold_mape = []\n",
    "\n",
    "    print(f\"\\nTraining model: {name}\")\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(tscv.split(X_train), 1):\n",
    "        print(f\"  Fold {fold}/5\")\n",
    "\n",
    "        X_tr, X_val = X_train[train_idx], X_train[val_idx]\n",
    "        y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "        model_fold = clone(model)\n",
    "\n",
    "        if name == \"LightGBM\":\n",
    "            X_tr = pd.DataFrame(X_tr, columns=feature_names)\n",
    "            X_val = pd.DataFrame(X_val, columns=feature_names)\n",
    "\n",
    "        model_fold.fit(X_tr, y_tr)\n",
    "        y_pred = model_fold.predict(X_val)\n",
    "\n",
    "        fold_mae.append(mean_absolute_error(y_val, y_pred))\n",
    "        fold_rmse.append(np.sqrt(mean_squared_error(y_val, y_pred)))\n",
    "        fold_mape.append(\n",
    "            np.mean(np.abs((y_val - y_pred) / np.maximum(np.abs(y_val), 1e-8)))\n",
    "        )\n",
    "\n",
    "    stage1_results.append({\n",
    "        \"Model\": name,\n",
    "        \"MAE\": np.mean(fold_mae),\n",
    "        \"RMSE\": np.mean(fold_rmse),\n",
    "        \"MAPE\": np.mean(fold_mape),\n",
    "    })\n",
    "\n",
    "    print(f\"  → MAE:  {np.mean(fold_mae):.3f}\")\n",
    "    print(f\"  → RMSE: {np.mean(fold_rmse):.3f}\")\n",
    "    print(f\"  → MAPE: {np.mean(fold_mape):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_stage1 = (\n",
    "    pd.DataFrame(stage1_results)\n",
    "      .sort_values(by=[\"MAE\", \"RMSE\", \"MAPE\"])\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(\"\\nFinal results:\")\n",
    "print(results_stage1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197",
   "metadata": {},
   "source": [
    "Before tuning:\n",
    "\n",
    "| Model            | MAE    | RMSE   | MAPE   |\n",
    "| ---------------- | ------ | ------ | ------ |\n",
    "| LinearRegression | 2.0272 | 3.1191 | 0.0561 |\n",
    "| RandomForest     | 2.2178 | 3.4819 | 0.0657 |\n",
    "| LightGBM         | 2.2992 | 3.5899 | 0.0693 |\n",
    "| GradientBoosting | 2.3319 | 3.6322 | 0.0688 |\n",
    "| Bagging          | 2.3822 | 3.6588 | 0.0676 |\n",
    "| XGBoost          | 2.4362 | 3.7724 | 0.0773 |\n",
    "| SVR              | 3.1489 | 5.6502 | 0.1291 |\n",
    "| DecisionTree     | 3.4551 | 5.2995 | 0.1020 |\n",
    "| KNN              | 3.9266 | 5.5235 | 0.1241 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198",
   "metadata": {},
   "source": [
    "*Linear Regression* clearly outperforms all other models, achieving the lowest MAE, RMSE, and MAPE, which suggests that the electricity price dynamics are largely linear for 1-step-ahead forecasting. Ensemble tree-based models (Random Forest, Gradient Boosting, LightGBM) show competitive but slightly inferior performance, while instance-based and kernel methods (KNN, SVR) perform considerably worse, indicating limited benefit from more complex non-linear models at this stage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199",
   "metadata": {},
   "source": [
    "#### 4.2.4 Hyperparameter tuning\n",
    "\n",
    "Hyperparameter tuning is carried out using *TimeSeriesSplit*, optimizing the Mean Absolute Error (MAE) as the primary selection criterion. This metric is chosen due to its robustness and direct interpretability in the context of electricity price forecasting. For each model, the best-performing hyperparameter configuration is selected based on cross-validation results.\n",
    "\n",
    "Linear Regression will noe be tuned because it has no meaningful hyperparameters that control model complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grids = {\n",
    "    \"DecisionTree\": {\n",
    "        \"max_depth\": [3, 5, 10, None],\n",
    "        \"min_samples_leaf\": [1, 5, 10]\n",
    "    },\n",
    "\n",
    "    \"KNN\": {\n",
    "        \"model__n_neighbors\": [3, 5, 10, 20]\n",
    "    },\n",
    "\n",
    "    \"SVR\": {\n",
    "        \"model__C\": [1, 10],\n",
    "        \"model__gamma\": [\"scale\"]\n",
    "    },\n",
    "\n",
    "    \"Bagging\": {\n",
    "        \"n_estimators\": [50, 100]\n",
    "    },\n",
    "\n",
    "    \"GradientBoosting\": {\n",
    "        \"n_estimators\": [100, 200],\n",
    "        \"learning_rate\": [0.05, 0.1],\n",
    "        \"max_depth\": [3, 5]\n",
    "    },\n",
    "\n",
    "    \"RandomForest\": {\n",
    "        \"n_estimators\": [100, 200],\n",
    "        \"max_depth\": [5, 10, None]\n",
    "    },\n",
    "\n",
    "    \"XGBoost\": {\n",
    "        \"n_estimators\": [200, 400],\n",
    "        \"learning_rate\": [0.05, 0.1],\n",
    "        \"max_depth\": [3, 5]\n",
    "    },\n",
    "\n",
    "    \"LightGBM\": {\n",
    "        \"n_estimators\": [200, 400],\n",
    "        \"learning_rate\": [0.05, 0.1],\n",
    "        \"num_leaves\": [31, 63]\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_results = []\n",
    "best_estimators = {}\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "for name, model in models_stage1.items():\n",
    "    print(f\"\\nTuning model: {name}\")\n",
    "\n",
    "    if name == \"LinearRegression\":\n",
    "        print(\"No tuning perfomed\")\n",
    "        continue\n",
    "\n",
    "    if name in [\"SVR\", \"LightGBM\"]:\n",
    "        grid = GridSearchCV(\n",
    "            estimator=model,\n",
    "            param_grid=param_grids.get(name, {}),\n",
    "            cv=tscv,\n",
    "            scoring=scoring,     \n",
    "            refit=\"mae\",         \n",
    "            n_jobs=1\n",
    "        )\n",
    "    elif name in [\"RandomForest\", \"XGBoost\"]:\n",
    "        grid = GridSearchCV(\n",
    "            estimator=model,\n",
    "            param_grid=param_grids.get(name, {}),\n",
    "            cv=tscv,\n",
    "            scoring=scoring,    \n",
    "            refit=\"mae\"\n",
    "        )\n",
    "    else:\n",
    "        grid = GridSearchCV(\n",
    "            estimator=model,\n",
    "            param_grid=param_grids.get(name, {}),\n",
    "            cv=tscv,\n",
    "            scoring=scoring,     \n",
    "            refit=\"mae\",\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "    if name == \"LightGBM\":\n",
    "        X_train_df = pd.DataFrame(\n",
    "            X_train,\n",
    "            columns=[f\"x{i}\" for i in range(1, X_train.shape[1] + 1)]\n",
    "        )\n",
    "        grid.fit(X_train_df, y_train)\n",
    "    else:\n",
    "        grid.fit(X_train, y_train)\n",
    "\n",
    "    best_idx = grid.best_index_\n",
    "\n",
    "    best_mae = -grid.cv_results_[\"mean_test_mae\"][best_idx]\n",
    "    best_rmse = -grid.cv_results_[\"mean_test_rmse\"][best_idx]\n",
    "    best_mape = -grid.cv_results_[\"mean_test_mape\"][best_idx]\n",
    "\n",
    "    tuning_results.append({\n",
    "        \"Model\": name,\n",
    "        \"Best_MAE\": best_mae,\n",
    "        \"Best_RMSE\": best_rmse,\n",
    "        \"Best_MAPE\": best_mape,\n",
    "        \"Best_Params\": grid.best_params_\n",
    "    })\n",
    "\n",
    "    best_estimators[name] = grid.best_estimator_\n",
    "\n",
    "    print(f\"  → MAE:  {best_mae:.3f}\")\n",
    "    print(f\"  → RMSE: {best_rmse:.3f}\")\n",
    "    print(f\"  → MAPE: {best_mape:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_tuning = (\n",
    "    pd.DataFrame(tuning_results)\n",
    "      .sort_values(\"Best_MAE\")\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(\"\\nFinal results:\")\n",
    "print(results_tuning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203",
   "metadata": {},
   "source": [
    "After tuning:\n",
    "\n",
    "| Model            | MAE       | RMSE      | MAPE       | Best Parameters                                       |\n",
    "| ---------------- | --------- | --------- | ---------- | ----------------------------------------------------- |\n",
    "| **RandomForest** | **2.211** | **3.470** | **0.0658** | `max_depth=None, n_estimators=200`                    |\n",
    "| Bagging          | 2.221     | 3.479     | 0.0654     | `n_estimators=100`                                    |\n",
    "| LightGBM         | 2.263     | 3.544     | 0.0684     | `learning_rate=0.05, n_estimators=200, num_leaves=31` |\n",
    "| GradientBoosting | 2.274     | 3.621     | 0.0703     | `learning_rate=0.05, max_depth=5, n_estimators=200`   |\n",
    "| XGBoost          | 2.279     | 3.595     | 0.0707     | `learning_rate=0.05, max_depth=5, n_estimators=200`   |\n",
    "| SVR              | 2.527     | 4.664     | 0.0832     | `C=10, gamma=scale`                                   |\n",
    "| DecisionTree     | 2.717     | 4.049     | 0.0793     | `max_depth=10, min_samples_leaf=10`                   |\n",
    "| KNN              | 3.875     | 5.434     | 0.1281     | `n_neighbors=10`                                      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204",
   "metadata": {},
   "source": [
    "Among the evaluated machine-learning models, *Random Forest* achieved the best overall performance, obtaining the lowest MAE, RMSE, and MAPE. Ensemble methods generally outperformed single learners, while distance-based (KNN) and kernel-based (SVR) models performed worse.\n",
    "\n",
    "***Comparison with the baseline: Seasonal Naïve***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_last_value_cv(X_train, y_train, n_splits=5):\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "    maes, rmses, mapes = [], [], []\n",
    "\n",
    "    for _, val_idx in tscv.split(X_train):\n",
    "        X_val = X_train[val_idx]\n",
    "        y_val = y_train[val_idx]\n",
    "\n",
    "        # Naive forecast = last value in the window\n",
    "        y_pred = X_val[:, -1]\n",
    "\n",
    "        maes.append(mean_absolute_error(y_val, y_pred))\n",
    "        rmses.append(np.sqrt(mean_squared_error(y_val, y_pred)))\n",
    "        mapes.append(\n",
    "            np.mean(np.abs((y_val - y_pred) / np.maximum(np.abs(y_val), 1e-8)))\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        \"Model\": \"Naive (Last value)\",\n",
    "        \"MAE\": np.mean(maes),\n",
    "        \"RMSE\": np.mean(rmses),\n",
    "        \"MAPE\": np.mean(mapes),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_results = naive_last_value_cv(X_train, y_train)\n",
    "baseline_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEASONAL_LAG = 24\n",
    "def seasonal_naive_cv(X, y, seasonal_lag=24, n_splits=5):\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "    maes, rmses, mapes = [], [], []\n",
    "\n",
    "    for train_idx, val_idx in tscv.split(X):\n",
    "        X_val = X[val_idx]\n",
    "        y_val = y[val_idx]\n",
    "\n",
    "        # Seasonal naive forecast\n",
    "        y_pred = X_val[:, -seasonal_lag]\n",
    "\n",
    "        maes.append(mean_absolute_error(y_val, y_pred))\n",
    "        rmses.append(np.sqrt(mean_squared_error(y_val, y_pred)))\n",
    "        mapes.append(\n",
    "            np.mean(\n",
    "                np.abs((y_val - y_pred) / np.maximum(np.abs(y_val), 1e-8))\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        \"Model\": \"SeasonalNaive\",\n",
    "        \"MAE\": np.mean(maes),\n",
    "        \"RMSE\": np.mean(rmses),\n",
    "        \"MAPE\": np.mean(mapes),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_result = seasonal_naive_cv(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    seasonal_lag=24,\n",
    "    n_splits=5\n",
    ")\n",
    "\n",
    "baseline_df = pd.DataFrame([baseline_result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final results table\n",
    "\n",
    "before_df = (\n",
    "    pd.DataFrame(stage1_results)\n",
    "    .rename(columns={\n",
    "        \"MAE\": \"MAE_before\",\n",
    "        \"RMSE\": \"RMSE_before\",\n",
    "        \"MAPE\": \"MAPE_before\"\n",
    "    })\n",
    "    [[\"Model\", \"MAE_before\", \"RMSE_before\", \"MAPE_before\"]]\n",
    ")\n",
    "\n",
    "after_df = (\n",
    "    pd.DataFrame(tuning_results)\n",
    "    .rename(columns={\n",
    "        \"Best_MAE\": \"MAE_after\",\n",
    "        \"Best_RMSE\": \"RMSE_after\",\n",
    "        \"Best_MAPE\": \"MAPE_after\"\n",
    "    })\n",
    "    [[\"Model\", \"MAE_after\", \"RMSE_after\", \"MAPE_after\"]]\n",
    ")\n",
    "\n",
    "final_models = (\n",
    "    before_df\n",
    "    .merge(after_df, on=\"Model\", how=\"left\")\n",
    "    .sort_values(\"MAE_before\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "baseline_row = pd.DataFrame([{\n",
    "    \"Model\": \"SeasonalNaive\",\n",
    "    \"MAE_before\": baseline_df.loc[baseline_df[\"Model\"] == \"SeasonalNaive\", \"MAE\"].values[0],\n",
    "    \"RMSE_before\": baseline_df.loc[baseline_df[\"Model\"] == \"SeasonalNaive\", \"RMSE\"].values[0],\n",
    "    \"MAPE_before\": baseline_df.loc[baseline_df[\"Model\"] == \"SeasonalNaive\", \"MAPE\"].values[0],\n",
    "    \"MAE_after\": np.nan,\n",
    "    \"RMSE_after\": np.nan,\n",
    "    \"MAPE_after\": np.nan,\n",
    "}])\n",
    "\n",
    "final_table = pd.concat(\n",
    "    [final_models, baseline_row],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "final_table[\"Model\"] = pd.Categorical(\n",
    "    final_table[\"Model\"],\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "final_table = final_table.sort_values(\"Model\").reset_index(drop=True)\n",
    "\n",
    "print(final_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210",
   "metadata": {},
   "source": [
    "|     *Model*      | MAE_before | RMSE_before | MAPE_before | MAE_after | RMSE_after | MAPE_after |\n",
    "| :--------------: | :--------: | :---------: | :---------: | :-------: | :--------: | :--------: |\n",
    "| LinearRegression |  2.027226  |  3.119120   |  0.056081   |     -     |     -      |     -      |\n",
    "|   RandomForest   |  2.217789  |  3.481925   |  0.065677   | 2.210768  |  3.470076  |  0.065812  |\n",
    "|     Bagging      |  2.382228  |  3.658807   |  0.067565   | 2.221170  |  3.478677  |  0.065382  |\n",
    "|     LightGBM     |  2.299236  |  3.589891   |  0.069324   | 2.262874  |  3.543766  |  0.068422  |\n",
    "| GradientBoosting |  2.331883  |  3.632150   |  0.068788   | 2.273512  |  3.620644  |  0.070329  |\n",
    "|     XGBoost      |  2.436203  |  3.772397   |  0.077259   | 2.279497  |  3.595189  |  0.070680  |\n",
    "|       SVR        |  3.148904  |  5.650184   |  0.129055   | 2.527390  |  4.664315  |  0.083185  |\n",
    "|   DecisionTree   |  3.455143  |  5.299461   |  0.102029   | 2.717259  |  4.048858  |  0.079340  |\n",
    "|       KNN        |  3.926630  |  5.523529   |  0.124120   | 3.875492  |  5.433601  |  0.128079  |\n",
    "|  ***BASELINE***  |  **MAE**   |  **RMSE**   |  **MAPE**   |           |            |            |\n",
    "|  SeasonalNaive   |  7.570453  |  10.922027  |  0.236852   |     -     |     -      |     -      |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211",
   "metadata": {},
   "source": [
    "The *Seasonal Naïve* baseline performs substantially worse than all machine-learning models, confirming the value of learned approaches. Hyperparameter tuning improves most models slightly, with *Random Forest* achieving the best overall performance after tuning. *Linear Regression* performs strongly without tuning and remains competitive with ensemble methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = \"LinearRegression\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213",
   "metadata": {},
   "source": [
    "#### 4.2.5 Perform predictions\n",
    "\n",
    "After selecting the best-performing machine learning model and the optimal window size, the model is retrained on the full training dataset and used to generate forecasts on the unseen test set. Predictions are produced for both single-step (1 hour ahead) and multi-step (24 hours ahead) horizons.\n",
    "\n",
    "##### 4.2.5.1 Single-step\n",
    "\n",
    "In this step, the selected machine learning model is trained using the optimal sliding-window size and used to generate 1-step-ahead forecasts on the test set. The predicted electricity prices are then compared against the real observed values to assess the model’s short-term forecasting accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1step = clone(models_stage1[best_model])\n",
    "\n",
    "print(\"Training 1-step ahead model...\")\n",
    "model_1step.fit(X_train, y_train)\n",
    "\n",
    "y_pred_1step = model_1step.predict(X_test)\n",
    "print(\"1-step ahead model trained.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215",
   "metadata": {},
   "source": [
    "##### 4.2.5.2 Multi-step (24-step)\n",
    "\n",
    "For the 24-step ahead scenario, the model predicts the next 24 hourly prices simultaneously based on the input window. This task is more challenging, as prediction errors can accumulate across the forecasting horizon, and it assesses the model’s capability to learn daily patterns and longer-term temporal dynamics.\n",
    "\n",
    "Since `slideWindow` function returned a dataset and not `X` and `y` values, first, these variables must be extracted from the generated dataset in paragraph `4.2.1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_24 = df_sw_multi_step_train.filter(like=\"x\").values\n",
    "y_train_24 = df_sw_multi_step_train.filter(like=\"y\").values\n",
    "\n",
    "X_test_24 = df_sw_multi_step_test.filter(like=\"x\").values\n",
    "y_test_24 = df_sw_multi_step_test.filter(like=\"y\").values\n",
    "\n",
    "model_24step = clone(models_stage1[best_model])\n",
    "\n",
    "print(\"Training 24-step ahead model...\")\n",
    "model_24step.fit(X_train_24, y_train_24)\n",
    "\n",
    "y_pred_24step = model_24step.predict(X_test_24)\n",
    "print(\"24-step ahead model trained.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217",
   "metadata": {},
   "source": [
    "#### 4.2.5.3 Plots comparing predictions vs. real test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(y_test[:200], label=\"Actual\")\n",
    "plt.plot(y_pred_1step[:200], label=\"Prediction\")\n",
    "plt.title(\"1-Step Ahead Prediction vs Actual\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Target\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219",
   "metadata": {},
   "source": [
    "The 1-step ahead prediction closely follows the actual electricity price series, capturing both short-term fluctuations and larger trend changes with high accuracy. Small deviations mainly appear around sharp peaks and sudden drops, which is expected since abrupt changes are harder to predict from past values alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(y_test_24[0], marker=\"o\", label=\"Actual (24h)\")\n",
    "plt.plot(y_pred_24step[0], marker=\"x\", label=\"Prediction (24h)\")\n",
    "plt.title(\"24-Step Ahead Forecast (First Test Window)\")\n",
    "plt.xlabel(\"Forecast Horizon (hours)\")\n",
    "plt.ylabel(\"Target\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "y_test_full = y_test_24[:, 0]\n",
    "y_pred_full = y_pred_24step[:, 0]\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(y_test_full, label=\"Actual\")\n",
    "plt.plot(y_pred_full, label=\"Predicted\")\n",
    "plt.title(\"24-step Model – 1-hour Ahead Predictions over Full Test Set\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Electricity Price\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221",
   "metadata": {},
   "source": [
    "The first plot (24-step ahead, first test window) shows poor accuracy because it is a direct multi-output forecast, where the model must predict all 24 future hours at once; errors accumulate quickly and the model struggles to capture the full daily amplitude and level.\n",
    "\n",
    "The second plot (full test set) looks much better because it effectively evaluates many overlapping short-horizon predictions, where the model mainly follows the overall pattern and seasonality, even though individual point-wise errors are still present."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222",
   "metadata": {},
   "source": [
    "### 4.3 Deep Learning Models\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223",
   "metadata": {},
   "source": [
    "LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 1. Data Preparation\n",
    "# ==========================================\n",
    "WINDOW_SIZE = 48  # Lookback period (e.g., 48 hours)\n",
    "BATCH_SIZE = 32   # Hyperparameter to tune\n",
    "EPOCHS = 50       # Max epochs\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "train_scaled = scaler.fit_transform(train_dfML)\n",
    "test_scaled = scaler.transform(test_dfML)\n",
    "\n",
    "X_train_full, y_train_full = make_sliding_window(train_scaled, WINDOW_SIZE, horizon=1)\n",
    "X_test, y_test = make_sliding_window(test_scaled, WINDOW_SIZE, horizon=1)\n",
    "\n",
    "y_train_full = y_train_full[:, 0]\n",
    "y_test = y_test[:, 0]\n",
    "\n",
    "val_split = int(len(X_train_full) * 0.8)\n",
    "X_train, y_train = X_train_full[:val_split], y_train_full[:val_split]\n",
    "X_val, y_val = X_train_full[val_split:], y_train_full[val_split:]\n",
    "\n",
    "print(f\"Train shape: {X_train.shape}, Val shape: {X_val.shape}, Test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 2. LSTM Model Definition\n",
    "# ==========================================\n",
    "def build_lstm_model(input_shape):\n",
    "    lstm_model = Sequential()\n",
    "\n",
    "    # Input Layer\n",
    "    lstm_model.add(Input(shape=input_shape))\n",
    "\n",
    "    # LSTM Layer 1\n",
    "    lstm_model.add(LSTM(units=50, return_sequences=True))\n",
    "    lstm_model.add(Dropout(0.2))\n",
    "\n",
    "    # LSTM Layer 2\n",
    "    lstm_model.add(LSTM(units=25, return_sequences=False))\n",
    "    lstm_model.add(Dropout(0.2))\n",
    "\n",
    "    # Output Layer\n",
    "    lstm_model.add(Dense(1))\n",
    "\n",
    "    optimizer = Adam(learning_rate=0.0001)\n",
    "    lstm_model.compile(optimizer=optimizer, loss='mse')\n",
    "    return lstm_model\n",
    "\n",
    "\n",
    "lstm_model = build_lstm_model(input_shape=(X_train.shape[1], X_train.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 3. Training\n",
    "# ==========================================\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "history = lstm_model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('LSTM Training vs Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 4. Evaluation & Metrics\n",
    "# ==========================================\n",
    "y_pred_scaled = lstm_model.predict(X_test)\n",
    "\n",
    "def inverse_transform_target(pred_array, scaler, n_features):\n",
    "    dummy = np.zeros((len(pred_array), n_features))\n",
    "    dummy[:, 0] = pred_array.flatten()\n",
    "    return scaler.inverse_transform(dummy)[:, 0]\n",
    "\n",
    "y_pred_real = inverse_transform_target(y_pred_scaled, scaler, train_dfML.shape[1])\n",
    "y_test_real = inverse_transform_target(y_test.reshape(-1, 1), scaler, train_dfML.shape[1])\n",
    "\n",
    "mae = mean_absolute_error(y_test_real, y_pred_real)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_real, y_pred_real))\n",
    "non_zero_mask = y_test_real != 0\n",
    "mape = np.mean(np.abs((y_test_real[non_zero_mask] - y_pred_real[non_zero_mask]) / y_test_real[non_zero_mask])) * 100\n",
    "\n",
    "print(f\"\\nModel Performance:\")\n",
    "print(f\"MAE:  {mae:.4f}\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAPE: {mape:.4f}%\")\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(y_test_real[:200], label='Actual Price', color='blue')\n",
    "plt.plot(y_pred_real[:200], label='Predicted Price', color='red', linestyle='--')\n",
    "plt.title('LSTM Forecast: Actual vs Predicted (First 200 Hours)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229",
   "metadata": {},
   "source": [
    "RESULTS ANALYSIS\n",
    "\n",
    "The Long Short-Term Memory (LSTM) network demonstrated strong performance in capturing the temporal dependencies of electricity prices, achieving an MAE of 0.0959 and an RMSE of 0.1532. The high MAPE (82.15%) is attributed to the presence of near-zero prices in the test set rather than poor predictive quality.\n",
    "\n",
    "Visually, the LSTM predictions track the actual test data very closely, successfully replicating the daily seasonality and general trends of the market. A slight \"reaction delay\" was observed, which is expected in autoregressive models that rely on immediate past windows. While the model handles standard volatility well, it occasionally struggles with extreme, rapid fluctuations (drastic down-and-up movements), where it tends to smooth the curve rather than capturing the full amplitude of the sharpest spikes.\n",
    "\n",
    "The training process was stable, with training and validation loss curves converging naturally. The EarlyStopping mechanism was not triggered, and the optimal model weights were recorded at epoch 49 (out of 50). This continuous improvement throughout the training cycle indicates that the model had appropriate capacity and learning rate settings for this dataset, avoiding both premature convergence and overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230",
   "metadata": {},
   "source": [
    "GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import GRU\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 1. GRU Model Definition\n",
    "# ==========================================\n",
    "def build_gru_model(input_shape):\n",
    "    gru_model = Sequential()\n",
    "\n",
    "    # Input Layer\n",
    "    gru_model.add(Input(shape=input_shape))\n",
    "\n",
    "    # GRU Layer 1\n",
    "    gru_model.add(GRU(units=50, return_sequences=True))\n",
    "    gru_model.add(Dropout(0.2))\n",
    "\n",
    "    # GRU Layer 2\n",
    "    gru_model.add(GRU(units=25, return_sequences=False))\n",
    "    gru_model.add(Dropout(0.2))\n",
    "\n",
    "    # Output Layer\n",
    "    gru_model.add(Dense(1))\n",
    "\n",
    "    optimizer = Adam(learning_rate=0.0001)\n",
    "    gru_model.compile(optimizer=optimizer, loss='mse')\n",
    "    return gru_model\n",
    "\n",
    "\n",
    "gru_model = build_gru_model(input_shape=(X_train.shape[1], X_train.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 2. Training\n",
    "# ==========================================\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=20,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "history_gru = gru_model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history_gru.history['loss'], label='Training Loss')\n",
    "plt.plot(history_gru.history['val_loss'], label='Validation Loss')\n",
    "plt.title('GRU Training vs Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 3. Evaluation\n",
    "# ==========================================\n",
    "y_pred_scaled_gru = gru_model.predict(X_test)\n",
    "\n",
    "y_pred_real_gru = inverse_transform_target(y_pred_scaled_gru, scaler, train_dfML.shape[1])\n",
    "\n",
    "mae_gru = mean_absolute_error(y_test_real, y_pred_real_gru)\n",
    "rmse_gru = np.sqrt(mean_squared_error(y_test_real, y_pred_real_gru))\n",
    "non_zero_mask = y_test_real != 0\n",
    "mape_gru = np.mean(np.abs((y_test_real[non_zero_mask] - y_pred_real_gru[non_zero_mask]) / y_test_real[non_zero_mask])) * 100\n",
    "\n",
    "print(f\"\\nGRU Model Performance:\")\n",
    "print(f\"MAE:  {mae_gru:.4f}\")\n",
    "print(f\"RMSE: {rmse_gru:.4f}\")\n",
    "print(f\"MAPE: {mape_gru:.4f}%\")\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(y_test_real[:200], label='Actual Price', color='black', alpha=0.7)\n",
    "plt.plot(y_pred_real[:200], label='LSTM Prediction', color='red', linestyle='--', alpha=0.7)\n",
    "plt.plot(y_pred_real_gru[:200], label='GRU Prediction', color='green', linestyle='-.', alpha=0.7)\n",
    "plt.title('Comparison: LSTM vs GRU vs Actual (First 200 Hours)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235",
   "metadata": {},
   "source": [
    "GRU Analysis\n",
    "\n",
    "The Gated Recurrent Unit (GRU) model outperformed the LSTM on this dataset, achieving a lower MAE of 0.0822 (vs. 0.0959 for LSTM) and RMSE of 0.1381 (vs. 0.1532 for LSTM). This indicates that the GRU provided a slightly more accurate fit to the test data overall. As expected, the training time was shorter, 14 minutes insted of 18 for LSTM.\n",
    "\n",
    "Visually, the GRU predictions followed a very similar trajectory to the LSTM, closely tracking the actual price curve. This suggests that both recurrent architectures successfully captured the underlying temporal patterns of the electricity market. The fact that the simpler GRU architecture yielded better metrics suggests that the additional complexity of the LSTM (extra gates and separate cell state) was not necessary for this specific 1-step forecast task and may have introduced slight inefficiencies or noise.\n",
    "\n",
    "Similar to the LSTM, the GRU showed stable learning and continued to improve throughout the training process, with the best model weights saved at the final epoch 50. This confirms that the model did not overfit and could potentially benefit from an even longer training duration, though the current performance is already superior to the LSTM baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236",
   "metadata": {},
   "source": [
    "24-Step Ahead Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 1. Data Preparation for 24-Step Ahead\n",
    "# ==========================================\n",
    "def create_24h_window(data, window_size):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size - 24 + 1):\n",
    "        X.append(data[i:i + window_size])\n",
    "        y.append(data[i + window_size: i + window_size + 24, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "WINDOW_SIZE = 48\n",
    "\n",
    "X_train_24, y_train_24 = create_24h_window(train_scaled, WINDOW_SIZE)\n",
    "X_test_24, y_test_24 = create_24h_window(test_scaled, WINDOW_SIZE)\n",
    "\n",
    "val_split_24 = int(len(X_train_24) * 0.8)\n",
    "X_train_sub_24, y_train_sub_24 = X_train_24[:val_split_24], y_train_24[:val_split_24]\n",
    "X_val_24, y_val_24 = X_train_24[val_split_24:], y_train_24[val_split_24:]\n",
    "\n",
    "print(f\"Input Shape: {X_train_sub_24.shape}\")\n",
    "print(f\"Target Shape: {y_train_sub_24.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 2. LSTM Model for 24-Step Output\n",
    "# ==========================================\n",
    "model_24 = Sequential()\n",
    "# Input Layer\n",
    "model_24.add(Input(shape=(X_train_sub_24.shape[1], X_train_sub_24.shape[2])))\n",
    "\n",
    "# LSTM24 Layer 1\n",
    "model_24.add(LSTM(128, return_sequences=True))\n",
    "model_24.add(Dropout(0.2))\n",
    "\n",
    "# LSTM24 Layer 2\n",
    "model_24.add(LSTM(68, return_sequences=False))\n",
    "model_24.add(Dropout(0.2))\n",
    "\n",
    "# OUTPUT LAYER\n",
    "model_24.add(Dense(24))\n",
    "\n",
    "model_24.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 3. Training\n",
    "# ==========================================\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "history_24 = model_24.fit(\n",
    "    X_train_sub_24, y_train_sub_24,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(X_val_24, y_val_24),\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 4. Evaluation\n",
    "# ==========================================\n",
    "y_pred_scaled_24 = model_24.predict(X_test_24)\n",
    "\n",
    "n_samples = y_pred_scaled_24.shape[0]\n",
    "n_steps = 24\n",
    "n_features = train_dfML.shape[1]\n",
    "\n",
    "flat_preds = y_pred_scaled_24.reshape(-1, 1)\n",
    "dummy_preds = np.zeros((len(flat_preds), n_features))\n",
    "dummy_preds[:, 0] = flat_preds.flatten()\n",
    "flat_real_preds = scaler.inverse_transform(dummy_preds)[:, 0]\n",
    "\n",
    "y_pred_real_24 = flat_real_preds.reshape(n_samples, n_steps)\n",
    "\n",
    "flat_actuals = y_test_24.reshape(-1, 1)\n",
    "dummy_actuals = np.zeros((len(flat_actuals), n_features))\n",
    "dummy_actuals[:, 0] = flat_actuals.flatten()\n",
    "flat_real_actuals = scaler.inverse_transform(dummy_actuals)[:, 0]\n",
    "y_test_real_24 = flat_real_actuals.reshape(n_samples, n_steps)\n",
    "\n",
    "mae_24 = mean_absolute_error(y_test_real_24, y_pred_real_24)\n",
    "rmse_24 = np.sqrt(mean_squared_error(y_test_real_24, y_pred_real_24))\n",
    "mask_24 = y_test_real_24 != 0\n",
    "mape_24 = np.mean(np.abs((y_test_real_24[mask_24] - y_pred_real_24[mask_24]) / y_test_real_24[mask_24])) * 100\n",
    "\n",
    "print(f\"\\n24-Step Ahead Model Performance:\")\n",
    "print(f\"MAE:  {mae_24:.4f}\")\n",
    "print(f\"RMSE: {rmse_24:.4f}\")\n",
    "print(f\"MAPE: {mape_24:.4f}%\")\n",
    "\n",
    "\n",
    "sample_idx = 0\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(24), y_test_real_24[sample_idx], marker='o', label='Actual Day')\n",
    "plt.plot(range(24), y_pred_real_24[sample_idx], marker='x', linestyle='--', label='Predicted Day')\n",
    "plt.title(f'24-Hour Forecast for Sample #{sample_idx}')\n",
    "plt.xlabel('Hour of Day')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 5. Continuous Plot (Day-Ahead Simulation)\n",
    "# ==========================================\n",
    "\n",
    "stitched_pred = y_pred_real_24[::24].flatten()\n",
    "stitched_actual = y_test_real_24[::24].flatten()\n",
    "\n",
    "plot_hours = 240 # 10 days\n",
    "\n",
    "plot_hours = min(plot_hours, len(stitched_pred))\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "plt.plot(stitched_actual[:plot_hours], label='Actual Price', color='blue', alpha=0.6)\n",
    "\n",
    "plt.plot(stitched_pred[:plot_hours], label='Day-Ahead Prediction (Stitched)',\n",
    "         color='orange', linestyle='--', marker='.', markersize=5)\n",
    "\n",
    "plt.title(f'Day-Ahead Forecast: Continuous View (First {plot_hours} Hours)')\n",
    "plt.xlabel('Hours')\n",
    "plt.ylabel('Electricity Price')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "mae_stitched = mean_absolute_error(stitched_actual, stitched_pred)\n",
    "print(f\"Realistic Day-Ahead Operation MAE: {mae_stitched:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242",
   "metadata": {},
   "source": [
    "24-Step LSTM Analysis\n",
    "\n",
    "Predicting a full 24-hour horizon proved to be significantly more challenging than the 1-step task. The model achieved an MAE of 0.2650 and RMSE of 0.3563. These errors are roughly 3x higher than the 1-step GRU/LSTM models (MAE ~0.08), reflecting the inherent difficulty of forecasting an entire day without the ability to correct course using intermediate real values.\n",
    "\n",
    "On a larger scale, the model demonstrates a basic ability to follow the general market trend, confirming it learned the overall weekly and daily seasonality. A major limitation observed is a substantial \"phase shift\" or lag. When a rapid price drop occurs, the model often predicts this drop only after the event has passed (likely with a 24-hour delay). This suggests the model is relying heavily on persistence (repeating yesterday's pattern) rather than anticipating changes based on exogenous features like weather. Visually, the predictions are frequently \"off\" from the actual values, lacking the precision seen in the 1-step models. This is consistent with the EarlyStopping occurring at epoch 15 (best weights at epoch 5), indicating the model struggled to find a complex pattern and converged quickly to a simpler, safer suboptimal solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243",
   "metadata": {},
   "source": [
    "Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [16, 32, 64]\n",
    "results = {}\n",
    "\n",
    "for bs in batch_sizes:\n",
    "    print(f\"Testing Batch Size: {bs}\")\n",
    "    model = build_lstm_model(input_shape=(X_train.shape[1], X_train.shape[2]))\n",
    "\n",
    "    # Train\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=20,\n",
    "        batch_size=bs,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=[early_stop],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    best_val_loss = min(history.history['val_loss'])\n",
    "    results[bs] = best_val_loss\n",
    "    print(f\"Batch Size {bs} - Best Val Loss: {best_val_loss:.5f}\")\n",
    "\n",
    "print(\"Best Configuration:\", min(results, key=results.get))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tunable_lstm(input_shape, units, num_layers, dropout_rate=0.2):\n",
    "    tunable_lstm_model = Sequential()\n",
    "\n",
    "    # Input Layer\n",
    "    tunable_lstm_model.add(Input(shape=input_shape))\n",
    "\n",
    "    # First Layer (Always present)\n",
    "    return_seq = (num_layers > 1)\n",
    "    tunable_lstm_model.add(LSTM(units=units, return_sequences=return_seq))\n",
    "    tunable_lstm_model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Second Layer (Conditional)\n",
    "    if num_layers == 2:\n",
    "        tunable_lstm_model.add(LSTM(units=units // 2, return_sequences=False))\n",
    "        tunable_lstm_model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Output Layer\n",
    "    tunable_lstm_model.add(Dense(1))\n",
    "\n",
    "    optimizer = Adam(learning_rate=0.0001)\n",
    "    tunable_lstm_model.compile(optimizer=optimizer, loss='mse')\n",
    "    return tunable_lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Hyperparameter Tuning: Units & Layers\n",
    "# ==========================================\n",
    "\n",
    "units_options = [32, 64, 128]\n",
    "layers_options = [1, 2]\n",
    "\n",
    "tuning_results = []\n",
    "\n",
    "print(\"Starting Hyperparameter Tuning...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for units in units_options:\n",
    "    for layers in layers_options:\n",
    "        print(f\"Testing: {units} Units | {layers} Layers...\")\n",
    "\n",
    "        model = build_tunable_lstm(\n",
    "            input_shape=(X_train.shape[1], X_train.shape[2]),\n",
    "            units=units,\n",
    "            num_layers=layers\n",
    "        )\n",
    "\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=30,\n",
    "            batch_size=32, # Using your fixed best batch size\n",
    "            validation_data=(X_val, y_val),\n",
    "            callbacks=[early_stop],\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        best_val_loss = min(history.history['val_loss'])\n",
    "\n",
    "        tuning_results.append({\n",
    "            'units': units,\n",
    "            'layers': layers,\n",
    "            'val_loss': best_val_loss\n",
    "        })\n",
    "\n",
    "        print(f\"   -> Result: Best Val Loss = {best_val_loss:.5f}\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(\"Tuning Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(tuning_results)\n",
    "\n",
    "results_df = results_df.sort_values(by='val_loss', ascending=True)\n",
    "\n",
    "print(\"\\nTop 3 Configurations:\")\n",
    "print(results_df.head(3))\n",
    "\n",
    "best_config = results_df.iloc[0]\n",
    "print(f\"\\nWINNER: LSTM with {int(best_config['units'])} Units and {int(best_config['layers'])} Layers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248",
   "metadata": {},
   "source": [
    "Hyperparameter Analysis\n",
    "\n",
    "The tuning process revealed a clear preference for a simpler architecture. The configuration with 32 units achieved the lowest validation loss (0.000856), outperforming larger configurations like 128 units (0.000904) or 64 units (0.000981). The differences are extremly slow and multiple test showed that the results may vary depending on test.\n",
    "\n",
    "The fact that 1-layer models consistently outperformed 2-layer models (which did not appear in the top 3) suggests that the features in this dataset (price, weather, generation) are strong enough that a deeper, more complex network is not required. Adding a second layer likely introduced unnecessary noise or optimization difficulties rather than learning new abstractions.\n",
    "\n",
    "Selecting the 32-unit model not only improves accuracy but also significantly reduces the computational cost, making the model faster to train and lighter to deploy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Seasonal Naive\n",
    "# ==========================================\n",
    "seasonality = 168\n",
    "y_naive_pred = []\n",
    "y_naive_real = []\n",
    "\n",
    "test_values = test_dfML.iloc[:, 0].values # Assuming price is col 0\n",
    "\n",
    "for i in range(seasonality, len(test_values)):\n",
    "    y_naive_pred.append(test_values[i - seasonality])\n",
    "    y_naive_real.append(test_values[i])\n",
    "\n",
    "mae_naive = mean_absolute_error(y_naive_real, y_naive_pred)\n",
    "rmse_naive = np.sqrt(mean_squared_error(y_naive_real, y_naive_pred))\n",
    "print(f\"Baseline (Seasonal Naive) - MAE: {mae_naive:.4f}, RMSE: {rmse_naive:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(y_naive_real[:240], label='Actual Price', color='tab:blue', alpha=0.7)\n",
    "plt.plot(y_naive_pred[:240], label='10-Day Recursive Forecast', color='tab:orange', linestyle='--')\n",
    "\n",
    "plt.title(f'10-Day Recursive Forecast (LSTM)')\n",
    "plt.ylabel('Price (€)')\n",
    "plt.xlabel('Hours (0 to 240)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250",
   "metadata": {},
   "source": [
    "Naive Analysis\n",
    "\n",
    "The Seasonal Naive baseline performed significantly worse than the Deep Learning models, yielding an MAE of 0.4179 and RMSE of 0.5468. In comparison, the best-performing model (GRU) achieved an MAE of roughly 0.08, representing an improvement of approximately 80% over this baseline. This huge gap confirms that the project's complexity was justified.\n",
    "\n",
    "The graph appears to \"predict something\" in certain areas because electricity demand does have a strong weekly structure. The areas where the prediction looks \"random\" or fails completely represent times when exogenous factors (weather changes, wind generation, holidays) shifted the price away from the historical average. Because the Naïve model blindly copies the previous week's value , it cannot account for these dynamic changes, leading to large errors whenever the weather pattern changes from one week to the next.\n",
    "\n",
    "The poor performance of the Seasonal Naïve model demonstrates that electricity prices are not merely repetitive cycles. They are driven by complex, non-linear dependencies on weather and generation data, which only the Deep Learning models (LSTM/GRU) were able to successfully learn and predict."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Conclusions and Recommendations\n",
    "\n",
    "### 6.1 Summary of Findings\n",
    "\n",
    "\n",
    "### 6.2 Best Model Selection\n",
    "\n",
    "### 6.3 Future Work\n",
    "\n",
    "\n",
    "### 6.4 Lessons Learned\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252",
   "metadata": {},
   "source": [
    "## Project Notes and Team Collaboration\n",
    "\n",
    "### Team Members\n",
    "\n",
    "- Julia Kardasz 1250264\n",
    "- Mateusz Nowak 1250296\n",
    "- Emilia Pawlowska 1250230"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
