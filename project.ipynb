{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Bank Telemarketing Campaign - Predictive Modeling Project\n",
    "\n",
    "**Project Goal:** Build data-driven models to predict the success of telemarketing calls for long-term bank deposits\n",
    "\n",
    "**Dataset Period:** 2008-2013 (Global Financial Crisis)\n",
    "\n",
    "**Methodology:** CRISP-DM (Cross-Industry Standard Process for Data Mining)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## 1. Business Understanding\n",
    "\n",
    "### 1.1 Business Objectives\n",
    "- TODO: Define the business problem\n",
    "- TODO: Identify key stakeholders\n",
    "- TODO: Define success criteria for the project\n",
    "\n",
    "### 1.2 Project Goals\n",
    "- TODO: Translate business objectives into data mining goals\n",
    "- TODO: Define target variable\n",
    "- TODO: Identify evaluation metrics (accuracy, precision, recall, F1-score, ROC-AUC)\n",
    "\n",
    "### 1.3 Business Context\n",
    "- TODO: Describe the telemarketing campaign process\n",
    "- TODO: Explain the financial crisis context (2008-2013)\n",
    "- TODO: Define constraints and requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "# TODO: Add imports as needed\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# TODO: Add scikit-learn imports\n",
    "# TODO: Add any other libraries needed\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "import math\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Data Understanding\n",
    "\n",
    "### 2.1 Data Collection\n",
    "\n",
    "The first step is to load the dataset into the working environment. This involves importing the necessary libraries and reading the data file into a suitable data structure, namely, a DataFrame using Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('bank.csv', sep=';')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### 2.2 Data Description \n",
    "??? do we need to describe evetything since we have a file describing the dataframe\n",
    "- TODO: Examine dataset structure - \n",
    "- TODO: Identify features and their types\n",
    "- TODO: Document feature definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "##### Basic dataset information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "This dataser contains 41188 entries and 21 features, representing information collected from a direct marketing campaign by a Portuguese bank institution. Each row corresponds to a contact with a client and the goal is to predict whether the client purchased the term deposit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### 2.3 Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "#### Target variable analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "The target variable 'y' represents whether a customer will buy a long-term bank deposit or not.\n",
    "To check class imbalance we will to compare the number of records with 'yes' and 'no' values in *y* column and plot a bar plot to depict class distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target value\n",
    "goal = df['y']\n",
    "counts = goal.value_counts()\n",
    "percent = goal.value_counts(normalize=True)\n",
    "percent100 = goal.value_counts(normalize=True).mul(100).round(1).astype(str)+'%'\n",
    "pd.DataFrame({'y': counts,'percent': percent100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_summary = pd.DataFrame({\n",
    "    'class': counts.index,\n",
    "    'count': counts.values,\n",
    "    'percent': percent.values\n",
    "})\n",
    "\n",
    "print(subscription_summary)\n",
    "\n",
    "sns.countplot(data=df, x='y')\n",
    "plt.title('Purchase Class Distribution')\n",
    "plt.xlabel('Purchase (y)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "As an additional check, we will to calculate imbalance ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "imbalance_ratio = counts.min() / counts.max()\n",
    "print(f\"Imbalance ratio: {imbalance_ratio:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "Imbalance ratio is 0.13 (below 0.2) which means there's a severe imbalance. Dataset is dominated by non-purchase cases.\n",
    "Without adressing this imbalance, predictive models predicting \"no purchase\" would achieve high accuracy, but fail to identify potential buyers.\n",
    "\n",
    "To handle class imbalance we will use SMOTE combined with Tomek Links technique later on in paragraph `3.4`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "#### Univariate analysis\n",
    "In the next step, we will to extract numerical and categorical features from the dataset for separate analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "numericFeatures = list(df.select_dtypes(include='number').columns)\n",
    "categFeatures = list(set(df.columns) - set(numericFeatures))\n",
    "\n",
    "# Remove goal attribute\n",
    "goalAttrib = df.columns.values.tolist()[-1]\n",
    "if goalAttrib in categFeatures:\n",
    "    categFeatures.remove(goalAttrib)\n",
    "elif goalAttrib in numericFeatures:\n",
    "    numericFeatures.remove(goalAttrib)\n",
    "    \n",
    "print(len(numericFeatures),\" Numeric Features: \",numericFeatures)\n",
    "print(len(categFeatures),\" Categorical Features: \",categFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "Numerical features: ['age', 'duration', 'campaign', 'pdays', 'previous', 'emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed']\n",
    "\n",
    "Categorical features: ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'poutcome']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "#### Feature distribution analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "Now we will perform feature distribution analysis to examine how the data values are spread across the dataset. We will uar plots and histograms to visualise the distributions of categorical and numerical features. Box plots for numerical features will be skipped in this step, as they will be specifically used for outlier detection in paragraph `2.4.2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categ_feat_distribution():\n",
    "    nrows = math.ceil(len(categFeatures) / 2)\n",
    "    ncols = 2\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(16, nrows * 5))\n",
    "\n",
    "    axes = axes.flatten() if len(categFeatures) > 1 else [axes]\n",
    "\n",
    "    for i, col in enumerate(categFeatures):\n",
    "        df[col].value_counts().plot(kind='bar', ax=axes[i])\n",
    "        axes[i].set_title(f'{col} Counts')\n",
    "        axes[i].set_xlabel(col)\n",
    "        axes[i].set_ylabel('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "categ_feat_distribution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "There are 'unknown values present in several catagorical features, which represent missing data, which, in turn, distorts statistical summaries. Because of this we will revisit and redo this analysis after `Data Cleaning` to ensure accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = math.ceil(len(numericFeatures) / 2)\n",
    "ncols = 2\n",
    "\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(16, nrows * 5))\n",
    "\n",
    "for i, col in enumerate(numericFeatures):\n",
    "    row = i // ncols  \n",
    "    col_idx = i % ncols  \n",
    "    df[col].hist(bins=30, ax=axes[row, col_idx])\n",
    "    axes[row, col_idx].set_title(f'{col} Distribution')\n",
    "    axes[row, col_idx].set_xlabel(col)\n",
    "    axes[row, col_idx].set_ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "None of the numerical features has normal distribution. Only *age* distribution is close to normal distribution. *duration*, *campaign* and *previous* are strongly skewed to the right, whereas *euribor3m* and *nr.employed* are very slightly skewed to the left. *emp.var.rare*, *cons.conf.idx* and it can be ignored.\n",
    "\n",
    "*pdays* distribution is not accurate because of '999' value which indicates that the client hasn't been called before. There is a huge spike at 999, which inidicates that many clients are new targets for the campaign. Therefore, for more detailed interpretation, the analysis of this feature will be conducted again after `Data Cleaning`.\n",
    "\n",
    "The data represented by other variables is highly variable with clusters at different value ranges and lots of fluctuations in frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "skewed_cols = ['duration', 'campaign', 'previous']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "### 2.4 Data Quality Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "#### 2.4.1 Identify missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "In the first place, we will to check for missing values to ensure data completeness and avoid potential issues during analysis and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# % missing values by column\n",
    "\n",
    "nulls = df.isnull().sum()\n",
    "percent = round(nulls/df.shape[0]*100,3)\n",
    "nullvalues = pd.concat([nulls,percent], axis=1, keys=('Cont','%'))\n",
    "nullvalues\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "Since there are no empty cells and 'unknown' value indicates a missing value, `df.isnull()` cannot be used. It will return information that there are no missing values, hence the cells with 'unknown' must be checked manually (and not using a pre-build function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_unknown():\n",
    "    categorical_cols_with_unknown = ['job', 'marital', 'education', 'default', 'housing', 'loan']\n",
    "# Count 'unknown' in each column\n",
    "    unknown_counts = {col: (df[col] == 'unknown').sum() for col in categorical_cols_with_unknown}\n",
    "    unknown_df = pd.DataFrame.from_dict(unknown_counts, orient='index', columns=['Count'])\n",
    "    unknown_df['Percent'] = round(unknown_df['Count'] / df.shape[0] * 100, 3)\n",
    "    print(unknown_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_unknown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "Columns *job*, *marital*, *education*, *default*, *housing* and *loan*, as indicated in the `bank-information.txt` file, contain missing values labaled as 'unknown'. \n",
    "\n",
    "The frequency of 'unknown'; entries varies across columns, with *default* having the highest proportion at 20.87% (8,597 entries), followed by *education* at 4.20% (1,731 entries), *housing* and *loan* both at 2.40% (990 entries each), *job* at 0.80% (330 entries), and *marital* at 0.19% (80 entries)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "#### 2.4.2 Identify outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "Based on dataframe information in `paragraph 2.2` there might be potential outliers such as clients contacted up to 56 times in the *capmaign* variable. It can disproportionately influence analysis and model results.\n",
    "That's why now wewill to identify outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_plots = len(numericFeatures)\n",
    "cols = 2\n",
    "rows = math.ceil(num_plots / cols)\n",
    "\n",
    "plt.figure(figsize=(cols * 4, rows * 5)) \n",
    "\n",
    "for i, feature in enumerate(numericFeatures):\n",
    "    plt.subplot(rows, cols, i + 1)\n",
    "    sns.boxplot(data=df, x='y', y=feature, hue='y', palette={\"yes\": \"red\", \"no\": \"green\"})\n",
    "    plt.title(feature)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df[numericFeatures].quantile(0.25)\n",
    "Q3 = df[numericFeatures].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "outliers = ((df[numericFeatures] < (Q1 - 1.5 * IQR)) | (df[numericFeatures] > (Q3 + 1.5 * IQR)))\n",
    "print(\"Number of outliers per numeric feature:\")\n",
    "print(outliers.sum())\n",
    "\n",
    "outliers_cols = outliers.any()\n",
    "print(\"\\nColumns containing outliers:\")\n",
    "print(outliers_cols[outliers_cols].index.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "We performed outliers detection on all numerical features using the Interquartile Range (IQR) method and visualized it using boxplots.\n",
    "\n",
    "Features such as *previous*, *duration* and *campaign* contained a high number of outlier values.\n",
    "*age* and *pdays* alco contained a noticeable number out outliers.\n",
    "Several features, including *emp.var.rate*, *cons.price.idx*, *e8uribor3m* and *nr.employed*, showed no outliers according to the IQR method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "#### 2.4.3 Check data duplication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "The next step is to check for duplication, because duplicate records can cause biased insights and reduce the effectiveness of the model. Removing duplicates helps maintain the integrity of the data and ensures that each observation contributes uniquely to the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "There are 12 duplicated rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Data Preparation\n",
    "\n",
    "### 3.1 Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "The first thing to be perfomed is to handle missing values indicated in paragraph `2.4.1`.\n",
    "\n",
    "For the attributes with low number of missing values and multipule possible values, namely, *job*, *marital* and *education*, the missing values will be replaced with the most common value in the dataset related to the specific attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_cols = ['job', 'marital', 'education']\n",
    "\n",
    "for col in impute_cols:\n",
    "    most_common = df.loc[df[col] != 'unknown', col].mode()[0]\n",
    "    df.loc[df[col] == 'unknown', col] = most_common\n",
    "    print(f\"Imputed 'unknown' in '{col}' with: {most_common}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_unknown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "For columns *housing* and *loan* 'unknown' values are changed to 'no', because [...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_cols = ['default', 'housing', 'loan']\n",
    "\n",
    "\n",
    "for col in replace_cols:\n",
    "    df.loc[df[col] == 'unknown', col] = 'no'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_unknown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "Then we will to delete duplicates to avoid redundancy of data, as indicated in paragraph `2.4.3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate lines, if they exist\n",
    "\n",
    "shape_before = df.shape\n",
    "print('Shape before deleting duplicate values:',shape_before)\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "shape_after = df.shape\n",
    "print('Shape after deleting duplicate values:',shape_after)\n",
    "\n",
    "percent = round((1-shape_after[0]/shape_before[0])*100,3)\n",
    "print(f\"Percentage of duplicates rows droped: {percent}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "To remove outliers identified in paragraph `2.4.2` we will use Robust Scaler during `Data Transformation` in paragraph `3.3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.select_dtypes(include='object').columns:\n",
    "    print(f\"{col} unique values: {df[col].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58",
   "metadata": {},
   "source": [
    "Based on the information about unique values there were no inconsistencies to be fixed, however we will change value '999' in *pdays* variable to '-1'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 999 with -1 to mark 'never contacted'\n",
    "df.loc[:,'pdays'] = df['pdays'].replace(999, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60",
   "metadata": {},
   "source": [
    "Now we will redo the distribution analysis for categorical features and *pdays* variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "categ_feat_distribution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "ehe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Filter out -1 (i.e., only keep rows where pdays != -1)\n",
    "plt.hist(df[df['pdays'] != -1]['pdays'], bins=30, edgecolor='black')\n",
    "\n",
    "plt.title('Histogram of pdays (Only Previously Contacted Clients)')\n",
    "plt.xlabel('Days Since Last Contact')\n",
    "plt.ylabel('Number of Clients')\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64",
   "metadata": {},
   "source": [
    "We omitted '-1' values for the analysis purposes. \n",
    "*pdays* variable is not severly skewed but has two peaks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65",
   "metadata": {},
   "source": [
    "### 3.2 Bivariate analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, PlotCanvas = plt.subplots(nrows=math.ceil(len(categFeatures)/2), ncols=2, figsize=(16, 40))\n",
    "\n",
    "# Creating Grouped bar plots for each categorical predictor against the Target Variable \"class\"\n",
    "lin = 0\n",
    "for i, Categcol in enumerate(categFeatures):\n",
    "    col = i%2   \n",
    "    CrossTabResult=pd.crosstab(index=df[Categcol], columns=df['y'])\n",
    "    CrossTabResult.plot.bar(color=['green','red'], ax=PlotCanvas[lin,col])\n",
    "    if i%2 == 1:\n",
    "        lin = lin+1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67",
   "metadata": {},
   "source": [
    "These grouped bar charts display the frequency on the Y-axis and the category values on the X-axis. If the proportions of the target variable (e.g., 'yes' vs. 'no') are similar across all categories of a feature, it suggests that there is little to no relationship between that feature and the target.\n",
    "\n",
    "For example, if we look at a hypothetical plot like *day of week* vs. *y*, and observe that each day of a week has a similar 'yes' to 'no' ratio, it indicates that the day of week likely has no significant influence on *y*. In such cases, the feature and the target variable are likely not correlated. It can be also observed on the plot depicting *default* vs. *y*, *housing* vs. *y* and *loan* vs. *y*, which means that *default*, *housing* and *loan* are likely not correlated to *y*. \n",
    "\n",
    "However, there are a few variables that seems to be strongly correlated to *y*. Namely, *marital*, *poutcome*, *contact*, *job* and *education*. These variables do not maintain consistent proportions across the target classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = len(numericFeatures)\n",
    "cols = 3\n",
    "rows = math.ceil(num_features / cols)\n",
    "\n",
    "# Create histograms\n",
    "plt.figure(figsize=(5 * cols, 4 * rows))\n",
    "\n",
    "for i, feature in enumerate(numericFeatures): \n",
    "    plt.subplot(rows, cols, i + 1)\n",
    "    if feature == 'pdays':\n",
    "        sns.histplot(data=df[df['pdays'] != -1], x='pdays', hue='y', kde=True, bins=30, palette={\"yes\": \"red\", \"no\": \"green\"})\n",
    "    else:\n",
    "        sns.histplot(df, x=feature, hue='y', kde=True, bins=30, palette={\"yes\": \"red\", \"no\": \"green\"})\n",
    "    plt.title(feature)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69",
   "metadata": {},
   "source": [
    "Every variable except for *pdays* is dominated by 'no' class and *pdays* is dominated by 'yes' class, which means all of the variables are relevant for the predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70",
   "metadata": {},
   "source": [
    "### 3.3 Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71",
   "metadata": {},
   "source": [
    "There are a lot of categorical variables with multiple possible values. We will `get.dummies()` function to separate [...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfML = df.copy()\n",
    "\n",
    "dfML = pd.get_dummies(dfML, drop_first=True, dtype=int)\n",
    "\n",
    "dfML.rename({'y_yes': 'y'}, axis='columns', inplace = True)\n",
    "\n",
    "dfML.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73",
   "metadata": {},
   "source": [
    "We will also create a new variable - *never_contacted* - related to the variables: *previous* and *pdays*. Value '1' will indicate that the client has never been called by another campaign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfML.insert(\n",
    "    loc = dfML.columns.get_loc('pdays') + 1,  # insert after 'pdays'\n",
    "    column = 'never_contacted',\n",
    "    value = (dfML['pdays'] == -1).astype(int)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfML.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76",
   "metadata": {},
   "source": [
    "### 3.4 Data Transformation\n",
    "\n",
    "To enable models to use the dataframe, data transformation, including encoding categorical variables must be conducted. Each variable with only two values ('yes' and 'no' in this dataframe) will be changed to '1' and '0'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineerNumericFeatures = list(dfML.select_dtypes(include='number').columns)\n",
    "engineerCategFeatures = list(set(dfML.columns) - set(numericFeatures))\n",
    "\n",
    "for feature in engineerCategFeatures:\n",
    "    print(feature)\n",
    "    print(dfML[feature].unique())\n",
    "    if dfML[feature].dropna().isin(['yes', 'no']).all():\n",
    "        dfML[feature] = (dfML[feature].values == 'yes').astype(int)\n",
    "        print(dfML[feature].unique())\n",
    "\n",
    "dfML.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78",
   "metadata": {},
   "source": [
    "Since all of the skewed distrubutions concern variables with positive values we will use a logarithmic transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in skewed_cols:\n",
    "    df.loc[:,col] = np.log1p(df[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80",
   "metadata": {},
   "source": [
    "As indicated in paragraph `3.1`, we will Robust Scaler to handle outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = RobustScaler()\n",
    "\n",
    "# Fit the scaler on the numeric features and transform\n",
    "df.loc[:,outliers_cols] = scaler.fit_transform(df[outliers_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82",
   "metadata": {},
   "source": [
    "### 3.5 Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['y'])\n",
    "y = df['y']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Original dataframe\n",
    "# Combine features and target for training set\n",
    "train_df = X_train.copy()\n",
    "train_df['y'] = y_train\n",
    "\n",
    "# Combine features and target for testing set\n",
    "test_df = X_test.copy()\n",
    "test_df['y'] = y_test\n",
    "\n",
    "\n",
    "# This second dataframe is processed\n",
    "\n",
    "X = dfML.drop(columns=['y'])\n",
    "y = dfML['y']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_tomek = SMOTETomek(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote_tomek.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dfML = X_train_resampled.copy()\n",
    "train_dfML['y'] = y_train_resampled\n",
    "\n",
    "test_dfML = X_test.copy()\n",
    "test_dfML['y'] = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88",
   "metadata": {},
   "source": [
    "### 3.5 Feature Selection\n",
    "- TODO: Identify highly correlated features - DONE\n",
    "- TODO: Apply feature importance analysis - DONE\n",
    "- TODO: Select relevant features for modeling - DONE - two dataframes prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89",
   "metadata": {},
   "source": [
    "#### Filter Methods\n",
    "\n",
    "**Statistical Feature Selection**\n",
    "\n",
    "* Categorical vs Continuous---- ANOVA test\n",
    "* Categorical vs Categorical--- Chi-Square test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90",
   "metadata": {},
   "source": [
    "**Categorical vs categorical using Chi-Square Test**\n",
    "\n",
    "Chi-Square test is conducted to check the correlation between two categorical variables\n",
    " - Assumption(H0): The two columns are NOT related to each other\n",
    " - Result of Chi-Sq Test: The Probability of H0 being True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FunctionChisq(inpData, TargetVariable, CategoricalVariablesList):\n",
    "    # Creating an empty list of final selected predictors\n",
    "    FiltPredictors=[]\n",
    "\n",
    "    for predictor in CategoricalVariablesList:\n",
    "        CrossTabResult=pd.crosstab(index=inpData[TargetVariable], columns=inpData[predictor])\n",
    "        ChiSqResult = chi2_contingency(CrossTabResult)\n",
    "        \n",
    "        # If the ChiSq P-Value is <0.05, that means we reject H0\n",
    "        if (ChiSqResult[1] < 0.05):\n",
    "            print(predictor, 'is correlated with', TargetVariable, '| P-Value:', ChiSqResult[1])\n",
    "        else:\n",
    "            print(predictor, 'is NOT correlated with', TargetVariable, '| P-Value:', ChiSqResult[1]) \n",
    "            FiltPredictors.append(predictor)\n",
    "            \n",
    "    return(FiltPredictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {},
   "outputs": [],
   "source": [
    "filterCateg = FunctionChisq(inpData=train_df, TargetVariable='y', CategoricalVariablesList= categFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93",
   "metadata": {},
   "source": [
    "The Chi-square test proves that *default*, *housing and *loan* are not correclated with y, which was shown on the plots (3.2). \n",
    "For example: while the raw counts of loan categories vary significantly, the proportion of clients who purchased the deposit (y = yes) is similar between those with and without loans. This is reflected in a high p-value (~0.98), indicating no statistically significant association between loan status and the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94",
   "metadata": {},
   "source": [
    "**Continuous vs categorical using ANOVA test**\n",
    " \n",
    "   - Assumption(H0): There is NO relation between the given variables (i.e. the average(mean) values of the numeric    predictor variable is same for all the groups in the categorical Target variable)\n",
    "\n",
    "ANOVA Test result: Probability of H0 being true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FunctionAnova(inpData, TargetVariable, ContinuousPredictorList):\n",
    "    from scipy.stats import f_oneway\n",
    "\n",
    "    # Creating an empty list of final selected predictors\n",
    "    FiltPredictors=[]\n",
    "    \n",
    "    print('##### ANOVA Results ##### \\n')\n",
    "    for predictor in ContinuousPredictorList:\n",
    "        CategoryGroupLists=inpData.groupby(TargetVariable)[predictor].apply(list)\n",
    "        AnovaResults = f_oneway(*CategoryGroupLists)\n",
    "        \n",
    "        # If the ANOVA P-Value is <0.05, that means we reject H0\n",
    "        if (AnovaResults[1] < 0.05):\n",
    "            print(predictor, 'is correlated with', TargetVariable, '| P-Value:', AnovaResults[1])\n",
    "        else:\n",
    "            print(predictor, 'is NOT correlated with', TargetVariable, '| P-Value:', AnovaResults[1])\n",
    "            FiltPredictors.append(predictor)\n",
    "            \n",
    "    return(FiltPredictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the function to check which numeric variables are correlated with target\n",
    "df_anova = train_df[train_df,['pdays'] != -1]  # remove -1s\n",
    "\n",
    "filterNumeric = FunctionAnova(inpData=df_anova TargetVariable='y', ContinuousPredictorList = numericFeatures)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97",
   "metadata": {},
   "outputs": [],
   "source": [
    "FilterColumns = filterCateg + filterNumeric\n",
    "\n",
    "print(f\"Removed features by Filter methods: {FilterColumns}\")\n",
    "\n",
    "# Prepare df1 to be used by KNN\n",
    "\n",
    "df1 = train_dfML.copy()\n",
    "\n",
    "#Drop columns: gender and PhoneService (excluded by Chi-Square test)\n",
    "df1.drop(columns=FilterColumns, axis=1, inplace=True)\n",
    "\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_regularization(df):\n",
    "\n",
    "    X = df.iloc[:,:-1].copy()          \n",
    "    y = df.iloc[:,-1].copy() \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    # fit a Logistic Regression model and feature selection altogether \n",
    "    # select the Lasso (l1) penalty.\n",
    "    # The selectFromModel class from sklearn, selects the features which coefficients are non-zero\n",
    "\n",
    "    sel_ = SelectFromModel(LogisticRegression(C=0.5, penalty='l1', solver='liblinear', random_state=10))\n",
    "\n",
    "    sel_.fit(scaler.transform(X_train), y_train)\n",
    "\n",
    "    # make a list with the selected features\n",
    "    selected_feat = X_train.columns[(sel_.get_support())]\n",
    "    \n",
    "    print(\"Number of features which coefficient was shrank to zero: \", np.sum(sel_.estimator_.coef_ == 0))\n",
    "    # identify the removed features like this:\n",
    "    removed_feats = X_train.columns[(sel_.estimator_.coef_ == 0).ravel().tolist()]\n",
    "    print('Removed features by Lasso: ',removed_feats) \n",
    "\n",
    "    return X_train.columns[(sel_.estimator_.coef_ != 0).ravel().tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lasso_SelectedColumns = lasso_regularization(train_dfML)\n",
    "\n",
    "Lasso_SelectedColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = train_dfML[Lasso_SelectedColumns].copy()\n",
    "\n",
    "df2['y'] = train_dfML['y']\n",
    "\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Modeling\n",
    "\n",
    "### 4.1 Baseline Model\n",
    "- TODO: Create a simple baseline model (e.g., majority class classifier)\n",
    "- TODO: Evaluate baseline performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline model\n",
    "# TODO: Implement baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103",
   "metadata": {},
   "source": [
    "### 4.2 Model Selection\n",
    "- TODO: Train multiple algorithms from class:\n",
    "  - Logistic Regression\n",
    "  - Decision Trees\n",
    "  - Random Forest\n",
    "  - Gradient Boosting (XGBoost, LightGBM)\n",
    "  - Support Vector Machines\n",
    "  - Neural Networks\n",
    "  - K-Nearest Neighbors\n",
    "  - Naive Bayes\n",
    "  - TODO: Add others as covered in class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: Logistic Regression\n",
    "# TODO: Train and evaluate logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2: Decision Tree\n",
    "# TODO: Train and evaluate decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3: Random Forest\n",
    "# TODO: Train and evaluate random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 4: Gradient Boosting\n",
    "# TODO: Train and evaluate gradient boosting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 5: Support Vector Machine\n",
    "# TODO: Train and evaluate SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 6: [Add more models as needed]\n",
    "# TODO: Train and evaluate additional models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110",
   "metadata": {},
   "source": [
    "### 4.3 Hyperparameter Tuning\n",
    "- TODO: Define hyperparameter search space\n",
    "- TODO: Apply Grid Search or Random Search\n",
    "- TODO: Use cross-validation for tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning - Model 1\n",
    "# TODO: Implement GridSearchCV or RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning - Model 2\n",
    "# TODO: Implement hyperparameter tuning for other promising models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113",
   "metadata": {},
   "source": [
    "### 4.4 Ensemble Methods\n",
    "- TODO: Create ensemble models (voting, stacking, blending)\n",
    "- TODO: Combine best performing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble models\n",
    "# TODO: Implement ensemble techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Evaluation\n",
    "\n",
    "### 5.1 Model Performance Metrics\n",
    "- TODO: Calculate accuracy, precision, recall, F1-score\n",
    "- TODO: Generate ROC curves and calculate AUC\n",
    "- TODO: Create confusion matrices\n",
    "- TODO: Calculate business-relevant metrics (cost/benefit analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation metrics\n",
    "# TODO: Calculate and compare all metrics across models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model performance\n",
    "# TODO: Create ROC curves, precision-recall curves\n",
    "# TODO: Create confusion matrices\n",
    "# TODO: Create comparison charts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118",
   "metadata": {},
   "source": [
    "### 5.2 Model Interpretation\n",
    "- TODO: Analyze feature importance\n",
    "- TODO: Interpret model predictions\n",
    "- TODO: Validate model behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance analysis\n",
    "# TODO: Extract and visualize feature importance from models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model interpretation\n",
    "# TODO: Use SHAP, LIME, or other interpretation methods if applicable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121",
   "metadata": {},
   "source": [
    "### 5.3 Model Validation\n",
    "- TODO: Perform cross-validation\n",
    "- TODO: Test on holdout set\n",
    "- TODO: Check for overfitting/underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation\n",
    "# TODO: Perform k-fold cross-validation on best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final model evaluation on test set\n",
    "# TODO: Evaluate final model(s) on unseen test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124",
   "metadata": {},
   "source": [
    "### 5.4 Business Impact Assessment\n",
    "- TODO: Translate model performance to business value\n",
    "- TODO: Calculate expected ROI or cost savings\n",
    "- TODO: Provide actionable recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Business impact analysis\n",
    "# TODO: Calculate business metrics (conversion rate improvement, cost reduction, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Conclusions and Recommendations\n",
    "\n",
    "### 6.1 Summary of Findings\n",
    "- TODO: Summarize key insights from data exploration\n",
    "- TODO: Summarize model performance\n",
    "- TODO: Identify most important predictive features\n",
    "\n",
    "### 6.2 Best Model Selection\n",
    "- TODO: Select and justify the best model\n",
    "- TODO: Document model strengths and limitations\n",
    "\n",
    "### 6.3 Recommendations\n",
    "- TODO: Provide actionable business recommendations\n",
    "- TODO: Suggest customer prioritization strategy\n",
    "- TODO: Recommend campaign optimization strategies\n",
    "\n",
    "### 6.4 Future Work\n",
    "- TODO: Suggest model improvements\n",
    "- TODO: Identify additional data needs\n",
    "- TODO: Propose deployment strategy\n",
    "\n",
    "### 6.5 Lessons Learned\n",
    "- TODO: Document challenges faced\n",
    "- TODO: Share insights from the project\n",
    "- TODO: Note what would be done differently\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127",
   "metadata": {},
   "source": [
    "## Project Notes and Team Collaboration\n",
    "\n",
    "### Team Members\n",
    "- TODO: List team members and responsibilities\n",
    "Julia Kardasz 1250264\n",
    "\n",
    "### Project Timeline\n",
    "- TODO: Document project milestones and deadlines\n",
    "\n",
    "### References\n",
    "- TODO: Add references to papers, documentation, and resources used\n",
    "\n",
    "---\n",
    "*This notebook follows the CRISP-DM methodology for data mining projects*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (jupyter-env)",
   "language": "python",
   "name": "jupyter-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
