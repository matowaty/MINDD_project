{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Bank Telemarketing Campaign - Predictive Modeling Project\n",
    "\n",
    "**Project Goal:** Build data-driven models to predict the success of telemarketing calls for long-term bank deposits\n",
    "\n",
    "**Dataset Period:** 2008-2013 (Global Financial Crisis)\n",
    "\n",
    "**Methodology:** CRISP-DM (Cross-Industry Standard Process for Data Mining)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## 1. Business Understanding\n",
    "\n",
    "### 1.1 Business Objectives\n",
    "- TODO: Define the business problem\n",
    "- TODO: Identify key stakeholders\n",
    "- TODO: Define success criteria for the project\n",
    "\n",
    "### 1.2 Project Goals\n",
    "- TODO: Translate business objectives into data mining goals\n",
    "- TODO: Define target variable\n",
    "- TODO: Identify evaluation metrics (accuracy, precision, recall, F1-score, ROC-AUC)\n",
    "\n",
    "### 1.3 Business Context\n",
    "- TODO: Describe the telemarketing campaign process\n",
    "- TODO: Explain the financial crisis context (2008-2013)\n",
    "- TODO: Define constraints and requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "# TODO: Add imports as needed\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# TODO: Add scikit-learn imports\n",
    "# TODO: Add any other libraries needed\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "import math\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Data Understanding\n",
    "\n",
    "### 2.1 Data Collection\n",
    "- TODO: Load the dataset - DONE\n",
    "- TODO: Document data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('bank.csv', sep=';')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### 2.2 Data Description\n",
    "- TODO: Examine dataset structure\n",
    "- TODO: Identify features and their types\n",
    "- TODO: Document feature definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic dataset information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### 2.3 Data Exploration\n",
    "- TODO: Analyze target variable distribution - DONE\n",
    "- TODO: Check for class imbalance - DONE\n",
    "- TODO: Explore feature distributions - DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "The target variable 'y' represents whether a customer will buy a long-term bank deposit or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target value\n",
    "goal = df['y']\n",
    "counts = goal.value_counts()\n",
    "percent = goal.value_counts(normalize=True)\n",
    "percent100 = goal.value_counts(normalize=True).mul(100).round(1).astype(str)+'%'\n",
    "pd.DataFrame({'y': counts,'percent': percent100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_summary = pd.DataFrame({\n",
    "    'class': counts.index,\n",
    "    'count': counts.values,\n",
    "    'percent': percent.values\n",
    "})\n",
    "\n",
    "print(subscription_summary)\n",
    "\n",
    "sns.countplot(data=df, x='y')\n",
    "plt.title('Subscription Class Distribution')\n",
    "plt.xlabel('Subscription (y)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "imbalance_ratio = counts.min() / counts.max()\n",
    "print(f\"Imbalance ratio: {imbalance_ratio:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "Imbalance ratio is below 0.2 which means there's a severe imbalance. Dataset is dominated by non\n",
    "Without adressing this imbalance, predictive models predicting \"no purchase\" would achieve high accuracy, but fail to identify potential buyers.\n",
    "\n",
    "To handle class imbalance we will use SMOTE combined with Tomek Links technique later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariate analysis\n",
    "# TODO: Analyze numerical features\n",
    "# TODO: Analyze categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate numerical and categorical features\n",
    "numericFeatures = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categFeatures = [col for col in df.select_dtypes(include=['object', 'category']).columns if col != 'y']\n",
    "\n",
    "print(\"Numerical features:\", numericFeatures)\n",
    "print(\"Categorical features:\", categFeatures)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bivariate analysis - shouldnt it be later???\n",
    "# TODO: Analyze relationships with target variable\n",
    "# TODO: Correlation analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### 2.4 Data Quality Assessment\n",
    "- TODO: Check for missing values - DONE\n",
    "- TODO: Identify outliers - DONE\n",
    "- TODO: Check for duplicates - DONE\n",
    "- TODO: Identify data quality issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data quality checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# % missing values by column\n",
    "\n",
    "nulls = df.isnull().sum()\n",
    "percent = round(nulls/df.shape[0]*100,3)\n",
    "nullvalues = pd.concat([nulls,percent], axis=1, keys=('Cont','%'))\n",
    "nullvalues\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_unknown():\n",
    "    categorical_cols_with_unknown = ['job', 'marital', 'education', 'default', 'housing', 'loan']\n",
    "# Count 'unknown' in each column\n",
    "    unknown_counts = {col: (df[col] == 'unknown').sum() for col in categorical_cols_with_unknown}\n",
    "    unknown_df = pd.DataFrame.from_dict(unknown_counts, orient='index', columns=['Count'])\n",
    "    unknown_df['Percent'] = round(unknown_df['Count'] / df.shape[0] * 100, 3)\n",
    "    print(unknown_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_unknown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "There are "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_plots = len(numericFeatures)\n",
    "cols = 2\n",
    "rows = math.ceil(num_plots / cols)\n",
    "\n",
    "plt.figure(figsize=(cols * 4, rows * 5)) \n",
    "\n",
    "for i, feature in enumerate(numericFeatures):\n",
    "    plt.subplot(rows, cols, i + 1)\n",
    "    sns.boxplot(data=df, x='y', y=feature, hue='y', palette={\"yes\": \"red\", \"no\": \"green\"})\n",
    "    plt.title(feature)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df[numericFeatures].quantile(0.25)\n",
    "Q3 = df[numericFeatures].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "outliers = ((df[numericFeatures] < (Q1 - 1.5 * IQR)) | (df[numericFeatures] > (Q3 + 1.5 * IQR)))\n",
    "print(\"Number of outliers per numeric feature:\")\n",
    "print(outliers.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "We performed outliers detection on all numerical features using the Interquartile Range (IQR) method and visualized it using boxplots.\n",
    "\n",
    "Features such as *previous*, *duration* and *campaign* contained a high number of outlier values.\n",
    "*age* and *pdays* alco contained a noticeable number out outliers.\n",
    "Several features, including *emp.var.rate*, *cons.price.idx*, e8uribor3m* and *nr.employed*, showed no outliers according to the IQR method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate lines, if they exist\n",
    "\n",
    "shape_before = df.shape\n",
    "print('Shape before deleting duplicate values:',shape_before)\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "shape_after = df.shape\n",
    "print('Shape after deleting duplicate values:',shape_after)\n",
    "\n",
    "percent = round((1-shape_after[0]/shape_before[0])*100,3)\n",
    "print(f\"Percentage of duplicates rows droped: {percent}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "There are 12 duplicated rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Data Preparation\n",
    "\n",
    "### 3.1 Data Cleaning\n",
    "- TODO: Handle missing values - DONE\n",
    "- TODO: Remove/treat outliers - We will use Robust Scaler.\n",
    "- TODO: Remove duplicates - DONE\n",
    "- TODO: Fix data inconsistencies - DONE (there were none)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "The first thing to be perfomed is to handle missing values indicated in paragraph 2.4 [...].\n",
    "For the attributes with low numbers of missing values, namely, *job*, *marital* and *education*, the missing values will be replaced with the most common value in the dataset related to the specific attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_cols = ['job', 'marital', 'education']\n",
    "\n",
    "for col in impute_cols:\n",
    "    most_common = df.loc[df[col] != 'unknown', col].mode()[0]\n",
    "    df.loc[df[col] == 'unknown', col] = most_common\n",
    "    print(f\"Imputed 'unknown' in '{col}' with: {most_common}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_unknown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "For the the missing values of a more siginificant number, they are changed to 'no' because [...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_cols = ['default', 'housing', 'loan']\n",
    "\n",
    "for col in replace_cols:\n",
    "    df.loc[df[col] == 'unknown', col] = 'no'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_unknown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "Then the duplicates were deleted to avoid redundancy of data. [...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate lines, if they exist\n",
    "\n",
    "shape_before = df.shape\n",
    "print('Shape before deleting duplicate values:',shape_before)\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "shape_after = df.shape\n",
    "print('Shape after deleting duplicate values:',shape_after)\n",
    "\n",
    "percent = round((1-shape_after[0]/shape_before[0])*100,3)\n",
    "print(f\"Percentage of duplicates rows droped: {percent}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.select_dtypes(include='object').columns:\n",
    "    print(f\"{col} unique values: {df[col].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "### 3.2 Bivariate analysis\n",
    "- TODO: Analyze relationships with target variable\n",
    "- TODO: Correlation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, PlotCanvas = plt.subplots(nrows=math.ceil(len(categFeatures)/2), ncols=2, figsize=(16, 40))\n",
    "\n",
    "# Creating Grouped bar plots for each categorical predictor against the Target Variable \"class\"\n",
    "lin = 0\n",
    "for i, Categcol in enumerate(categFeatures):\n",
    "    col = i%2   \n",
    "    CrossTabResult=pd.crosstab(index=df[Categcol], columns=df['y'])\n",
    "    CrossTabResult.plot.bar(color=['green','red'], ax=PlotCanvas[lin,col])\n",
    "    if i%2 == 1:\n",
    "        lin = lin+1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "These grouped bar charts display the frequency on the Y-axis and the category values on the X-axis. If the proportions of the target variable (e.g., \"yes\" vs. \"no\") are similar across all categories of a feature, it suggests that there is little to no relationship between that feature and the target.\n",
    "\n",
    "For example, if we look at a hypothetical plot like *day of week* vs. y*, and observe that each day of a week has a similar \"yes\" to \"no\" ratio, it indicates that the day of week likely has no significant influence on *y*. In such cases, the feature and the target variable are likely not correlated. It can be also observed on the plot depicting *default* vs. *y*, *housing* vs. *y* and *loan* vs. *y*, which means that *default*, *housing* and *loan* are likely not correlated to *y*. \n",
    "\n",
    "However, there are a few variables that seems to be strongly correlated to *y*. Namely, *marital*, *poutcome*, *contact*, *job* and *education*. These variables do not maintain consistent proportions across the target classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = len(numericFeatures)\n",
    "cols = 3\n",
    "rows = math.ceil(num_features / cols)\n",
    "\n",
    "# Create histograms\n",
    "plt.figure(figsize=(5 * cols, 4 * rows))\n",
    "\n",
    "for i, feature in enumerate(numericFeatures):\n",
    "    plt.subplot(rows, cols, i + 1)\n",
    "    sns.histplot(df, x=feature, hue='y', kde=True, bins=30, palette={\"yes\": \"red\", \"no\": \"green\"})\n",
    "    plt.title(feature)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "### 3.3 Data Transformation\n",
    "- TODO: Encode categorical variables - DONE\n",
    "- TODO: Scale/normalize numerical features - DONE\n",
    "- TODO: Handle skewed distributions - DONE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfML = df.copy()\n",
    "\n",
    "for feature in categFeatures:\n",
    "    print(feature)\n",
    "    print(dfML[feature].unique())\n",
    "    if dfML[feature].dropna().isin(['yes', 'no']).all():\n",
    "        dfML[feature] = (dfML[feature].values == 'yes').astype(int)\n",
    "        print(dfML[feature].unique())\n",
    "\n",
    "dfML.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfML = pd.get_dummies(dfML, drop_first=True, dtype=int)\n",
    "\n",
    "dfML.rename({'y_yes': 'y'}, axis='columns', inplace = True)\n",
    "\n",
    "dfML.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['age', 'duration', 'campaign', 'pdays', 'previous', 'emp.var.rate', \n",
    "                    'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed']\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = RobustScaler()\n",
    "\n",
    "# Fit the scaler on the numeric features and transform\n",
    "df[numeric_features] = scaler.fit_transform(df[numeric_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "### 3.3 Feature Engineering ???\n",
    "- TODO: Create new features from existing ones\n",
    "- TODO: Create interaction features\n",
    "- TODO: Create time-based features if applicable\n",
    "- TODO: Create domain-specific features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "# TODO: Create new features based on domain knowledge and EDA insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "### 3.4 Data Splitting\n",
    "- TODO: Split data into training and test sets - DONE\n",
    "- TODO: Handle class imbalance if necessary (SMOTE, undersampling, etc.) - DONE \n",
    "- TODO: Set up cross-validation strategy ??? why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['y'])\n",
    "y = df['y']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Original dataframe\n",
    "# Combine features and target for training set\n",
    "train_df = X_train.copy()\n",
    "train_df['y'] = y_train\n",
    "\n",
    "# Combine features and target for testing set\n",
    "test_df = X_test.copy()\n",
    "test_df['y'] = y_test\n",
    "\n",
    "\n",
    "# This second dataframe is processed\n",
    "\n",
    "X = dfML.drop(columns=['y'])\n",
    "y = dfML['y']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote_tomek = SMOTETomek(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote_tomek.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dfML = X_train_resampled.copy()\n",
    "train_dfML['y'] = y_train_resampled\n",
    "\n",
    "test_dfML = X_test.copy()\n",
    "test_dfML['y'] = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60",
   "metadata": {},
   "source": [
    "### 3.5 Feature Selection\n",
    "- TODO: Identify highly correlated features - DONE\n",
    "- TODO: Apply feature importance analysis - DONE\n",
    "- TODO: Select relevant features for modeling - DONE - two dataframes prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {},
   "source": [
    "#### Filter Methods\n",
    "\n",
    "**Statistical Feature Selection**\n",
    "\n",
    "* Continuous vs Continuous ---- Correlation matrix\n",
    "* Categorical vs Continuous---- ANOVA test\n",
    "* Categorical vs Categorical--- Chi-Square test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "**Categorical vs categorical using Chi-Square Test**\n",
    "\n",
    "Chi-Square test is conducted to check the correlation between two categorical variables\n",
    " - Assumption(H0): The two columns are NOT related to each other\n",
    " - Result of Chi-Sq Test: The Probability of H0 being True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FunctionChisq(inpData, TargetVariable, CategoricalVariablesList):\n",
    "    # Creating an empty list of final selected predictors\n",
    "    FiltPredictors=[]\n",
    "\n",
    "    for predictor in CategoricalVariablesList:\n",
    "        CrossTabResult=pd.crosstab(index=inpData[TargetVariable], columns=inpData[predictor])\n",
    "        ChiSqResult = chi2_contingency(CrossTabResult)\n",
    "        \n",
    "        # If the ChiSq P-Value is <0.05, that means we reject H0\n",
    "        if (ChiSqResult[1] < 0.05):\n",
    "            print(predictor, 'is correlated with', TargetVariable, '| P-Value:', ChiSqResult[1])\n",
    "        else:\n",
    "            print(predictor, 'is NOT correlated with', TargetVariable, '| P-Value:', ChiSqResult[1]) \n",
    "            FiltPredictors.append(predictor)\n",
    "            \n",
    "    return(FiltPredictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "filterCateg = FunctionChisq(inpData=train_df, TargetVariable='y', CategoricalVariablesList= categFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65",
   "metadata": {},
   "source": [
    "The Chi-square test proves that *default*, *housing and *loan* are not correclated with y, which was shown on the plots (3.2). \n",
    "For example: while the raw counts of loan categories vary significantly, the proportion of clients who purchased the deposit (y = yes) is similar between those with and without loans. This is reflected in a high p-value (~0.98), indicating no statistically significant association between loan status and the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66",
   "metadata": {},
   "source": [
    "**Continuous vs categorical using ANOVA test**\n",
    " \n",
    "   - Assumption(H0): There is NO relation between the given variables (i.e. the average(mean) values of the numeric    predictor variable is same for all the groups in the categorical Target variable)\n",
    "\n",
    "ANOVA Test result: Probability of H0 being true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FunctionAnova(inpData, TargetVariable, ContinuousPredictorList):\n",
    "    from scipy.stats import f_oneway\n",
    "\n",
    "    # Creating an empty list of final selected predictors\n",
    "    FiltPredictors=[]\n",
    "    \n",
    "    print('##### ANOVA Results ##### \\n')\n",
    "    for predictor in ContinuousPredictorList:\n",
    "        CategoryGroupLists=inpData.groupby(TargetVariable)[predictor].apply(list)\n",
    "        AnovaResults = f_oneway(*CategoryGroupLists)\n",
    "        \n",
    "        # If the ANOVA P-Value is <0.05, that means we reject H0\n",
    "        if (AnovaResults[1] < 0.05):\n",
    "            print(predictor, 'is correlated with', TargetVariable, '| P-Value:', AnovaResults[1])\n",
    "        else:\n",
    "            print(predictor, 'is NOT correlated with', TargetVariable, '| P-Value:', AnovaResults[1])\n",
    "            FiltPredictors.append(predictor)\n",
    "            \n",
    "    return(FiltPredictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the function to check which numeric variables are correlated with target\n",
    "\n",
    "filterNumeric = FunctionAnova(inpData=train_df, TargetVariable='y', ContinuousPredictorList = numericFeatures)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "FilterColumns = filterCateg + filterNumeric\n",
    "\n",
    "print(f\"Removed features by Filter methods: {FilterColumns}\")\n",
    "\n",
    "# Prepare df1 to be used by KNN\n",
    "\n",
    "df1 = train_dfML.copy()\n",
    "\n",
    "#Drop columns: gender and PhoneService (excluded by Chi-Square test)\n",
    "df1.drop(columns=FilterColumns, axis=1, inplace=True)\n",
    "\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_regularization(df):\n",
    "\n",
    "    X = df.iloc[:,:-1].copy()          \n",
    "    y = df.iloc[:,-1].copy() \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    # fit a Logistic Regression model and feature selection altogether \n",
    "    # select the Lasso (l1) penalty.\n",
    "    # The selectFromModel class from sklearn, selects the features which coefficients are non-zero\n",
    "\n",
    "    sel_ = SelectFromModel(LogisticRegression(C=0.5, penalty='l1', solver='liblinear', random_state=10))\n",
    "\n",
    "    sel_.fit(scaler.transform(X_train), y_train)\n",
    "\n",
    "    # make a list with the selected features\n",
    "    selected_feat = X_train.columns[(sel_.get_support())]\n",
    "    \n",
    "    print(\"Number of features which coefficient was shrank to zero: \", np.sum(sel_.estimator_.coef_ == 0))\n",
    "    # identify the removed features like this:\n",
    "    removed_feats = X_train.columns[(sel_.estimator_.coef_ == 0).ravel().tolist()]\n",
    "    print('Removed features by Lasso: ',removed_feats) \n",
    "\n",
    "    return X_train.columns[(sel_.estimator_.coef_ != 0).ravel().tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lasso_SelectedColumns = lasso_regularization(train_dfML)\n",
    "\n",
    "Lasso_SelectedColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = train_dfML[Lasso_SelectedColumns].copy()\n",
    "\n",
    "df2['y'] = train_dfML['y']\n",
    "\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Modeling\n",
    "\n",
    "### 4.1 Baseline Model\n",
    "- TODO: Create a simple baseline model (e.g., majority class classifier)\n",
    "- TODO: Evaluate baseline performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline model\n",
    "# TODO: Implement baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75",
   "metadata": {},
   "source": [
    "### 4.2 Model Selection\n",
    "- TODO: Train multiple algorithms from class:\n",
    "  - Logistic Regression\n",
    "  - Decision Trees\n",
    "  - Random Forest\n",
    "  - Gradient Boosting (XGBoost, LightGBM)\n",
    "  - Support Vector Machines\n",
    "  - Neural Networks\n",
    "  - K-Nearest Neighbors\n",
    "  - Naive Bayes\n",
    "  - TODO: Add others as covered in class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: Logistic Regression\n",
    "# TODO: Train and evaluate logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2: Decision Tree\n",
    "# TODO: Train and evaluate decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3: Random Forest\n",
    "# TODO: Train and evaluate random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 4: Gradient Boosting\n",
    "# TODO: Train and evaluate gradient boosting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 5: Support Vector Machine\n",
    "# TODO: Train and evaluate SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 6: [Add more models as needed]\n",
    "# TODO: Train and evaluate additional models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82",
   "metadata": {},
   "source": [
    "### 4.3 Hyperparameter Tuning\n",
    "- TODO: Define hyperparameter search space\n",
    "- TODO: Apply Grid Search or Random Search\n",
    "- TODO: Use cross-validation for tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning - Model 1\n",
    "# TODO: Implement GridSearchCV or RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning - Model 2\n",
    "# TODO: Implement hyperparameter tuning for other promising models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85",
   "metadata": {},
   "source": [
    "### 4.4 Ensemble Methods\n",
    "- TODO: Create ensemble models (voting, stacking, blending)\n",
    "- TODO: Combine best performing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble models\n",
    "# TODO: Implement ensemble techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Evaluation\n",
    "\n",
    "### 5.1 Model Performance Metrics\n",
    "- TODO: Calculate accuracy, precision, recall, F1-score\n",
    "- TODO: Generate ROC curves and calculate AUC\n",
    "- TODO: Create confusion matrices\n",
    "- TODO: Calculate business-relevant metrics (cost/benefit analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation metrics\n",
    "# TODO: Calculate and compare all metrics across models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model performance\n",
    "# TODO: Create ROC curves, precision-recall curves\n",
    "# TODO: Create confusion matrices\n",
    "# TODO: Create comparison charts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90",
   "metadata": {},
   "source": [
    "### 5.2 Model Interpretation\n",
    "- TODO: Analyze feature importance\n",
    "- TODO: Interpret model predictions\n",
    "- TODO: Validate model behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance analysis\n",
    "# TODO: Extract and visualize feature importance from models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model interpretation\n",
    "# TODO: Use SHAP, LIME, or other interpretation methods if applicable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93",
   "metadata": {},
   "source": [
    "### 5.3 Model Validation\n",
    "- TODO: Perform cross-validation\n",
    "- TODO: Test on holdout set\n",
    "- TODO: Check for overfitting/underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation\n",
    "# TODO: Perform k-fold cross-validation on best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final model evaluation on test set\n",
    "# TODO: Evaluate final model(s) on unseen test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96",
   "metadata": {},
   "source": [
    "### 5.4 Business Impact Assessment\n",
    "- TODO: Translate model performance to business value\n",
    "- TODO: Calculate expected ROI or cost savings\n",
    "- TODO: Provide actionable recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Business impact analysis\n",
    "# TODO: Calculate business metrics (conversion rate improvement, cost reduction, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Conclusions and Recommendations\n",
    "\n",
    "### 6.1 Summary of Findings\n",
    "- TODO: Summarize key insights from data exploration\n",
    "- TODO: Summarize model performance\n",
    "- TODO: Identify most important predictive features\n",
    "\n",
    "### 6.2 Best Model Selection\n",
    "- TODO: Select and justify the best model\n",
    "- TODO: Document model strengths and limitations\n",
    "\n",
    "### 6.3 Recommendations\n",
    "- TODO: Provide actionable business recommendations\n",
    "- TODO: Suggest customer prioritization strategy\n",
    "- TODO: Recommend campaign optimization strategies\n",
    "\n",
    "### 6.4 Future Work\n",
    "- TODO: Suggest model improvements\n",
    "- TODO: Identify additional data needs\n",
    "- TODO: Propose deployment strategy\n",
    "\n",
    "### 6.5 Lessons Learned\n",
    "- TODO: Document challenges faced\n",
    "- TODO: Share insights from the project\n",
    "- TODO: Note what would be done differently\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99",
   "metadata": {},
   "source": [
    "## Project Notes and Team Collaboration\n",
    "\n",
    "### Team Members\n",
    "- TODO: List team members and responsibilities\n",
    "Julia Kardasz 1250264\n",
    "\n",
    "### Project Timeline\n",
    "- TODO: Document project milestones and deadlines\n",
    "\n",
    "### References\n",
    "- TODO: Add references to papers, documentation, and resources used\n",
    "\n",
    "---\n",
    "*This notebook follows the CRISP-DM methodology for data mining projects*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (jupyter-env)",
   "language": "python",
   "name": "jupyter-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
